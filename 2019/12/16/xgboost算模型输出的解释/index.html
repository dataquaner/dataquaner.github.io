<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>xgboost算法模型输出的解释 | DataQuaner</title><meta name="description" content="xgboost算法模型输出的解释"><meta name="keywords" content="xgboost"><meta name="author" content="Leon"><meta name="copyright" content="Leon"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="xgboost算法模型输出的解释"><meta name="twitter:description" content="xgboost算法模型输出的解释"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png"><meta property="og:type" content="article"><meta property="og:title" content="xgboost算法模型输出的解释"><meta property="og:url" content="https://dataquaner.github.io/2019/12/16/xgboost%E7%AE%97%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A/"><meta property="og:site_name" content="DataQuaner"><meta property="og:description" content="xgboost算法模型输出的解释"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://dataquaner.github.io/2019/12/16/xgboost%E7%AE%97%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A/"><link rel="prev" title="机器学习系列之决策树算法（01）：决策树特征选择" href="https://dataquaner.github.io/2019/12/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8801%EF%BC%89%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"><link rel="next" title="数据存储之MySQL系列（01）：MySQL体系结构" href="https://dataquaner.github.io/2019/12/04/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E4%B9%8BMySQL%E7%B3%BB%E5%88%97%EF%BC%8801%EF%BC%89%EF%BC%9AMySQL%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false,
  ClickShowText: undefined,
  medium_zoom: 'false',
  Snackbar: undefined
  
}</script><link rel="alternate" href="/atom.xml" title="DataQuaner" type="application/atom+xml">
</head><body><div id="header"> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">DataQuaner</a></span><i class="fa fa-bars fa-fw toggle-menu pull_right close" aria-hidden="true"></i><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 类别</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 小憩</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/Photo/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">4</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">5</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">5</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 类别</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 小憩</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-问题描述"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">1. 问题描述</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#2-数据集"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">2. 数据集</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3-训练集与测试集"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">3. 训练集与测试集</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#4-Xgboost建模"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">4. Xgboost建模</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-1-模型初始化设置"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text">4.1 模型初始化设置</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-2-建模与预测"><span class="toc_mobile_items-number">4.2.</span> <span class="toc_mobile_items-text">4.2 建模与预测</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-3-可视化输出"><span class="toc_mobile_items-number">4.3.</span> <span class="toc_mobile_items-text">4.3 可视化输出</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#4-3-1-得分"><span class="toc_mobile_items-number">4.3.1.</span> <span class="toc_mobile_items-text">4.3.1 得分</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#4-3-2-所属的叶子节点"><span class="toc_mobile_items-number">4.3.2.</span> <span class="toc_mobile_items-text">4.3.2 所属的叶子节点</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#4-3-2-特征重要性"><span class="toc_mobile_items-number">4.3.3.</span> <span class="toc_mobile_items-text">4.3.2 特征重要性</span></a></li></ol></li></ol></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-问题描述"><span class="toc-number">1.</span> <span class="toc-text">1. 问题描述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-数据集"><span class="toc-number">2.</span> <span class="toc-text">2. 数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-训练集与测试集"><span class="toc-number">3.</span> <span class="toc-text">3. 训练集与测试集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Xgboost建模"><span class="toc-number">4.</span> <span class="toc-text">4. Xgboost建模</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-模型初始化设置"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 模型初始化设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-建模与预测"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 建模与预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-可视化输出"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 可视化输出</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-1-得分"><span class="toc-number">4.3.1.</span> <span class="toc-text">4.3.1 得分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-所属的叶子节点"><span class="toc-number">4.3.2.</span> <span class="toc-text">4.3.2 所属的叶子节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-特征重要性"><span class="toc-number">4.3.3.</span> <span class="toc-text">4.3.2 特征重要性</span></a></li></ol></li></ol></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png)"><div id="post-info"><div id="post-title"><div class="posttitle">xgboost算法模型输出的解释</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-12-16<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-12-16</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/MachineLearning/">MachineLearning</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon" aria-hidden="true"></i><span>字数总计: </span><span class="word-count">1.8k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon" aria-hidden="true"></i><span>阅读时长: 8 分钟</span><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true">       </i><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h2><p> 近来, 在python环境下使用xgboost算法作若干的机器学习任务, 在这个过程中也使用了其内置的函数来可视化树的结果, 但对leaf value的值一知半解; 同时, 也遇到过使用xgboost 内置的predict 对测试集进行打分预测, 发现若干样本集的输出分值是一样的. 这个问题该怎么解释呢? 通过翻阅Stack Overflow 上的相关问题, 以及搜索到的github上的issue回答, 应该算初步对这个问题有了一定的理解。</p>
<h2 id="2-数据集"><a href="#2-数据集" class="headerlink" title="2. 数据集"></a>2. 数据集</h2><p> 在这里, 使用经典的鸢尾花的数据来说明. 使用二分类的问题来说明, 故在这里只取前100行的数据.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"> </span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">data = iris.data[:<span class="number">100</span>]</span><br><span class="line"><span class="keyword">print</span> data.shape</span><br><span class="line"><span class="comment">#(100L, 4L)</span></span><br><span class="line"><span class="comment">#一共有100个样本数据, 维度为4维</span></span><br><span class="line"> </span><br><span class="line">label = iris.target[:<span class="number">100</span>]</span><br><span class="line"><span class="keyword">print</span> label</span><br><span class="line"><span class="comment">#正好选取label为0和1的数据</span></span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<h2 id="3-训练集与测试集"><a href="#3-训练集与测试集" class="headerlink" title="3. 训练集与测试集"></a>3. 训练集与测试集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"> </span><br><span class="line">train_x, test_x, train_y, test_y = train_test_split(data, label, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4-Xgboost建模"><a href="#4-Xgboost建模" class="headerlink" title="4. Xgboost建模"></a>4. Xgboost建模</h2><h3 id="4-1-模型初始化设置"><a href="#4-1-模型初始化设置" class="headerlink" title="4.1 模型初始化设置"></a>4.1 模型初始化设置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">dtrain=xgb.DMatrix(train_x,label=train_y)</span><br><span class="line">dtest=xgb.DMatrix(test_x)</span><br><span class="line"> </span><br><span class="line">params=&#123;<span class="string">'booster'</span>:<span class="string">'gbtree'</span>,</span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'binary:logistic'</span>,</span><br><span class="line">    <span class="string">'eval_metric'</span>: <span class="string">'auc'</span>,</span><br><span class="line">    <span class="string">'max_depth'</span>:<span class="number">4</span>,</span><br><span class="line">    <span class="string">'lambda'</span>:<span class="number">10</span>,</span><br><span class="line">    <span class="string">'subsample'</span>:<span class="number">0.75</span>,</span><br><span class="line">    <span class="string">'colsample_bytree'</span>:<span class="number">0.75</span>,</span><br><span class="line">    <span class="string">'min_child_weight'</span>:<span class="number">2</span>,</span><br><span class="line">    <span class="string">'eta'</span>: <span class="number">0.025</span>,</span><br><span class="line">    <span class="string">'seed'</span>:<span class="number">0</span>,</span><br><span class="line">    <span class="string">'nthread'</span>:<span class="number">8</span>,</span><br><span class="line">     <span class="string">'silent'</span>:<span class="number">1</span>&#125;</span><br><span class="line"> </span><br><span class="line">watchlist = [(dtrain,<span class="string">'train'</span>)]</span><br></pre></td></tr></table></figure>

<h3 id="4-2-建模与预测"><a href="#4-2-建模与预测" class="headerlink" title="4.2 建模与预测"></a>4.2 建模与预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">bst=xgb.train(params,dtrain,num_boost_round=<span class="number">100</span>,evals=watchlist)</span><br><span class="line"> </span><br><span class="line">ypred=bst.predict(dtest)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置阈值, 输出一些评价指标</span></span><br><span class="line">y_pred = (ypred &gt;= <span class="number">0.5</span>)*<span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">print</span> <span class="string">'AUC: %.4f'</span> % metrics.roc_auc_score(test_y,ypred)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'ACC: %.4f'</span> % metrics.accuracy_score(test_y,y_pred)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'Recall: %.4f'</span> % metrics.recall_score(test_y,y_pred)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'F1-score: %.4f'</span> %metrics.f1_score(test_y,y_pred)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'Precesion: %.4f'</span> %metrics.precision_score(test_y,y_pred)</span><br><span class="line">metrics.confusion_matrix(test_y,y_pred)</span><br></pre></td></tr></table></figure>

<p>Out[23]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">AUC: <span class="number">1.0000</span></span><br><span class="line">ACC: <span class="number">1.0000</span></span><br><span class="line">Recall: <span class="number">1.0000</span></span><br><span class="line">F1-score: <span class="number">1.0000</span></span><br><span class="line">Precesion: <span class="number">1.0000</span></span><br><span class="line">array([[<span class="number">13</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>, <span class="number">12</span>]], dtype=int64)</span><br></pre></td></tr></table></figure>

<p>Yeah, 完美的模型, 完美的预测!</p>
<h3 id="4-3-可视化输出"><a href="#4-3-可视化输出" class="headerlink" title="4.3 可视化输出"></a>4.3 可视化输出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对于预测的输出有三种方式</span></span><br><span class="line">?bst.predict</span><br><span class="line">Signature: bst.predict(data, output_margin=<span class="literal">False</span>, ntree_limit=<span class="number">0</span>, pred_leaf=<span class="literal">False</span>, pred_contribs=<span class="literal">False</span>, approx_contribs=<span class="literal">False</span>)</span><br><span class="line"> </span><br><span class="line">pred_leaf : bool</span><br><span class="line">    When this option <span class="keyword">is</span> on, the output will be a matrix of (nsample, ntrees)</span><br><span class="line">    <span class="keyword">with</span> each record indicating the predicted leaf index of each sample <span class="keyword">in</span> each tree.</span><br><span class="line">    Note that the leaf index of a tree <span class="keyword">is</span> unique per tree, so you may find leaf <span class="number">1</span></span><br><span class="line">    <span class="keyword">in</span> both tree <span class="number">1</span> <span class="keyword">and</span> tree <span class="number">0.</span></span><br><span class="line"> </span><br><span class="line">pred_contribs : bool</span><br><span class="line">    When this option <span class="keyword">is</span> on, the output will be a matrix of (nsample, nfeats+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> each record indicating the feature contributions (SHAP values) <span class="keyword">for</span> that</span><br><span class="line">    prediction. The sum of all feature contributions <span class="keyword">is</span> equal to the prediction.</span><br><span class="line">    Note that the bias <span class="keyword">is</span> added <span class="keyword">as</span> the final column, on top of the regular features.</span><br></pre></td></tr></table></figure>

<h4 id="4-3-1-得分"><a href="#4-3-1-得分" class="headerlink" title="4.3.1 得分"></a>4.3.1 得分</h4><p>默认的输出就是得分, 这没什么好说的, 直接上code.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ypred = bst.predict(dtest)</span><br><span class="line">ypred</span><br></pre></td></tr></table></figure>

<p>Out[32]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">array([ <span class="number">0.20081411</span>,  <span class="number">0.80391562</span>,  <span class="number">0.20081411</span>,  <span class="number">0.80391562</span>,  <span class="number">0.80391562</span>,</span><br><span class="line">        <span class="number">0.80391562</span>,  <span class="number">0.20081411</span>,  <span class="number">0.80391562</span>,  <span class="number">0.80391562</span>,  <span class="number">0.80391562</span>,</span><br><span class="line">        <span class="number">0.80391562</span>,  <span class="number">0.80391562</span>,  <span class="number">0.80391562</span>,  <span class="number">0.20081411</span>,  <span class="number">0.20081411</span>,</span><br><span class="line">        <span class="number">0.20081411</span>,  <span class="number">0.20081411</span>,  <span class="number">0.20081411</span>,  <span class="number">0.20081411</span>,  <span class="number">0.20081411</span>,</span><br><span class="line">        <span class="number">0.20081411</span>,  <span class="number">0.80391562</span>,  <span class="number">0.20081411</span>,  <span class="number">0.80391562</span>,  <span class="number">0.20081411</span>], dtype=float32)</span><br></pre></td></tr></table></figure>

<p>在这里, 就可以观察到文章最开始遇到的问题: 为什么得分几乎都是一样的值? 先不急, 看看另外两种输出.</p>
<h4 id="4-3-2-所属的叶子节点"><a href="#4-3-2-所属的叶子节点" class="headerlink" title="4.3.2 所属的叶子节点"></a>4.3.2 所属的叶子节点</h4><p>当设置<code>pred_leaf=True</code>的时候, 这时就会输出每个样本在所有树中的叶子节点</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ypred_leaf = bst.predict(dtest, pred_leaf=<span class="literal">True</span>)</span><br><span class="line">ypred_leaf</span><br></pre></td></tr></table></figure>

<p>Out[33]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, ..., <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       ..., </span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, ..., <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br></pre></td></tr></table></figure>

<p>输出的维度为[样本数, 树的数量], 树的数量默认是100, 所以<code>ypred_leaf</code>的维度为<code>[100*100]</code>.</p>
<p>对于第一行数据的解释就是, 在xgboost所有的100棵树里, 预测的叶子节点都是1(相对于每颗树).</p>
<p>那怎么看每颗树以及相应的叶子节点的分值呢?这里有两种方法, 可视化树或者直接输出模型.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xgb.to_graphviz(bst, num_trees=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#可视化第一棵树的生成情况</span></span><br></pre></td></tr></table></figure>

<p><img alt="img" data-src="https://images2017.cnblogs.com/blog/957413/201710/957413-20171017204407818-1932629185.png" class="lazyload"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#直接输出模型的迭代工程</span></span><br><span class="line">bst.dump_model(<span class="string">"model.txt"</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">booster[<span class="number">0</span>]:</span><br><span class="line"><span class="number">0</span>:[f3&lt;<span class="number">0.75</span>] yes=<span class="number">1</span>,no=<span class="number">2</span>,missing=<span class="number">1</span></span><br><span class="line">    <span class="number">1</span>:leaf=<span class="number">-0.019697</span></span><br><span class="line">    <span class="number">2</span>:leaf=<span class="number">0.0214286</span></span><br><span class="line">booster[<span class="number">1</span>]:</span><br><span class="line"><span class="number">0</span>:[f2&lt;<span class="number">2.35</span>] yes=<span class="number">1</span>,no=<span class="number">2</span>,missing=<span class="number">1</span></span><br><span class="line">    <span class="number">1</span>:leaf=<span class="number">-0.0212184</span></span><br><span class="line">    <span class="number">2</span>:leaf=<span class="number">0.0212</span></span><br><span class="line">booster[<span class="number">2</span>]:</span><br><span class="line"><span class="number">0</span>:[f2&lt;<span class="number">2.35</span>] yes=<span class="number">1</span>,no=<span class="number">2</span>,missing=<span class="number">1</span></span><br><span class="line">    <span class="number">1</span>:leaf=<span class="number">-0.0197404</span></span><br><span class="line">    <span class="number">2</span>:leaf=<span class="number">0.0197235</span></span><br><span class="line">booster[<span class="number">3</span>]: ……</span><br></pre></td></tr></table></figure>

<p>通过上述命令就可以输出模型的迭代过程, 可以看到每颗树都有两个叶子节点(树比较简单). 然后我们对每颗树中的叶子节点1的value进行累加求和, 同时进行相应的函数转换, 就是第一个样本的预测值.</p>
<p>在这里, 以第一个样本为例, 可以看到, 该样本在所有树中都属于第一个叶子, 所以累加值, 得到以下值.</p>
<p>同样, 以第二个样本为例, 可以看到, 该样本在所有树中都属于第二个叶子, 所以累加值, 得到以下值.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">leaf1   <span class="number">-1.381214</span></span><br><span class="line">leaf2    <span class="number">1.410950</span></span><br></pre></td></tr></table></figure>

<p>在使用xgboost模型最开始, 模型初始化的时候, 我们就设置了<code>&#39;objective&#39;: &#39;binary:logistic&#39;</code>, 因此使用函数将累加的值转换为实际的打分:</p>
<p>f(x)=1/(1+exp(−x))</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>/float(<span class="number">1</span>+np.exp(<span class="number">1.38121416</span>))</span><br><span class="line">Out[<span class="number">24</span>]: <span class="number">0.20081407112186503</span></span><br><span class="line"><span class="number">1</span>/float(<span class="number">1</span>+np.exp(<span class="number">-1.410950</span>))</span><br><span class="line">Out[<span class="number">25</span>]: <span class="number">0.8039157403338895</span></span><br></pre></td></tr></table></figure>

<p>这就与<code>ypred = bst.predict(dtest)</code> 的分值相对应上了.</p>
<h4 id="4-3-2-特征重要性"><a href="#4-3-2-特征重要性" class="headerlink" title="4.3.2 特征重要性"></a>4.3.2 特征重要性</h4><p>接着, 我们看另一种输出方式, 输出的是特征相对于得分的重要性.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ypred_contribs = bst.predict(dtest, pred_contribs=<span class="literal">True</span>)</span><br><span class="line">ypred_contribs</span><br></pre></td></tr></table></figure>

<p>Out[37]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">array([[ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.96967536</span>,  <span class="number">0.39522746</span>,  <span class="number">0.04604663</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-1.01448286</span>, <span class="number">-0.41277751</span>,  <span class="number">0.04604663</span>]], dtype=float32)</span><br></pre></td></tr></table></figure>

<p>输出的<code>ypred_contribs</code>的维度为<code>[100,5]</code>, 通过阅读前面的文档注释就可以知道, 最后一列是<code>bias</code>, 前面的四列分别是每个特征对最后打分的影响因子, 可以看出, 前面两个特征是不起作用的.</p>
<p>通过这个输出, 怎么和最后的打分进行关联呢? 原理也是一样的, 还是以前两列为例.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">score_a = sum(ypred_contribs[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">print</span> score_a</span><br><span class="line"><span class="comment"># -1.38121373579</span></span><br><span class="line">score_b = sum(ypred_contribs[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">print</span> score_b</span><br><span class="line"><span class="comment"># 1.41094945744</span></span><br></pre></td></tr></table></figure>

<p>相同的分值, 相同的处理情况.</p>
<p>到此, 这期关于在python上关于xgboost算法的简单实现, 以及在实现的过程中: 得分的输出、样本对应到树的节点、每个样本中单独特征对得分的影响, 以及上述三者之间的联系, 均已介绍完毕。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">Leon</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://dataquaner.github.io/2019/12/16/xgboost%E7%AE%97%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A/">https://dataquaner.github.io/2019/12/16/xgboost%E7%AE%97%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://dataquaner.github.io">DataQuaner</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/xgboost/">xgboost    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button"><i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019/12/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8801%EF%BC%89%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>机器学习系列之决策树算法（01）：决策树特征选择</span></div></a></div><div class="next-post pull_right"><a href="/2019/12/04/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E4%B9%8BMySQL%E7%B3%BB%E5%88%97%EF%BC%8801%EF%BC%89%EF%BC%9AMySQL%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>数据存储之MySQL系列（01）：MySQL体系结构</span></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="disqus_thread"></div><script>var unused = null;
var disqus_config = function () {
  this.page.url = 'https://dataquaner.github.io/2019/12/16/xgboost%E7%AE%97%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A/';
  this.page.identifier = '2019/12/16/xgboost算模型输出的解释/';
  this.page.title = 'xgboost算法模型输出的解释';
}
var d = document, s = d.createElement('script');
s.src = "https://" + 'dataquaner' +".disqus.com/embed.js";
s.setAttribute('data-timestamp', '' + +new Date());
(d.head || d.body).appendChild(s);</script></div></div></div><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2019 By Leon</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://dataquaner.github.io/">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/baidupush.js"> </script><script src="/js/tw_cn.js"></script><script>translateInitilization()
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>