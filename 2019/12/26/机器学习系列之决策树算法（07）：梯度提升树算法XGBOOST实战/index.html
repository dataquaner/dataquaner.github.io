<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战 | DataQuaner</title><meta name="description" content="XGBoost"><meta name="keywords" content="XGBoost"><meta name="author" content="Leon"><meta name="copyright" content="Leon"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战"><meta name="twitter:description" content="XGBoost"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png"><meta property="og:type" content="article"><meta property="og:title" content="机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战"><meta property="og:url" content="https://dataquaner.github.io/2019/12/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8807%EF%BC%89%EF%BC%9A%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E7%AE%97%E6%B3%95XGBOOST%E5%AE%9E%E6%88%98/"><meta property="og:site_name" content="DataQuaner"><meta property="og:description" content="XGBoost"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://dataquaner.github.io/2019/12/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8807%EF%BC%89%EF%BC%9A%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E7%AE%97%E6%B3%95XGBOOST%E5%AE%9E%E6%88%98/"><link rel="prev" title="机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战：原生接口和sklearn接口区别" href="https://dataquaner.github.io/2019/12/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8807%EF%BC%89%EF%BC%9A%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E7%AE%97%E6%B3%95XGBOOST%E5%AE%9E%E6%88%98%EF%BC%9A%E5%8E%9F%E7%94%9F%E6%8E%A5%E5%8F%A3%E5%92%8Csklearn%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%8C%BA%E5%88%AB/"><link rel="next" title="xgboost算法模型输出的解释" href="https://dataquaner.github.io/2019/12/25/xgboost%E7%AE%97%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false,
  ClickShowText: undefined,
  medium_zoom: 'false',
  Snackbar: undefined
  
}</script><link rel="alternate" href="/atom.xml" title="DataQuaner" type="application/atom+xml">
</head><body><div id="header"> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">DataQuaner</a></span><i class="fa fa-bars fa-fw toggle-menu pull_right close" aria-hidden="true"></i><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 类别</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 小憩</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/Photo/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">13</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">6</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">9</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 类别</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 小憩</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#1-前言"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">1 前言</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#2-XGBoost模型构建"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">2 XGBoost模型构建</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#回归模型"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">回归模型</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#准备数据"><span class="toc_mobile_items-number">2.1.1.</span> <span class="toc_mobile_items-text">准备数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#创建并训练XGBoost模型"><span class="toc_mobile_items-number">2.1.2.</span> <span class="toc_mobile_items-text">创建并训练XGBoost模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#评估并预测模型"><span class="toc_mobile_items-number">2.1.3.</span> <span class="toc_mobile_items-text">评估并预测模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#模型调优"><span class="toc_mobile_items-number">2.1.4.</span> <span class="toc_mobile_items-text">模型调优</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#n-estimators"><span class="toc_mobile_items-number">2.1.4.1.</span> <span class="toc_mobile_items-text">n_estimators</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#early-stopping-rounds"><span class="toc_mobile_items-number">2.1.4.2.</span> <span class="toc_mobile_items-text">early_stopping_rounds</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#learning-rate"><span class="toc_mobile_items-number">2.1.4.3.</span> <span class="toc_mobile_items-text">learning_rate</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#小结"><span class="toc_mobile_items-number">2.1.4.4.</span> <span class="toc_mobile_items-text">小结</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#分类模型"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">分类模型</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#导入包"><span class="toc_mobile_items-number">2.2.0.1.</span> <span class="toc_mobile_items-text">导入包</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#导入数据"><span class="toc_mobile_items-number">2.2.0.2.</span> <span class="toc_mobile_items-text">导入数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#数据集划分"><span class="toc_mobile_items-number">2.2.0.3.</span> <span class="toc_mobile_items-text">数据集划分</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#XGBoost模型训练"><span class="toc_mobile_items-number">2.2.0.4.</span> <span class="toc_mobile_items-text">XGBoost模型训练</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#模型可视化"><span class="toc_mobile_items-number">2.2.0.5.</span> <span class="toc_mobile_items-text">模型可视化</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3-参考资料"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">3 参考资料</span></a></li></ol></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-前言"><span class="toc-number">1.</span> <span class="toc-text">1 前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-XGBoost模型构建"><span class="toc-number">2.</span> <span class="toc-text">2 XGBoost模型构建</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#回归模型"><span class="toc-number">2.1.</span> <span class="toc-text">回归模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#准备数据"><span class="toc-number">2.1.1.</span> <span class="toc-text">准备数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#创建并训练XGBoost模型"><span class="toc-number">2.1.2.</span> <span class="toc-text">创建并训练XGBoost模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#评估并预测模型"><span class="toc-number">2.1.3.</span> <span class="toc-text">评估并预测模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型调优"><span class="toc-number">2.1.4.</span> <span class="toc-text">模型调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#n-estimators"><span class="toc-number">2.1.4.1.</span> <span class="toc-text">n_estimators</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#early-stopping-rounds"><span class="toc-number">2.1.4.2.</span> <span class="toc-text">early_stopping_rounds</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#learning-rate"><span class="toc-number">2.1.4.3.</span> <span class="toc-text">learning_rate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#小结"><span class="toc-number">2.1.4.4.</span> <span class="toc-text">小结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分类模型"><span class="toc-number">2.2.</span> <span class="toc-text">分类模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#导入包"><span class="toc-number">2.2.0.1.</span> <span class="toc-text">导入包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#导入数据"><span class="toc-number">2.2.0.2.</span> <span class="toc-text">导入数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据集划分"><span class="toc-number">2.2.0.3.</span> <span class="toc-text">数据集划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#XGBoost模型训练"><span class="toc-number">2.2.0.4.</span> <span class="toc-text">XGBoost模型训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#模型可视化"><span class="toc-number">2.2.0.5.</span> <span class="toc-text">模型可视化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-参考资料"><span class="toc-number">2.3.</span> <span class="toc-text">3 参考资料</span></a></li></ol></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png)"><div id="post-info"><div id="post-title"><div class="posttitle">机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-12-26<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-12-26</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Machine-Learning/XGBoost/">XGBoost</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon" aria-hidden="true"></i><span>字数总计: </span><span class="word-count">1.6k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon" aria-hidden="true"></i><span>阅读时长: 6 分钟</span><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true">       </i><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>上一篇从数据原理角度深入介绍了XGBoost的实现原理及优化，参考《<a href="https://dataquaner.github.io/2019/12/25/机器学习系列之决策树算法（07）：梯度提升树算法XGBOOST/">梯度提升树算法XGBoost</a>》。本篇主要介绍XGBoost的工程实战，参数调优等内容。</p>
<blockquote>
<p>学习一个算法实战，一般按照以下几步，第一步能够基于某个平台、某种语言构建一个模型，第二步是能够优化一个模型 。我们将学习以下内容</p>
<ol>
<li>如果使用xgboost构建分类器</li>
<li>xgboost 的参数含义，以及如何调参</li>
<li>xgboost 的如何做cv</li>
<li>xgboost的可视化</li>
</ol>
</blockquote>
<h1 id="2-XGBoost模型构建"><a href="#2-XGBoost模型构建" class="headerlink" title="2 XGBoost模型构建"></a>2 XGBoost模型构建</h1><h2 id="回归模型"><a href="#回归模型" class="headerlink" title="回归模型"></a>回归模型</h2><h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><p>我们使用<strong><a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data" target="_blank" rel="noopener">房价数据</a></strong> ，做的是一个回归任务，预测房价，分类任务类似。</p>
<p>导入包</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br></pre></td></tr></table></figure>

<p>读入和展示数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">'../input/train.csv'</span>)</span><br><span class="line">data.dropna(axis=<span class="number">0</span>, subset=[<span class="string">'SalePrice'</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">y = data.SalePrice</span><br><span class="line">X = data.drop([<span class="string">'SalePrice'</span>], axis=<span class="number">1</span>).select_dtypes(exclude=[<span class="string">'object'</span>])</span><br><span class="line"></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X.as_matrix(), y.as_matrix(), test_size=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line">my_imputer = Imputer()</span><br><span class="line">train_X = my_imputer.fit_transform(train_X)</span><br><span class="line">test_X = my_imputer.transform(test_X)</span><br><span class="line">print(train_X.shape)</span><br><span class="line">print(test_X.shape)</span><br><span class="line">print(train_y.shape)</span><br><span class="line">print(test_y.shape)</span><br><span class="line">---</span><br><span class="line"><span class="comment">##执行结果</span></span><br><span class="line">(<span class="number">1095</span>, <span class="number">37</span>)</span><br><span class="line">(<span class="number">365</span>, <span class="number">37</span>)</span><br><span class="line">(<span class="number">1095</span>,)</span><br><span class="line">(<span class="number">365</span>,)</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<h3 id="创建并训练XGBoost模型"><a href="#创建并训练XGBoost模型" class="headerlink" title="创建并训练XGBoost模型"></a>创建并训练XGBoost模型</h3><p>随机选取默认参数进行初始化建模</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_model = XGBRegressor()</span><br><span class="line"><span class="comment"># Add silent=True to avoid printing out updates with each cycle</span></span><br><span class="line">my_model.fit(train_X, train_y, verbose=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h3 id="评估并预测模型"><a href="#评估并预测模型" class="headerlink" title="评估并预测模型"></a>评估并预测模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make predictions</span></span><br><span class="line">predictions = my_model.predict(test_X)</span><br><span class="line">print(<span class="string">"Mean Absolute Error : "</span> + str(mean_absolute_error(predictions, test_y)))</span><br></pre></td></tr></table></figure>

<h3 id="模型调优"><a href="#模型调优" class="headerlink" title="模型调优"></a>模型调优</h3><p>XGBoost有一些参数可以显著影响模型的准确性和训练速度。</p>
<h4 id="n-estimators"><a href="#n-estimators" class="headerlink" title="n_estimators"></a><strong>n_estimators</strong></h4><p><strong>n_estimators</strong> 指定训练循环次数。在 <a href="https://link.zhihu.com/?target=http%3A//i.imgur.com/2q85n9s.png">欠拟合 vs 过拟合 图表</a>, n_estimators让训练沿着图表向右移动。 值太低会导致欠拟合，这对训练数据和新数据的预测都是不准确的。 太大的值会导致过度拟合，这是对训练数据的准确预测，但对新数据的预测不准确（这是我们关心的）。 通过实际实验来找到理想的n_estimators。 典型值范围为100-1000，但这很大程度上取决于下面讨论的</p>
<h4 id="early-stopping-rounds"><a href="#early-stopping-rounds" class="headerlink" title="early_stopping_rounds"></a><strong>early_stopping_rounds</strong></h4><p><strong>early_stopping_rounds</strong> 提供了一种自动查找理想值的方法。 early_stopping_rounds会导致模型在validation score停止改善时停止迭代，即使迭代次数还没有到n_estimators。为<strong>n_estimators</strong>设置一个高值然后使用<strong>early_stopping_rounds</strong>来找到停止迭代的最佳时间是明智的。</p>
<p>存在随机的情况有时会导致validation score无法改善，因此需要指定一个数字，以确定在停止前允许多少轮退化。<strong>early_stopping_rounds = 5</strong>是一个合理的值。 因此，在五轮validation score无法改善之后训练将停止。 以下是early_stopping的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">my_model = XGBRegressor(n_estimators=<span class="number">1000</span>)</span><br><span class="line">my_model.fit(train_X, train_y, early_stopping_rounds=<span class="number">5</span>, </span><br><span class="line">             eval_set=[(test_X, test_y)], verbose=<span class="literal">False</span>)</span><br><span class="line">predictions = my_model.predict(test_X)</span><br><span class="line">print(<span class="string">"Mean Absolute Error : "</span> + str(mean_absolute_error(predictions, test_y)))</span><br></pre></td></tr></table></figure>

<p>当使用<strong>early_stopping_rounds</strong>时，需要留出一些数据来检查要使用的轮数。 如果以后想要使所有数据拟合模型，请将<strong>n_estimators</strong>设置为在早期停止运行时发现的最佳值。</p>
<h4 id="learning-rate"><a href="#learning-rate" class="headerlink" title="learning_rate"></a>learning_rate</h4><p>对于更好的XGBoost模型，这是一个微妙但重要的技巧：</p>
<p>XGBoost模型不是通过简单地将每个组件模型中的预测相加来获得预测，而是在将它们添加之前将每个模型的预测乘以一个小数字。这意味着我们添加到集合中的每个树都不会对最后结果有决定性的影响。在实践中，这降低了模型过度拟合的倾向。</p>
<p>因此，使用一个较大的<strong>n_estimators</strong>值并不会造成过拟合。如果使用early_stopping_rounds，树的数量会被设置成一个合适的值。</p>
<p>通常，较小的learning rate（以及大量的estimators）将产生更准确的XGBoost模型，但是由于它在整个循环中进行更多迭代，因此也将使模型更长时间进行训练。 包含学习率的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">my_model = XGBRegressor(n_estimators=<span class="number">1000</span>, learning_rate=<span class="number">0.05</span>)</span><br><span class="line">my_model.fit(train_X, train_y, early_stopping_rounds=<span class="number">5</span>, </span><br><span class="line">             eval_set=[(test_X, test_y)], verbose=<span class="literal">False</span>)</span><br><span class="line">predictions = my_model.predict(test_X)</span><br><span class="line">print(<span class="string">"Mean Absolute Error : "</span> + str(mean_absolute_error(predictions, test_y)))</span><br></pre></td></tr></table></figure>

<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>XGBoost目前是用于在传统数据（也称为表格或结构数据）上构建精确模型的主要算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"></span><br><span class="line">my_model1 = XGBRegressor()</span><br><span class="line">my_model1.fit(train_X, train_y, verbose=<span class="literal">False</span>)</span><br><span class="line">predictions = my_model1.predict(test_X)</span><br><span class="line">print(<span class="string">"Mean Absolute Error 1: "</span> + str(mean_absolute_error(predictions, test_y)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">my_model2 = XGBRegressor(n_estimators=<span class="number">1000</span>)</span><br><span class="line">my_model2.fit(train_X, train_y, early_stopping_rounds=<span class="number">5</span>, </span><br><span class="line">             eval_set=[(test_X, test_y)], verbose=<span class="literal">False</span>)</span><br><span class="line">predictions = my_model2.predict(test_X)</span><br><span class="line">print(<span class="string">"Mean Absolute Error 2: "</span> + str(mean_absolute_error(predictions, test_y)))</span><br><span class="line"></span><br><span class="line">my_model3 = XGBRegressor(n_estimators=<span class="number">1000</span>, learning_rate=<span class="number">0.05</span>)</span><br><span class="line">my_model3.fit(train_X, train_y,  </span><br><span class="line">             eval_set=[(test_X, test_y)], verbose=<span class="literal">False</span>)</span><br><span class="line">predictions = my_model3.predict(test_X)</span><br><span class="line">print(<span class="string">"Mean Absolute Error 3: "</span> + str(mean_absolute_error(predictions, test_y)))</span><br></pre></td></tr></table></figure>

<h2 id="分类模型"><a href="#分类模型" class="headerlink" title="分类模型"></a>分类模型</h2><p>以天池竞赛中的<a href="https://tianchi.aliyun.com/competition/entrance/231702/introduction?spm=5176.12281973.1005.1.3dd52448pr3509" target="_blank" rel="noopener">《<strong>快来一起挖掘幸福感！</strong>》</a>中的数据为例，开始一个多分类模型的的实例</p>
<h4 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve, train_test_split,GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br></pre></td></tr></table></figure>

<h4 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''  </span></span><br><span class="line"><span class="string">##         准备训练集和测试集</span></span><br><span class="line"><span class="string">'''</span>  </span><br><span class="line">data = pd.read_csv(<span class="string">'happiness_train_abbr.csv'</span>)</span><br><span class="line">y=data[<span class="string">'happiness'</span>]</span><br><span class="line">data.drop(<span class="string">'happiness'</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">data.drop(<span class="string">'survey_time'</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)<span class="comment">#survey_time格式不能直接识别</span></span><br><span class="line">X=data</span><br></pre></td></tr></table></figure>

<h4 id="数据集划分"><a href="#数据集划分" class="headerlink" title="数据集划分"></a>数据集划分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_x, test_x, train_y, test_y = train_test_split (X, y, test_size =<span class="number">0.30</span>, early_stopping_rounds=<span class="number">10</span>,random_state = <span class="number">33</span>)</span><br></pre></td></tr></table></figure>

<h4 id="XGBoost模型训练"><a href="#XGBoost模型训练" class="headerlink" title="XGBoost模型训练"></a>XGBoost模型训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''  </span></span><br><span class="line"><span class="string">##         xgboost训练</span></span><br><span class="line"><span class="string">'''</span> </span><br><span class="line">params = &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>, </span><br><span class="line">          <span class="string">'n_estimators'</span>: <span class="number">500</span>, </span><br><span class="line">          <span class="string">'max_depth'</span>: <span class="number">5</span>, </span><br><span class="line">          <span class="string">'min_child_weight'</span>: <span class="number">1</span>, </span><br><span class="line">          <span class="string">'seed'</span>: <span class="number">0</span>, </span><br><span class="line">          <span class="string">'subsample'</span>: <span class="number">0.8</span>, </span><br><span class="line">          <span class="string">'colsample_bytree'</span>: <span class="number">0.8</span>,</span><br><span class="line">          <span class="string">'gamma'</span>: <span class="number">0</span>, </span><br><span class="line">          <span class="string">'reg_alpha'</span>: <span class="number">0</span>, </span><br><span class="line">          <span class="string">'reg_lambda'</span>: <span class="number">1</span></span><br><span class="line">         &#125;</span><br><span class="line"><span class="comment">#第一次设置300次的迭代，评测的指标是"merror","mlogloss"，这是一个多分类问题。</span></span><br><span class="line">model = xgb.XGBClassifier(params)</span><br><span class="line">eval_set = [(train_x, train_y), (test_x, test_y)]</span><br><span class="line">model.fit(train_x, train_y, eval_set=eval_set, eval_metric=[<span class="string">"merror"</span>, <span class="string">"mlogloss"</span>],verbose=<span class="literal">True</span>)</span><br><span class="line">predictions = model.predict(test_x)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Mean Absolute Error : "</span> + str(mean_absolute_error(predictions, test_y)))    </span><br><span class="line">accuracy = accuracy_score(test_y, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>

<h4 id="模型可视化"><a href="#模型可视化" class="headerlink" title="模型可视化"></a>模型可视化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''  </span></span><br><span class="line"><span class="string">##         可视化训练过程</span></span><br><span class="line"><span class="string">'''</span> </span><br><span class="line">results = model.evals_result()</span><br><span class="line">epochs = len(results[<span class="string">'validation_0'</span>][<span class="string">'merror'</span>])</span><br><span class="line">x_axis = range(<span class="number">0</span>, epochs)</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line">fig, ax = pyplot.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">ax[<span class="number">0</span>].plot(x_axis, results[<span class="string">'validation_0'</span>][<span class="string">'mlogloss'</span>], label=<span class="string">'Train'</span>)</span><br><span class="line">ax[<span class="number">0</span>].plot(x_axis, results[<span class="string">'validation_1'</span>][<span class="string">'mlogloss'</span>], label=<span class="string">'Test'</span>)</span><br><span class="line">ax[<span class="number">0</span>].legend()</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'XGBoost Log Loss'</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">'Log Loss'</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_xlabel(<span class="string">'epochs'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>].plot(x_axis, results[<span class="string">'validation_0'</span>][<span class="string">'merror'</span>], label=<span class="string">'Train'</span>)</span><br><span class="line">ax[<span class="number">1</span>].plot(x_axis, results[<span class="string">'validation_1'</span>][<span class="string">'merror'</span>], label=<span class="string">'Test'</span>)</span><br><span class="line">ax[<span class="number">1</span>].legend()</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'XGBoost Classification Error'</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">'Classification Error'</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_xlabel(<span class="string">'epochs'</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>

<img alt="模型迭代结果" style="zoom: 80%;" data-src="C:\Users\liyu25\AppData\Roaming\Typora\typora-user-images\image-20191226184624206.png" class="lazyload">

<p>实际训练效果，在第146次迭代就停止了，说明最好的效果实在136次左右。根据许多大牛的实践经验，选择<strong>early_stopping_rounds = 10% * n_estimators</strong>。</p>
<p>最终输出模型最佳状态下的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"best iteration:"</span>,model.best_iteration)</span><br><span class="line">limit = model.best_iteration</span><br><span class="line">predictions = model.predict(test_x,ntree_limit=limit)</span><br><span class="line">print(<span class="string">"Mean Absolute Error : "</span> + str(mean_absolute_error(predictions, test_y)))    </span><br><span class="line">accuracy = accuracy_score(test_y, predictions)</span><br><span class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (accuracy * <span class="number">100.0</span>))</span><br></pre></td></tr></table></figure>

<h2 id="3-参考资料"><a href="#3-参考资料" class="headerlink" title="3 参考资料"></a>3 参考资料</h2><p><a href="https://link.zhihu.com/?target=https%3A//www.kaggle.com/dansbecker/xgboost">https://www.kaggle.com/dansbecker/xgboost</a></p>
<p><a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/lujiandong1/article/details/52777168">https://blog.csdn.net/lujiandong1/article/details/52777168</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">Leon</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://dataquaner.github.io/2019/12/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8807%EF%BC%89%EF%BC%9A%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E7%AE%97%E6%B3%95XGBOOST%E5%AE%9E%E6%88%98/">https://dataquaner.github.io/2019/12/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8807%EF%BC%89%EF%BC%9A%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E7%AE%97%E6%B3%95XGBOOST%E5%AE%9E%E6%88%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://dataquaner.github.io">DataQuaner</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/XGBoost/">XGBoost    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button"><i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019/12/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8807%EF%BC%89%EF%BC%9A%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E7%AE%97%E6%B3%95XGBOOST%E5%AE%9E%E6%88%98%EF%BC%9A%E5%8E%9F%E7%94%9F%E6%8E%A5%E5%8F%A3%E5%92%8Csklearn%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%8C%BA%E5%88%AB/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战：原生接口和sklearn接口区别</span></div></a></div><div class="next-post pull_right"><a href="/2019/12/25/xgboost%E7%AE%97%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>xgboost算法模型输出的解释</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/12/25/xgboost算模型输出的解释/" title="xgboost算法模型输出的解释"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png"><div class="relatedPosts_title">xgboost算法模型输出的解释</div></a></div><div class="relatedPosts_item"><a href="/2019/12/27/机器学习系列之决策树算法（07）：梯度提升树算法XGBOOST实战：原生接口和sklearn接口的区别/" title="机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战：原生接口和sklearn接口区别"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png"><div class="relatedPosts_title">机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战：原生接口和sklearn接口区别</div></a></div><div class="relatedPosts_item"><a href="/2019/12/24/机器学习系列之决策树算法（09）：ID3、C4.5、CART、随机森林、bagging、boosting、Adaboost、GBDT、xgboost算法总结/" title="机器学习系列之决策树算法（09）：ID3、C4.5、CART、随机森林、bagging、boosting、Adaboost、GBDT、xgboost算法总结"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png"><div class="relatedPosts_title">机器学习系列之决策树算法（09）：ID3、C4.5、CART、随机森林、bagging、boosting、Adaboost、GBDT、xgboost算法总结</div></a></div><div class="relatedPosts_item"><a href="/2019/12/25/机器学习系列之决策树算法（07）：梯度提升树算法XGBOOST/" title="机器学习系列之决策树算法（07）：梯度提升树算法XGBoost"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png"><div class="relatedPosts_title">机器学习系列之决策树算法（07）：梯度提升树算法XGBoost</div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="disqus_thread"></div><script>var unused = null;
var disqus_config = function () {
  this.page.url = 'https://dataquaner.github.io/2019/12/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%EF%BC%8807%EF%BC%89%EF%BC%9A%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E7%AE%97%E6%B3%95XGBOOST%E5%AE%9E%E6%88%98/';
  this.page.identifier = '2019/12/26/机器学习系列之决策树算法（07）：梯度提升树算法XGBOOST实战/';
  this.page.title = '机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战';
}
var d = document, s = d.createElement('script');
s.src = "https://" + 'dataquaner' +".disqus.com/embed.js";
s.setAttribute('data-timestamp', '' + +new Date());
(d.head || d.body).appendChild(s);</script></div></div></div><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By Leon</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://dataquaner.github.io/">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/baidupush.js"> </script><script src="/js/tw_cn.js"></script><script>translateInitilization()
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>