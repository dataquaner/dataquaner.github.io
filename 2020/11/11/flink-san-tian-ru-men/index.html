<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Flink三天光速入门, 大数据 bigdata Algorithm DataQuaner 人工智能 大数据圈儿">
    <meta name="description" content="1. 初识 Flink在当前数据量激增的时代，各种业务场景都有大量的业务数据产生，对于这些不断产的数据应该如何进行有效的处理，成为当下大多数公司所面临的问题。目前比较流行的大数据处理引擎 Apache Spark，基本上已经取代了 MapR">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Flink三天光速入门 | DataQuaner</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    <script src="/libs/jquery/jquery.min.js"></script>
    
<link rel="alternate" href="/atom.xml" title="DataQuaner" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DataQuaner</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DataQuaner</div>
        <div class="logo-desc">
            
            Data|Algorithm|Business
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/dataquaner/dataquaner.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/dataquaner/dataquaner.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/23.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Flink三天光速入门</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Flink/">
                                <span class="chip bg-color">Flink</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Flink/" class="post-category">
                                Flink
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-11-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2020-11-11
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    28.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    120 分
                </div>
                
				
                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
            
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="1-初识-Flink"><a href="#1-初识-Flink" class="headerlink" title="1. 初识 Flink"></a>1. 初识 Flink</h1><p>在当前数据量激增的时代，各种业务场景都有大量的业务数据产生，对于这些不断产的数据应该如何进行有效的处理，成为当下大多数公司所面临的问题。目前比较流行的大数据处理引擎 <code>Apache Spark</code>，基本上已经取代了 MapReduce 成为当前大数据处理的标准。但 对实时数据处理来说，Apache Spark 的 Spark-Streaming 还有性能改进的空间。对于 Spark-Streaming 的<code>流计算本质上还是批（微批）计算</code>，Apache <a href="https://flink.apache.org/" target="_blank" rel="noopener">Flink</a> 就是近年来在开源社区不断发展的技术中的能够同时支持<code>高吞吐</code>、<code>低延迟</code>、<code>高性能</code>的纯实时的分布式处理框架(主要贡献者是阿里(官网支持汉化阅读)，QPS可达30W+)。</p>
<h3 id="Flink-是什么"><a href="#Flink-是什么" class="headerlink" title="Flink 是什么"></a>Flink 是什么</h3><h5 id="1-Flink-的发展历史"><a href="#1-Flink-的发展历史" class="headerlink" title="1. Flink 的发展历史"></a>1. Flink 的发展历史</h5><p>在 2010 年至 2014 年间，由柏林工业大学、柏林洪堡大学和哈索普拉特纳研究所联合发 起名为<code>Stratosphere:Information Management on the Cloud</code>研究项目，该项目在当时的社区逐渐具有了一定的社区知名度。<strong>2014</strong> 年 4 月，Stratosphere 代码被贡献给 Apache 软件基金会，成为 Apache 基金会孵化器项目。初期参与该项目的核心成员均是 Stratosphere 曾经的核心成员，之后团队的大部分创始成员离开学校，共同创办了一家名叫 Data Artisans 的公司，其主要业务便是将 Stratosphere，也就是之后的 Flink 实现商业化。在项目孵化 期间，项目 Stratosphere 改名为 Flink。Flink 在德语中是<strong>快速</strong>和<strong>灵敏</strong>的意思，用来体现流 式数据处理器速度快和灵活性强等特点，同时使用棕<strong>红色松鼠</strong>图案作为 Flink 项目的 Logo， 也是为了突出松鼠灵活快速的特点，由此，Flink 正式进入社区开发者的视线。 2014 年 12 月，该项目成为 Apache 软件基金会顶级项目，从 <code>2015 年 9 月</code>发布第一个稳 定版本 0.9，到目前为止已经发布到 1.9 的版本，更多的社区开发成员逐步加入，现在 Flink 在全球范围内拥有 350 多位开发人员，不断有新的特性发布。同时在全球范围内，越来越多 的公司开始使用 Flink，在国内比较出名的互联网公司如阿里巴巴、美团、滴滴等，都在大 规模使用 Flink 作为企业的分布式大数据处理引擎。</p>
<h5 id="2-Flink-的定义"><a href="#2-Flink-的定义" class="headerlink" title="2. Flink 的定义"></a>2. Flink 的定义</h5><p>Apache <a href="https://flink.apache.org/zh/flink-architecture.html" target="_blank" rel="noopener">Flink</a> 是一个框架和分布式处理引擎，用于在<code>无边界</code>和<code>有边界</code>数据流上进行<code>有状态</code>的计算。Flink 能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。</p>
<blockquote>
<p>Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale</p>
</blockquote>
<h5 id="3-有界流和无界流"><a href="#3-有界流和无界流" class="headerlink" title="3. 有界流和无界流"></a>3. 有界流和无界流</h5><p>任何类型的数据都可以形成一种事件流。信用卡交易、传感器测量、机器日志、网站或 移动应用程序上的用户交互记录，所有这些数据都形成一种流。</p>
<p>无界流： 有定义流的开始，但<strong>没有定义流的结束</strong>。它们会无休止地产生数据。无界流 的数据必须持续处理，即数据被摄取后需要立刻处理。我们不能等到所有数据都到达再处理， 因为输入是无限的，在任何时候输入都不会完成。处理无界数据通常要求以特定顺序摄取事 件，例如事件发生的顺序，以便能够推断结果的完整性。</p>
<p>有界流： 有定义流的开始，也有定义流的结束。有界流可以在摄取所有数据后再进行 计算。有界流所有数据可以被排序，所以并不需要有序摄取。有界流处理通常被称为批处理。跟Spark-Stream类似。<br><img src="https://img-blog.csdnimg.cn/20200713092013397.png#pic_center" alt="在这里插入图片描述"><br>Apache Flink 擅长处理无界和有界数据集精确的时间控制和状态化使得 Flink 的运行时(runtime)能够运行任何处理无界流的应用。有界流则由一些专为固定大小数据集特殊设计的算法和数据结构进行内部处理，产生了出色的性能。</p>
<h5 id="4-有状态的计算架构"><a href="#4-有状态的计算架构" class="headerlink" title="4. 有状态的计算架构"></a>4. 有状态的计算架构</h5><p>数据产生的<strong>本质</strong>，其实是一条条真实存在的事件按照时间顺序源源不断的产生，我们很难在数据产生的过程中进行计算并直接产生统计结果，因为这不仅对系统有非常高的要求， 还必须要满足高性能、高吞吐、低延时等众多目标。而有状态流计算架构（如图所示）的提 出，从一定程度上满足了企业的这种需求，企业基于实时的流式数据，维护所有计算过程的 状态，所谓状态就是<code>计算过程中产生的中间计算结果</code>，<code>每次计算新的数据进入到流式系统中 都是基于中间状态结果的基础上进行运算</code>，最终产生正确的统计结果。基于有状态计算的方式最大的优势是<code>不需要将原始数据重新从外部存储中拿出来</code>，从而进行全量计算，因为这种计算方式的代价可能是非常高的。从另一个角度讲，<strong>用户无须通过调度和协调各种批量计算 工具，从数据仓库中获取数据统计结果，然后再落地存储，这些操作全部都可以基于流式计 算完成，可以极大地减轻系统对其他框架的依赖，减少数据计算过程中的时间损耗以及硬件存储</strong>。<br><img src="https://img-blog.csdnimg.cn/20200721101922544.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-为什么要使用-Flink"><a href="#2-为什么要使用-Flink" class="headerlink" title="2. 为什么要使用 Flink"></a>2. 为什么要使用 Flink</h3><p>可以看出<code>有状态流计算将会逐步成为企业作为构建数据平台的架构模式</code>，而目前从社区 来看，能够满足的只有 Apache Flink。Flink 通过实现 <code>Google Dataflow</code> 流式计算模型实现 了高吞吐、低延迟、高性能兼具实时流式计算框架。同时 Flink 支持高度容错的状态管理， 防止状态在计算过程中因为系统异常而出现丢失，Flink 周期性地通过分布式快照技术 <code>Checkpoints</code>实现状态的<strong>持久化维护</strong>，使得即使在系统停机或者异常的情况下都能计算出正 确的结果。</p>
<p><a href="https://flink.apache.org/zh/poweredby.html" target="_blank" rel="noopener">Flink用户</a> 众多，自2019年1月起，阿里巴巴逐步将内部维护的Blink回馈给Flink开源社区，目前贡献代码已超过100万行，国内包括腾讯、百度、字节跳动等公司，国外包括Uber、Lyft、Netflix等公司都是Flink的使用者。<br><img src="https://img-blog.csdnimg.cn/20200713092742123.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="3-Flink-的应用场景"><a href="#3-Flink-的应用场景" class="headerlink" title="3. Flink 的应用场景"></a>3. Flink 的应用场景</h3><p>在实际生产的过程中，大量数据在不断地产生，例如金融交易数据、互联网订单数据、 GPS 定位数据、传感器信号、移动终端产生的数据、通信信号数据等，以及我们熟悉的网络 流量监控、服务器产生的日志数据，这些数据最大的共同点就是<strong>实时从不同的数据源中产生</strong>， 然后<strong>再传输到下游的分析系统</strong>。针对这些数据类型主要包括实时<strong>智能推荐</strong>、<strong>复杂事件处理</strong>、 <strong>实时欺诈检测</strong>、<strong>实时数仓</strong>与 <strong>ETL 类型</strong>、<strong>流数据分析类型</strong>、<strong>实时报表类型</strong>等实时业务场景，而 Flink 对于这些类型的场景都有着非常好的支持</p>
<h5 id="1-实时智能推荐"><a href="#1-实时智能推荐" class="headerlink" title="1. 实时智能推荐"></a>1. 实时智能推荐</h5><p>智能推荐会根据用户历史的购买行为，通过推荐算法训练模型，预测用户未来可能会购 买的物品。对个人来说，推荐系统起着信息过滤的作用，对 Web/App 服务端来说，推荐系统 起着满足用户个性化需求，提升用户满意度的作用。推荐系统本身也在飞速发展，除了算法 <strong>越来越完善</strong>，对<strong>时延</strong>的要求也越来越苛刻和实时化。利用 Flink 流计算帮助用户构建更加实 时的智能推荐系统，对用户行为指标进行实时计算，对模型进行实时更新，对用户指标进行 实时预测，并将预测的信息推送给 Wep/App 端，帮助用户获取想要的商品信息，另一方面也 帮助企业提升销售额，创造更大的商业价值。</p>
<h5 id="2-复杂事件处理"><a href="#2-复杂事件处理" class="headerlink" title="2. 复杂事件处理"></a>2. 复杂事件处理</h5><p>对于复杂事件处理，比较常见的案例主要集中于工业领域，例如对车载传感器、机械设备等实时故障检测，这些业务类型通常数据量都非常大，且对数据处理的时效性要求非常高。 通过利用 Flink 提供的 <code>CEP</code>（复杂事件处理）进行事件模式的抽取，同时应用 Flink 的 Sql 进行事件数据的转换，在流式系统中构建实时规则引擎，一旦事件触发报警规则，便立即将 告警结果传输至下游通知系统，从而实现对设备故障快速预警监测，车辆状态监控等目的。</p>
<h5 id="3-实时欺诈检测"><a href="#3-实时欺诈检测" class="headerlink" title="3. 实时欺诈检测"></a>3. 实时欺诈检测</h5><p>在金融领域的业务中，常常出现各种类型的欺诈行为，例如信用卡欺诈、信贷申请欺诈等，而如何保证用户和公司的资金安全，是近年来许多金融公司及银行共同面对的挑战。 随着不法分子欺诈手段的不断升级，传统的反欺诈手段已经不足以解决目前所面临的问题。 以往可能需要几个小时才能通过交易数据计算出用户的<code>行为指标</code>，然后通过规则判别出具有 欺诈行为嫌疑的用户，再进行案件调查处理，在这种情况下资金可能早已被不法分子转移， 从而给企业和用户造成大量的经济损失。而运用 Flink 流式计算技术能够在<strong>毫秒内就完成对 欺诈判断行为指标的计算</strong>，然后实时对交易流水进行规则判断或者模型预测，这样一旦检测 出交易中存在欺诈嫌疑，则直接对交易进行实时拦截，避免因为处理不及时而导致的经济损 失。</p>
<h5 id="4-实时数仓与-ETL-结合离线数仓"><a href="#4-实时数仓与-ETL-结合离线数仓" class="headerlink" title="4. 实时数仓与 ETL 结合离线数仓"></a>4. 实时数仓与 ETL 结合离线数仓</h5><p>通过利用流计算诸多优势和 SQL 灵活的加工能力，对流式数据进行实时<code>清洗</code>、<code>归并</code>、<code>结构化处理</code>，为离线数仓进行补充和优化。另一方面结合实时数据 ETL 处理能 力，利用有状态流式计算技术，可以尽可能降低企业由于在离线数据计算过程中调度逻辑的复杂度，高效快速地处理企业需要的统计结果，帮助企业更好地应用实时数据所分析出来的结果。</p>
<h5 id="5-流数据分析"><a href="#5-流数据分析" class="headerlink" title="5. 流数据分析"></a>5. 流数据分析</h5><p>实时计算各类<code>数据指标</code>，并利用<code>实时结果</code>及时调整在线系统<strong>相关策略</strong>，在各类内容投放、 无线智能推送领域有大量的应用。流式计算技术将数据分析场景实时化，帮助企业做到实时化分析 Web 应用或者 App 应用的各项指标，包括 App 版本分布情况、Crash 检测和分布等， 同时提供多维度用户行为分析，支持日志自主分析，助力开发者实现基于大数据技术的精细 化运营、提升产品质量和体验、增强用户黏性。</p>
<h5 id="6-实时报表分析"><a href="#6-实时报表分析" class="headerlink" title="6. 实时报表分析"></a>6. 实时报表分析</h5><p><code>实时报表分析</code>是近年来很多公司采用的报表统计方案之一，其中最主要的应用便是实时大屏展示。利用流式计算实时得出的结果直接被推送到前端应用，实时显示出重要指标的变 换情况。最典型的案例便是淘宝的<code>双十一活动</code>，每年双十一购物节，除疯狂购物外，最引人 注目的就是天猫双十一大屏不停跳跃的成交总额。在整个计算链路中包括从天猫交易下单购买到<code>数据采集</code>、<code>数据计算</code>、<code>数据校验</code>，最终落到双十一大屏上展现的全链路时间压缩在 5 秒以内，顶峰计算性能高达数<code>三十万笔订单/秒</code>，通过多条链路流计算备份确保<code>万无一失</code>。 而在其他行业，企业也在构建自己的实时报表系统，让企业能够依托于自身的业务数据，快 速提取出更多的数据价值，从而更好地服务于企业运行过程中。<br><img src="https://img-blog.csdnimg.cn/20200721102303696.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="4-Flink-的特点和优势"><a href="#4-Flink-的特点和优势" class="headerlink" title="4. Flink 的特点和优势"></a>4. Flink 的特点和优势</h3><p>Flink 的具体优势和特点有以下几点</p>
<h5 id="1-同时支持高吞吐、低延迟、高性能"><a href="#1-同时支持高吞吐、低延迟、高性能" class="headerlink" title="1. 同时支持高吞吐、低延迟、高性能"></a>1. 同时支持高吞吐、低延迟、高性能</h5><p>Flink 是目前开源社区中唯 一 一套集<code>高吞吐</code>、<code>低延迟</code>、<code>高性能</code>三者于一身的<code>分布式流式数据处理框架</code>。像 Apache Spark 也只能兼顾高吞吐和高性能特性，主要因为在 Spark Streaming 流式计算中无法做到低延迟保障；而流式计算框架 <code>Apache Storm</code> 只能支持低延迟和高性能特性，但是无法满足<strong>高吞吐</strong>的要求。而满足高吞吐、低延迟、高 性能这三个目标对分布式流式计算框架来说是非常重要的。</p>
<h5 id="2-支持事件时间（Event-Time）概念"><a href="#2-支持事件时间（Event-Time）概念" class="headerlink" title="2. 支持事件时间（Event Time）概念"></a>2. 支持事件时间（Event Time）概念</h5><p>在流式计算领域中，窗口计算的地位举足轻重，但目前大多数框架窗口计算采用的都是<code>系统时间</code>(Process Time)，也是事件传输到计算框架处理时，<strong>系统主机的当前时间</strong>。Flink 能够支持基于<code>事件时间</code>(Event Time)语义进行窗口计算，也就是使用事件产生的时间，这种基于事件驱动的机制使得事件即使乱序到达，流系统也能够计算出 确的结果，<strong>保持了事件原本产生时的时序性</strong>，尽可能避免网络传输或硬件系统的影响。</p>
<p><strong>Event Time/Processing Time/Ingestion Time，也就是事件时间、处理时间、提取时间，那么这三个时间有什么区别和联系</strong></p>
<p>下图是一个信号站，分别列出了事件时间、处理时间、提取时间的先后顺序。当然上面图示需要你对Flink有一个基本的了解。我们先白话解释，然后在官方解释。<br><img src="https://img-blog.csdnimg.cn/20200721103304536.png#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>Event Time：也就是事件发生的时间，事件的发生时间。我们有些同学可能会模糊，这里举个例子，我们<code>产生日志的时间</code>，这个应该清楚的，日志的时间戳就是<code>发生时间</code>。</li>
<li>Processing Time：也就是处理时间，我们看到了这个已经进入Flink程序，也就是我们读取数据源时间，也就是日志到达Flink的时间，但是这个时间是<code>本地机器的时间</code>。</li>
<li>Ingestion Time：也就是提取时间，我们看到它比处理时间还晚一些，这个时候数据已经发送给窗口，也就是<code>发送给窗口</code>的时间，也就是程序处理计算的时间。</li>
</ul>
<h5 id="3-支持有状态计算"><a href="#3-支持有状态计算" class="headerlink" title="3. 支持有状态计算"></a>3. 支持有状态计算</h5><p>Flink 在 1.4 版本中实现了<code>状态管理</code>，所谓状态就是<strong>在流式计算过程中将算子的中间结果数据保存在内存或者文件系统中，等下一个事件进入算子后可以从之前的状态中 获取中间结果中计算当前的结果</strong>，从而无须每次都基于全部的原始数据来统计结果，这 种方式极大地提升了<code>系统的性能</code>，并降低了数据计算过程的资源消耗。对于数据量大且运算逻辑非常复杂的流式计算场景，有状态计算发挥了非常重要的作用。</p>
<h5 id="4-支持高度灵活的窗口（Window）操作"><a href="#4-支持高度灵活的窗口（Window）操作" class="headerlink" title="4.支持高度灵活的窗口（Window）操作"></a>4.支持高度灵活的窗口（Window）操作</h5><p>在流处理应用中，数据是连续不断的，需要通过<code>窗口</code>的方式对流数据进行一定范围 的聚合计算，例如统计在过去的 1 分钟内有多少用户点击某一网页，在这种情况下，我 们必须定义一个窗口，用来收集最近一分钟内的数据，并对这个窗口内的数据进行再计 算。Flink 将窗口划分为基于 Time、Count、Session，以及 Data-driven 等类型的窗口 操作，<code>窗口</code>可以用灵活的触发条件定制化来达到对复杂的流传输模式的支持，用户可以 定义不同的窗口触发机制来满足不同的需求。</p>
<h5 id="5-基于轻量级分布式快照（CheckPoint）实现的容错"><a href="#5-基于轻量级分布式快照（CheckPoint）实现的容错" class="headerlink" title="5.基于轻量级分布式快照（CheckPoint）实现的容错"></a>5.基于轻量级分布式快照（CheckPoint）实现的容错</h5><p>Flink 能够分布式运行在<code>上千个节点</code>上，<code>将一个大型计算任务的流程拆解成小的计算过程</code>，然后将 tesk 分布到并行节点上进行处理。在任务执行过程中，能够自动发现事件处理过程中的错误而导致数据不一致的问题，比如：节点宕机、网路传输问题，或 是由于用户因为升级或修复问题而导致计算服务重启等。在这些情况下，通过基于分布 式快照技术的<code>Checkpoints</code>，将执行过程中的状态信息进行<code>持久化存储</code>，一旦任务出现异常停止，<code>Flink 就能够从 Checkpoints 中进行任务的自动恢复</code>，以确保数据在处理过 程中的精准一致性（<code>Exactly-Once</code>）。快照是默认自动开启实现的。</p>
<h5 id="6-基于-JVM-实现独立的内存管理"><a href="#6-基于-JVM-实现独立的内存管理" class="headerlink" title="6.基于 JVM 实现独立的内存管理"></a>6.基于 JVM 实现独立的内存管理</h5><p>内存管理是所有计算框架需要重点考虑的部分，尤其对于计算量比较大的计算场 景，数据在内存中该如何进行管理显得至关重要。针对内存管理，Flink 实现了<code>自身管理内存的机制</code>，尽可能减少 JVM GC 对系统的影响。另外，Flink 通过序列化/反序列化 方法将所有的数据对象转换成二进制在内存中存储，<code>降低数据存储的大小</code>的同时，能够<code>更加有效地对内存空间进行利用</code>，降低 GC 带来的性能下降或任务异常的风险，因此 Flink 较其他分布式处理的框架会显得更加稳定，不会因为 JVM GC 等问题而影响整个 应用的运行。</p>
<h5 id="7-Save-Points（保存点）"><a href="#7-Save-Points（保存点）" class="headerlink" title="7. Save Points（保存点）"></a>7. Save Points（保存点）</h5><p>对于 7*24 小时运行的流式应用，数据源源不断地接入，在一段时间内应用的终止有可能导致数据的丢失或者计算结果的不准确，例如进行集群版本的升级、停机运维操 作等操作。值得一提的是，Flink 通过 <code>SavePoints</code>技术将任务执行的快照保存在存储介质上，当任务重启的时候可以直接从事先保存的 Save Points 恢复原有的计算状态， 使得任务继续按照停机之前的状态运行，Save Points 技术可以让用户更好地管理和运 维实时流式应用。不过需要手动启动跟恢复数据。</p>
<h3 id="5-常见实时计算框架对比"><a href="#5-常见实时计算框架对比" class="headerlink" title="5. 常见实时计算框架对比"></a>5. 常见实时计算框架对比</h3><table>
<thead>
<tr>
<th>产品</th>
<th>模型</th>
<th>API</th>
<th>保证次数</th>
<th>容错机制</th>
<th>状态管理</th>
<th>延时</th>
<th>吞吐量</th>
</tr>
</thead>
<tbody><tr>
<td>Storm</td>
<td>Native(数据实时进入处理)</td>
<td>组合式(基础API)</td>
<td>At-least-once(至少一次)</td>
<td>Record ACK(ACK机制)</td>
<td>无</td>
<td>低</td>
<td>低</td>
</tr>
<tr>
<td>Trident</td>
<td>Micro-Batching(划分为小批次处理)</td>
<td>组合式</td>
<td>Exactly-once(精准一致性)</td>
<td>Record ACK</td>
<td>基于操作(每个操作都有一个状态)</td>
<td>中等</td>
<td>中等</td>
</tr>
<tr>
<td>Spark-Streaming</td>
<td>Micro-Batching</td>
<td>声明式(提供封装后的高阶函数，比如Count)</td>
<td>Exactly-once</td>
<td>RDD CheckPoint(基于RDD做CheckPoint)</td>
<td>基于DStream</td>
<td>中等</td>
<td>高</td>
</tr>
<tr>
<td>Flink</td>
<td>Native</td>
<td>声明式</td>
<td>Exactly-once</td>
<td>CheckPoint(Flink的一种快照)</td>
<td>基于操作</td>
<td>低</td>
<td>高</td>
</tr>
</tbody></table>
<ol>
<li><code>模型</code>：<br>Storm 和 Flink 是真正的一条一条处理数据；而 Trident（Storm 的封装框架） 和 Spark Streaming 其实都是<strong>小批处理</strong>，一次处理一批数据（小批量）。</li>
<li><code>API</code>：<br>Storm 和 Trident 都使用基础 API 进行开发，比如实现一个简单的 sum 求和操作； 而 Spark Streaming 和 Flink 中都<strong>提供封装后的高阶函数</strong>，可以直接拿来使用，这样就 比较方便了。</li>
<li><code>保证次数</code>：<br>在数据处理方面，Storm 可以实现至少处理一次，但不能保证仅处理一次， 这样就会导致数据<strong>重复处理</strong>问题，所以针对计数类的需求，可能会产生一些误差； Trident 通过<strong>事务</strong>可以保证对数据实现仅一次的处理，Spark Streaming 和 Flink 也是 如此。</li>
<li><code>容错机制</code>：<br>Storm和Trident可以通过<code>ACK</code>机制实现数据的容错机制，而Spark Streaming 和 Flink 可以通过 <code>CheckPoint</code> 机制实现容错机制。</li>
<li><code>状态管理</code>：<br>Storm 中没有实现状态管理，Spark Streaming 实现了基于 DStream 的状态 管理，而 Trident 和 Flink 实现了<strong>基于操作</strong>的状态管理。</li>
<li><code>延时</code>：<br>表示数据处理的延时情况，因此 Storm 和 Flink 接收到一条数据就处理一条数据， 其数据处理的延时性是很低的；而 Trident 和 Spark Streaming 都是小型批处理，它们 数据处理的延时性相对会偏高。</li>
<li><code>吞吐量</code>：<br>Storm 的吞吐量其实也不低，只是相对于其他几个框架而言较低；Trident 属于中等；而 Spark Streaming 和 Flink 的吞吐量是比较高的。<br><img src="https://img-blog.csdnimg.cn/20200713100821813.png#pic_center" alt="在这里插入图片描述"></li>
</ol>
<h1 id="2-Flink编程入门"><a href="#2-Flink编程入门" class="headerlink" title="2.Flink编程入门"></a>2.Flink编程入门</h1><h3 id="1-Flink-的开发环境"><a href="#1-Flink-的开发环境" class="headerlink" title="1. Flink 的开发环境"></a>1. Flink 的开发环境</h3><p>Flink 课程选择的是 Apache Flink 1.9.1 版本，是目前较的稳定版本，并且 兼容性比较好。<br>下载地址： <a href="https://flink.apache.org/zh/downloads.html" target="_blank" rel="noopener">https://flink.apache.org/zh/downloads.html</a></p>
<h5 id="1-开发工具"><a href="#1-开发工具" class="headerlink" title="1. 开发工具"></a>1. 开发工具</h5><p>先说明一下开发工具的问题。官方建议使用<code>IntelliJ IDEA</code>，因为它默认集成了 <code>Scala</code>和<code>Maven</code>环境，使用更加方便，当然使用 Eclipse 也是可以的。本文使用 IDEA。开发Flink 程序时，可以使用<code>Java</code>、<code>Python</code>或者<code>Scala</code>语言，本教程使用 Scala，因为 使用 Scala 实现函数式编程会比较简洁。</p>
<h5 id="2-配置依赖"><a href="#2-配置依赖" class="headerlink" title="2. 配置依赖"></a>2. 配置依赖</h5><p>开发 Flink 应用程序需要最低限度的 API 依赖。最低的依赖库包括：<code>flink-scala</code>和 <code>flink-streaming-scala</code>。大多数应用需要依赖特定的连接器或其他类库，例如 Kafka 的连 接器、TableAPI、CEP 库等。这些不是 Flink 核心依赖的一部分，因此必须作为依赖项手 动添加到应用程序中。</p>
<p>与其他运行用户自定义应用的大多数系统一样，Flink 中有两大类依赖类库</p>
<ul>
<li>Flink 核心依赖：<br>Flink 本身包含运行所需的一组类和依赖，比如协调、网络通讯、checkpoint、容错处理、API、算子(如窗口操作)、 资源管理等，这些类和依赖形成了 Flink 运行时的核心。当 Flink 应用启动时，这些依赖必须可用。<br>这些核心类和依赖被打包在 flink-dist jar 里。它们是 Flink lib 文件夹下的一部分，也是 Flink 基本容器镜像的一部分。 这些依赖类似 Java String 和 List 的核心类库(rt.jar, charsets.jar等)。<br>Flink 核心依赖不包含连接器和类库（如 CEP、SQL、ML 等），这样做的目的是默认情况下避免在类路径中具有过多的依赖项和类。 实际上，我们希望尽可能保持核心依赖足够精简，以保证一个较小的默认类路径，并且避免依赖冲突。</li>
<li>用户应用依赖：<br>是指特定的应用程序需要的类库，如连接器，formats等。用户应用代码和所需的连接器以及其他类库依赖通常被打包到 application jar 中。用户应用程序依赖项不需包括 Flink DataSet / DataStream API 以及运行时依赖项，因为它们已经是 Flink 核心依赖项的一部分。</li>
</ul>
<p>Flink官方依赖文档说明：<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/projectsetup/dependencies.html" target="_blank" rel="noopener">官方依赖入手</a></p>
<h3 id="2-WordCount演示"><a href="#2-WordCount演示" class="headerlink" title="2.WordCount演示"></a>2.WordCount演示</h3><p>添加pom依赖</p>
<pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0<span class="token punctuation">"</span></span>
         <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">"</span></span>
         <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>modelVersion</span><span class="token punctuation">></span></span>4.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>modelVersion</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.sowhat<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>Flink-Test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0-SNAPSHOT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-scala_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-streaming-scala_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token comment" spellcheck="true">&lt;!--    上述两个是核心依赖--></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.kafka<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>kafka-clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>0.11.0.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-filesystem_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.bahir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-redis_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.1.44<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-table-planner_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-table-api-scala-bridge_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-cep-scala_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>
            <span class="token comment" spellcheck="true">&lt;!-- 该插件用于将Scala代码编译成class文件 --></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.4.6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>
                        <span class="token comment" spellcheck="true">&lt;!-- 声明绑定到maven的compile阶段 --></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>

            <span class="token comment" spellcheck="true">&lt;!-- Java Compiler   https://blog.csdn.net/liupeifeng3514/article/details/80236077  --></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span> <span class="token comment" spellcheck="true">&lt;!-- 开始代码时指定的JDK版本--></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span> <span class="token comment" spellcheck="true">&lt;!-- 编译成.class 文件所需版本--></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>

            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span> 
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>!--</span> <span class="token attr-name">表示会出现一个无任何依赖的jar，还有一个包含所有依赖的jar</span> <span class="token attr-name">--</span> <span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">></span></span>
123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>注意事项</strong>: 所有这些 <a href="https://sowhat.blog.csdn.net/article/details/75349274" target="_blank" rel="noopener">依赖项</a> 的作用域都应该设置为 <code>provided</code> 。 这意味着需要这些依赖进行编译，但<code>不应</code>将它们打包到项目生成的应用程序jar文件中，因为这些依赖项是 Flink 的核心依赖，服务器运行环境在应用启动前已经是可用的状态了。</p>
<p>我们<strong>强烈建议保持这些依赖的作用域</strong>为 <code>provided</code>。 如果它们的作用域未设置为 provided ，则典型的情况是因为包含了 Flink 的核心依赖而导致生成的jar包变得过大。 最糟糕的情况是添加到应用程序的 Flink 核心依赖项与你自己的一些依赖项版本冲突（通常通过反向类加载来避免）。</p>
<p><code>IntelliJ 上的一些注意事项</code>: 为了可以让 Flink 应用在 IntelliJ IDEA 中运行，这些 Flink 核心依赖的作用域需要设置为 <code>compile</code> 而不是<code>provided</code> 。 <strong>否则 IntelliJ 不会添加这些依赖到 classpath</strong>，会导致应用运行时抛出 NoClassDefFountError 异常。为了避免声明这些依赖的作用域为 compile (因为我们不推荐这样做)， 上文给出的 Java 和 Scala 项目模板使用了一个小技巧：添加了一个 profile，仅当应用程序在 IntelliJ 中运行时该 profile 才会被激活， 然后将依赖作用域设置为 compile ，从而不影响应用 jar 包。</p>
<h5 id="1-流式接受数据"><a href="#1-流式接受数据" class="headerlink" title="1. 流式接受数据"></a>1. 流式接受数据</h5><p><code>案例需求</code>：采用 Netcat 数据源发送数据，使用 Flink 统计每个单词的数量。</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

<span class="token comment" spellcheck="true">/**
  * flink的流计算的WordCount
  */</span>
object FlinkStreamWordCount <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//1、初始化Flink流计算的环境</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//修改并行度</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//默认所有算子的并行度为1</span>
    <span class="token comment" spellcheck="true">//2、导入隐式转换</span>
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    <span class="token comment" spellcheck="true">//3、读取数据,读取sock流中的数据</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"IP"</span><span class="token punctuation">,</span> <span class="token number">8899</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//DataStream ==> spark 中Dstream</span>

    <span class="token comment" spellcheck="true">//4、转换和处理数据</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//分组算子  : 0 或者 1 代表下标。前面的DataStream[二元组] , 0代表单词 ，1代表单词出现的次数</span>
      <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//聚会累加算子</span>

    <span class="token comment" spellcheck="true">//5、打印结果</span>
    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"结果"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//6、启动流计算程序</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"wordcount"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122232425262728293031</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>找一个服务可以接受到的接口发送若干信息：</p>
<pre class="line-numbers language-bash"><code class="language-bash">$ nc -lk 8899
hadoop spark hive flink
flink sowhat liu spark
flink sowhat
---
结果<span class="token operator">></span> <span class="token punctuation">(</span>hive,1<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>spark,1<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>hadoop,1<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>flink,1<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>sowhat,1<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>spark,2<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>liu,1<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>flink,2<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>sowhat,2<span class="token punctuation">)</span>
结果<span class="token operator">></span> <span class="token punctuation">(</span>flink,3<span class="token punctuation">)</span>
123456789101112131415<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>PS：如果将代码中所有关于并行度的全部屏蔽掉，系统会自动的将全部CPU利用起来，然后利用Hash算法来将数据归类给不同的CPU核心来处理，结果可能如下：</p>
<pre class="line-numbers language-bash"><code class="language-bash">结果:1<span class="token operator">></span> <span class="token punctuation">(</span>hive,1<span class="token punctuation">)</span> // 表示第几个核给出的结果
结果:4<span class="token operator">></span> <span class="token punctuation">(</span>flink,1<span class="token punctuation">)</span>
结果:1<span class="token operator">></span> <span class="token punctuation">(</span>spark,1<span class="token punctuation">)</span>
结果:4<span class="token operator">></span> <span class="token punctuation">(</span>sohat,1<span class="token punctuation">)</span>
结果:1<span class="token operator">></span> <span class="token punctuation">(</span>hive,2<span class="token punctuation">)</span>
结果:2<span class="token operator">></span> <span class="token punctuation">(</span>node,1<span class="token punctuation">)</span>
结果:4<span class="token operator">></span> <span class="token punctuation">(</span>zookeeper,1<span class="token punctuation">)</span>
结果:3<span class="token operator">></span> <span class="token punctuation">(</span>manager,1<span class="token punctuation">)</span>
12345678<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="2-直接统计指定文件WordCount"><a href="#2-直接统计指定文件WordCount" class="headerlink" title="2. 直接统计指定文件WordCount"></a>2. 直接统计指定文件WordCount</h5><p><code>需求</code>：读取本地数据文件，统计文件中每个单词出现的次数。 根据需求，很明显是有界流（批计算），所以采用另外一个上下文环境：ExecutionEnvironment<br>在IDEA的<code>resources</code>目录下创建个<code>wc.txt</code> 文件内容如下：</p>
<pre><code>hello flink spark
hello spark
spark core flink stream
hello fink
1234</code></pre><p>批量统计代码如下：</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink

<span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span><span class="token punctuation">{</span>URL<span class="token punctuation">,</span> URLDecoder<span class="token punctuation">}</span>

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span><span class="token punctuation">{</span>DataSet<span class="token punctuation">,</span> ExecutionEnvironment<span class="token punctuation">,</span> _<span class="token punctuation">}</span>

<span class="token comment" spellcheck="true">/**
  * Flink的批计算案例
  */</span>
object BatchWordCount <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//初始化Flink批处理环境</span>
    val env<span class="token operator">:</span> ExecutionEnvironment <span class="token operator">=</span> ExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment

    val dataPath<span class="token operator">:</span> URL <span class="token operator">=</span> getClass<span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"/wc.txt"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//使用相对路径来得到完整的文件路径</span>
    var packagePath<span class="token operator">:</span> String <span class="token operator">=</span> dataPath<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">replaceAll</span><span class="token punctuation">(</span><span class="token string">"%20"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//解决路径中含有空格的情况</span>
    val str<span class="token operator">:</span>String <span class="token operator">=</span> URLDecoder<span class="token punctuation">.</span><span class="token function">decode</span><span class="token punctuation">(</span>packagePath<span class="token punctuation">,</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//解决路径包含中文的情况</span>
    <span class="token function">println</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//读数据</span>
    val data<span class="token operator">:</span> DataSet<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//DataSet ==> spark RDD</span>

    <span class="token comment" spellcheck="true">//计算并且打印结果</span>
    data<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">groupBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//分组算子  : 0 或者 1 代表下标。前面的DataStream[二元组] , 0代表单词 ，1代表单词出现的次数</span>
      <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122232425262728293031</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="3-Flink-的安装和部署"><a href="#3-Flink-的安装和部署" class="headerlink" title="3. Flink 的安装和部署"></a>3. Flink 的安装和部署</h1><p>Flink 的安装和部署主要分为本地（<code>单机</code>）模式和<code>集群</code>模式，其中本地模式只需直接解压就可以使用，不用修改任何参数，一般在做一些简单测试的时候使用。本地模式不再赘述。集群模式包含：</p>
<ol>
<li>Standalone</li>
<li>Flink on Yarn(重点)</li>
<li>Mesos</li>
<li>Docker</li>
<li>Kubernetes</li>
<li>AWS</li>
<li>Goole Compute Engine</li>
</ol>
<p>目前在企业中使用最多的是 <strong>Flink on Yarn</strong> 模式。本文主讲<code>Standalone</code> 和<code>Flink on Yarn</code>这两种模式。</p>
<h3 id="1-集群基本架构"><a href="#1-集群基本架构" class="headerlink" title="1. 集群基本架构"></a>1. 集群基本架构</h3><p>Flink 整个系统主要由两个组件组成，分别为 <code>JobManager</code> 和 <code>TaskManager</code>，Flink 架构也遵循<code>Master-Slave</code> 架构设计原则，JobManager 为 Master 节点，TaskManager 为 Worker （Slave）节点。所有组件之间的通信都是借助于 <code>Akka Framework</code>，包括任务的状态以及 Checkpoint 触发等信息。<br><img src="https://img-blog.csdnimg.cn/20200713141655879.png#pic_center" alt="在这里插入图片描述"></p>
<h5 id="1-Client-客户端"><a href="#1-Client-客户端" class="headerlink" title="1. Client 客户端"></a>1. Client 客户端</h5><p>客户端负责将任务提交到集群，与 <code>JobManager</code> 构建 <code>Akka</code>连接，然后将任务提交到 <code>JobManager</code>，通过和 <code>JobManager</code>之间进行交互获取任务执行状态。客户端提交任务可以采 用 <code>CLI 方式</code>或者通过使用 <code>Flink WebUI</code>提交，也可以在应用程序中指定<code>JobManager</code>的<code>RPC</code>网络端口构建 ExecutionEnvironment 提交 Flink 应用。</p>
<h5 id="2-JobManager"><a href="#2-JobManager" class="headerlink" title="2.JobManager"></a>2.JobManager</h5><p>JobManager <code>负责整个 Flink 集群任务的调度以及资源的管理</code>，从客户端中获取提交的 应用，然后根据集群中 TaskManager 上 TaskSlot 的使用情况，为提交的应用分配相应的 TaskSlots 资源并命令 TaskManger 启动从客户端中获取的应用。JobManager 相当于整个集 群的 Master 节点，且整个集群中有且仅有一个活跃的 JobManager，<code>负责整个集群的任务管 理和资源管理</code>。JobManager 和 TaskManager 之间通过 Actor System 进行通信，获取任务执 行的情况并通过 Actor System 将应用的任务执行情况发送给客户端。同时在任务执行过程 中，<code>Flink JobManager</code>会触发 <code>Checkpoints</code> 操作，每个<code>TaskManager</code> 节点收到 Checkpoint 触发指令后，完成 <code>Checkpoint</code>操作，所有的<code>Checkpoint</code>协调过程都是在 <code>Flink JobManager</code>中完成。当任务完成后，Flink 会将任务执行的信息反馈给客户端，并且释放掉 <code>TaskManager</code> 中的资源以供下一次提交任务使用。</p>
<h5 id="3-TaskManager"><a href="#3-TaskManager" class="headerlink" title="3. TaskManager"></a>3. TaskManager</h5><p>TaskManager 相当于整个集群的 Slave 节点，<strong>负责具体的任务执行和对应任务在每个节 点上的资源申请与管理</strong>。客户端通过将编写好的 Flink 应用编译打包，提交到 JobManager， 然后 JobManager 会根据已经注册在 JobManager 中 TaskManager 的资源情况，将任务分配给 有资源的 TaskManager 节点，然后启动并运行任务。TaskManager 从 JobManager 接收需要 部署的任务，然后使用 Slot 资源启动 Task，建立数据接入的网络连接，接收数据并开始数 据处理。同时 TaskManager 之间的数据交互都是通过数据流的方式进行的。 可以看出，Flink 的任务运行<code>其实是采用多线程的方式</code>，这和 MapReduce 多 JVM 进程的 方式有很大的区别<code>Fink 能够极大提高 CPU 使用效率</code>，在多个任务和 Task 之间通过 <code>TaskSlot</code>方式共享系统资源，<strong>每个 TaskManager 中通过管理多个 TaskSlot 资源池进行对资源进行有 效管理</strong>。</p>
<p><code>PS</code>：可以认为JobManager类似Hadoop中ApplicationMaster，然后一个机器就是一个TaskManager，一个TaskManager可以分解成若干个Flink基本工作单元<code>TaskSlot</code>。</p>
<h3 id="2-Standalone-集群安装和部署"><a href="#2-Standalone-集群安装和部署" class="headerlink" title="2. Standalone 集群安装和部署"></a>2. Standalone 集群安装和部署</h3><p>Standalone 是 Flink 的独立部署模式，它不依赖其他平台。在使用这种模式搭建 Flink 集群之前，需要先规划集群机器信息。在这里为了搭建一个标准的 Flink 集群，需要准备 3 台 Linux。<br><img src="https://img-blog.csdnimg.cn/20200713142222760.png#pic_center" alt="在这里插入图片描述"></p>
<ol>
<li>下载并解压文件到指定目录</li>
<li>修改配置文件<br>进入到 conf 目录下，编辑 flink-conf.yaml 配置文件</li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash">jobmanager.rpc.address: hadoop101

<span class="token comment" spellcheck="true"># The RPC port where the JobManager is reachable.</span>

jobmanager.rpc.port: 6123


<span class="token comment" spellcheck="true"># The heap size for the JobManager JVM</span>

jobmanager.heap.size: 1024m <span class="token comment" spellcheck="true"># JobManager 内存大小</span>

<span class="token comment" spellcheck="true"># The total process memory size for the TaskManager.</span>
<span class="token comment" spellcheck="true">#</span>
<span class="token comment" spellcheck="true"># Note this accounts for all memory usage within the TaskManager process, including JVM metaspace and other overhead.</span>

taskmanager.memory.process.size: 1024m <span class="token comment" spellcheck="true"># TaskManager初始化内存大小 </span>

<span class="token comment" spellcheck="true"># To exclude JVM metaspace and overhead, please, use total Flink memory size instead of 'taskmanager.memory.process.size'.</span>
<span class="token comment" spellcheck="true"># It is not recommended to set both 'taskmanager.memory.process.size' and Flink memory.</span>
<span class="token comment" spellcheck="true">#</span>
<span class="token comment" spellcheck="true"># taskmanager.memory.flink.size: 1280m</span>

<span class="token comment" spellcheck="true"># The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.</span>

taskmanager.numberOfTaskSlots: 3 <span class="token comment" spellcheck="true"># 每一个TaskManager 有几个TaskSlots</span>

<span class="token comment" spellcheck="true"># The parallelism used for programs that did not specify and other parallelism.</span>

parallelism.default: 1 <span class="token comment" spellcheck="true"># 默认并行度</span>
1234567891011121314151617181920212223242526272829<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>编辑slaves文件</li>
</ol>
<pre><code>vi slaves
hadoop101
hadoop102
hadoop103
1234</code></pre><ol>
<li>信息分发</li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop101 home<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># scp -r flink-1.9.1 root@hadoop102:`pwd`</span>
<span class="token punctuation">[</span>root@hadoop101 home<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># scp -r flink-1.9.1 root@hadoop103:`pwd`</span>
12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ol>
<li>主节点启动集群<br><img src="https://img-blog.csdnimg.cn/20200713143822269.png#pic_center" alt="在这里插入图片描述"></li>
<li>WebUI 访问<br><code>flink-conf.yaml</code>的配置文件中<code>rest.port</code>是WebUI的对外端口，服务器输入<code>hadoop101:8081</code>即可访问(我这里随便找个别人搭建看的集群看下WebUI)。<br><img src="https://img-blog.csdnimg.cn/20200713144415670.png#pic_center" alt="在这里插入图片描述"><br>左侧栏多点点看看即可，相对来说比较简单。</li>
<li>将IDEA代码中的两个Flink核心依赖设置为<code>provided</code>然后打包(<strong>打包的时候经常性出现问题需检查</strong>)通过WebUI上传。<br><img src="https://img-blog.csdnimg.cn/20200713151105102.png#pic_center" alt="在这里插入图片描述"><br>测试结果如下：</li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop101 home<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#  nc -lk 8899</span>
12 21 21
12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/20200713162651693.png#pic_center" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20200713162743635.png#pic_center" alt="在这里插入图片描述"><br><code>PS</code>：<strong>敲重点 IDEA中用到的Flink-scala核心依赖要跟服务器集群的核心依赖版本</strong><code>一致</code>，否则会 <a href="https://www.jianshu.com/p/91bb14306100" target="_blank" rel="noopener">报错</a>！</p>
<blockquote>
<p>java.lang.NoSuchMethodError: scala.Predef$.refArrayOps</p>
</blockquote>
<ol>
<li>命令行提交<br><a href="https://blog.csdn.net/Dax1n/article/details/72885035" target="_blank" rel="noopener">命令行提交</a> flink同样支持两种提交方式，默认不指定就是客户端方式。如果需要使用集群方式提交的话。可以在提交作业的命令行中指定-d或者–detached 进行进群模式提交。</li>
</ol>
<blockquote>
<p>-d,–detached If present, runs the job in detached mode（分离模式）</p>
</blockquote>
<pre class="line-numbers language-bash"><code class="language-bash">客户端提交方式：<span class="token variable">$FLINK_HOME</span>/bin/flink run   -c com.daxin.batch.App flinkwordcount.jar 
客户端会多出来一个CliFrontend进程，就是驱动进程。
集群模式提交：<span class="token variable">$FLINK_HOME</span>/bin/flink run -d  -c com.daxin.batch.App flinkwordcount.jar 
程序提交完毕退出客户端，不再打印作业进度等信息！
1234<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>重要参数说明：下面针对 flink-conf.yaml 文件中的几个重要参数进行分析：</li>
</ol>
<ul>
<li>jobmanager.heap.size：JobManager 节点可用的内存大小。</li>
<li>taskmanager.heap.size：TaskManager 节点可用的内存大小。</li>
<li>taskmanager.numberOfTaskSlots：每台机器可用的 Slot 数量。</li>
<li>parallelism.default：默认情况下 Flink 任务的并行度。</li>
</ul>
<p>上面参数中所说的 <code>Slot</code>和 <code>parallelism</code>的区别：</p>
<ul>
<li>Slot 是静态的概念，是指 TaskManager 具有的并发执行能力。</li>
<li>parallelism 是动态的概念，是指程序运行时实际使用的并发能力。</li>
<li>设置合适的 parallelism 能提高运算效率。</li>
<li>比如我又4个跑道(Slot )，本次任务我占用2个(parallelism)。 一般情况下Slot <code>&gt;=</code> parallelism</li>
</ul>
<h3 id="3-Flink-提交到-Yarn"><a href="#3-Flink-提交到-Yarn" class="headerlink" title="3. Flink 提交到 Yarn"></a>3. Flink 提交到 Yarn</h3><p>Flink on Yarn 模式的原理是<code>依靠 YARN 来调度 Flink 任务</code>，目前在企业中使用<strong>较多</strong>。 这种模式的好处是可以充分利用集群资源，提高集群机器的利用率，并且只需要 1 套 Hadoop 集群，就可以执行 MapReduce 和 Spark 任务，还可以执行 Flink 任务等，操作非常方便，不 需要维护多套集群，运维方面也很轻松。Flink on Yarn 模式需要依赖 Hadoop 集群，并且 Hadoop 的版本需要是 2.2 及以上。本文选择的 Hadoop 版本是 2.7.2。</p>
<p>Flink On Yarn 的内部实现原理(Snagit Editor绘制)：<br><img src="https://img-blog.csdnimg.cn/20200712212850155.png#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>当启动一个新的 Flink YARN Client 会话时，客户端首先会检查所请求的资源（容器和内存）是否可用。之后，它会上传 Flink 配置和 JAR 文件到 HDFS。</li>
<li>客 户 端 的 下 一 步 是 请 求 一 个 YARN 容 器 启 动 ApplicationMaster 。 JobManager 和 ApplicationMaster(AM)运行在同一个容器中，一旦它们成功地启动了，AM 就能够知道 JobManager 的地址，它会为 TaskManager 生成一个新的 Flink 配置文件（这样它才能连 上 JobManager），该文件也同样会被上传到 HDFS。另外，AM 容器还提供了 Flink 的 Web 界面服务。Flink 用来提供服务的端口是由用户和应用程序 ID 作为偏移配置的，这 使得用户能够并行执行多个 YARN 会话。</li>
<li>之后，AM 开始为 Flink 的 TaskManager 分配容器（Container），从 HDFS 下载 JAR 文件 和修改过的配置文件。一旦这些步骤完成了，Flink 就安装完成并准备接受任务了</li>
</ul>
<p>Flink on Yarn 模式在使用的时候又可以分为<code>两种</code>：</p>
<h5 id="第-1-种模式-Session-Cluster-："><a href="#第-1-种模式-Session-Cluster-：" class="headerlink" title="第 1 种模式(Session-Cluster)："></a>第 1 种模式(Session-Cluster)：</h5><p>是在 YARN 中<code>提前</code>初始化一个 Flink 集群(称为 Flink yarn-session)，开辟指定的资源，以后的 Flink 任务都提交到这里。这个 Flink 集群会<code>常驻</code>在 YARN 集群中，除非手工停止。这种方式创建的 Flink 集群会<code>独占资源</code>，不管有没有 Flink 任务在执行，YARN 上面的其他任务都无法使用这些资源。一般此种方式用的较少。<br><img src="https://img-blog.csdnimg.cn/20200713165033200.png#pic_center" alt="在这里插入图片描述"></p>
<h5 id="第-2-种模式-Per-Job-Cluster-："><a href="#第-2-种模式-Per-Job-Cluster-：" class="headerlink" title="第 2 种模式(Per-Job-Cluster)："></a>第 2 种模式(Per-Job-Cluster)：</h5><p><strong>每次提交 Flink 任务都会创建一个新的 Flink 集群</strong>， 每个 Flink 任务之间相互独立、互不影响，管理方便。任务执行完成之后创建的 Flink 集群也会消失，不会额外占用资源，按需使用，这使资源利用率达到最大，<strong>在工作中推荐使用这种模式</strong>。<br><img src="https://img-blog.csdnimg.cn/20200713165343219.png#pic_center" alt="在这里插入图片描述"><br><code>注意</code>：Flink on Yarn 还需要两个先决条件：</p>
<ol>
<li>配置 Hadoop 的环境变量</li>
<li><a href="https://flink.apache.org/zh/downloads.html" target="_blank" rel="noopener">下载</a> Flink 提交到 Hadoop 的连接器(jar 包 大约40M)，并把 jar 拷贝到 Flink 的 lib 目录下<img src="https://img-blog.csdnimg.cn/20200713165601842.png#pic_center" alt="在这里插入图片描述"></li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop101 flink-1.9.1<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cp  /home/flink-shaded-hadoop-2-uber-2.7.5-7.0.jar   lib/</span>
1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="启动第一种-Session-Cluster-模式（yarn-session）"><a href="#启动第一种-Session-Cluster-模式（yarn-session）" class="headerlink" title="启动第一种 Session-Cluster 模式（yarn-session）"></a>启动第一种 Session-Cluster 模式（yarn-session）</h3><p>1 先启动 Hadoop 集群，然后通过命令启动一个 Flink 的 yarn-session 集群：</p>
<pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop101 flink-1.9.1<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># bin/yarn-session.sh -n 3 -s 3 -nm sowhat -d </span>
1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>其中 yarn-session.sh 后面支持多个参数。下面针对一些常见的参数进行讲解：</p>
<ol>
<li>-n、–container 表示分配容器的数量（也就是 TaskManager 的数量）。</li>
<li>-D 动态属性。</li>
<li>-d、–detached 在后台独立运行。</li>
<li>-jm、–jobManagerMemory ：设置 JobManager 的内存，单位是 MB。</li>
<li>-nm、–name：在 YARN 上为一个自定义的应用设置一个名字。</li>
<li>-q、–query：显示 YARN 中可用的资源（内存、cpu 核数）。</li>
<li>-qu、–queue ：指定 YARN 队列。</li>
<li>-s、–slots ：每个 TaskManager 使用的 Slot 数量。</li>
<li>-tm、–taskManagerMemory ：每个 TaskManager 的内存，单位是 MB。</li>
<li>-z、–zookeeperNamespace ：针对 HA 模式在 ZooKeeper 上创建 NameSpace。</li>
<li>-id、–applicationId ：指定 YARN 集群上的任务 ID，附着到一个后台独 立运行的 yarn session 中。<br><img src="https://img-blog.csdnimg.cn/20200713170654200.png#pic_center" alt="在这里插入图片描述"><br>查看 WebUI: 由于还没有提交 Flink job，所以都是 0。<br><img src="https://img-blog.csdnimg.cn/20200713170554981.png#pic_center" alt="在这里插入图片描述"><br><strong>这个时候注意查看本地文件系统中有一个临时文件</strong>。有了这个文件可以提交 job 到 Yarn<br><img src="https://img-blog.csdnimg.cn/20200713170722129.png#pic_center" alt="在这里插入图片描述"><br>提交 Job : 由于有了之前的配置，所以自动会提交到 Yarn 中。</li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash">bin/flink run -c com.bjsxt.flink.StreamWordCount /home/Flink-Demo-1.0-SNAPSHOT.jar
1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/20200713170816557.png#pic_center" alt="在这里插入图片描述"><br>至此第一种模式全部完成。</p>
<h3 id="启动第二种模式"><a href="#启动第二种模式" class="headerlink" title="启动第二种模式"></a>启动第二种模式</h3><p>这种模式下<strong>不需要</strong>先启动 yarn-session。所以我们可以把前面启动的 yarn-session 集 群先停止，停止的命令是:</p>
<pre class="line-numbers language-bash"><code class="language-bash">yarn application -kill application_1576832892572_0002 //其中 application_1576832892572_0002 是ID
1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>确保 Hadoop 集群是健康的情况下直接提交 Job 命令：</p>
<pre class="line-numbers language-bash"><code class="language-bash">bin/flink run -m yarn-cluster -yn 3 -ys 3 -ynm sowhat02 \
-c com.sowhat.flink.StreamWordCount /home/Flink-Demo-1.0-SNAPSHOT.jar
12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>可以看到一个全新的 yarn-session<br><img src="https://img-blog.csdnimg.cn/2020071317130741.png#pic_center" alt="在这里插入图片描述"><br>任务提交参数讲解：相对于 Yarn-Session 参数而言，只是前面加了 y。</p>
<ol>
<li>-yn、–container 表示分配容器的数量，也就是 TaskManager 的数量。</li>
<li>-d、–detached：设置在后台运行。</li>
<li>-yjm、–jobManagerMemory:设置 JobManager 的内存，单位是 MB。</li>
<li>-ytm、–taskManagerMemory:设置每个 TaskManager 的内存，单位是 MB。</li>
<li>-ynm、–name:给当前 Flink application 在 Yarn 上指定名称。</li>
<li>-yq、–query：显示 yarn 中可用的资源（内存、cpu 核数）</li>
<li>-yqu、–queue :指定 yarn 资源队列</li>
<li>-ys、–slots :每个 TaskManager 使用的 Slot 数量。</li>
<li>-yz、–zookeeperNamespace:针对 HA 模式在 Zookeeper 上创建 NameSpace</li>
<li>-yid、–applicationID : 指定 Yarn 集群上的任务 ID,附着到一个后台独 立运行的 Yarn Session 中。</li>
</ol>
<h3 id="4-Flink-的HA"><a href="#4-Flink-的HA" class="headerlink" title="4. Flink 的HA"></a>4. Flink 的HA</h3><p>默认情况下，每个 Flink 集群<strong>只有一个 JobManager</strong>，这将导致单点故障（<code>SPOF</code>），如 果这个 JobManager 挂了，则不能提交新的任务，并且运行中的程序也会失败。使用 JobManager HA，集群可以从 JobManager 故障中恢复，从而避免单点故障。用户可以在 <code>Standalone</code>或<code>Flink on Yarn</code> 集群模式下配置 Flink 集群 HA（高可用性）。</p>
<h5 id="Standalone-HA"><a href="#Standalone-HA" class="headerlink" title="Standalone HA"></a>Standalone HA</h5><p>Standalone 模式下，JobManager 的高可用性的基本思想是，任何时候都有一个 Alive JobManager 和多个 Standby JobManager。Standby JobManager 可以在 Alive JobManager 挂掉的情况下接管集群成为 Alive JobManager，这样避免了单点故障，一旦某一个 Standby JobManager 接管集群，程序就可以继续运行。Standby JobManagers 和 Alive JobManager 实例之间<strong>没有明确区别</strong>，每个 JobManager 都可以成为 Alive 或 Standby<img src="https://img-blog.csdnimg.cn/20200713172223651.png#pic_center" alt="在这里插入图片描述"><br>Flink Standalone 集群的 HA 安装和配置<br>实现 HA 还需要依赖 ZooKeeper 和 HDFS，因此要有一个 ZooKeeper 集群和 Hadoop 集群， 首先启动 Zookeeper 集群和 HDFS 集群。本文中分配 3 台 JobManager，如下表：</p>
<table>
<thead>
<tr>
<th>hadoop101</th>
<th>hadoop102</th>
<th>hadoop103</th>
</tr>
</thead>
<tbody><tr>
<td>JobManager</td>
<td>JobManager</td>
<td>JobManager</td>
</tr>
<tr>
<td>TaskManager</td>
<td>TaskManager</td>
<td>TaskManager</td>
</tr>
</tbody></table>
<ol>
<li>修改配置文件 conf/masters</li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash">hadoop101:8081
hadoop102:8081
hadoop103:8081
123<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>修改配置文件 conf/flink-conf.yaml</li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#要启用高可用，设置修改为zookeeper</span>
 high-availability: zookeeper 
<span class="token comment" spellcheck="true">#Zookeeper的主机名和端口信息，多个参数之间用逗号隔开</span>
high-availability.zookeeper.quorum: hadoop103:2181,hadoop101:2181,hadoop102:2181 
<span class="token comment" spellcheck="true"># 建议指定HDFS的全路径。如果某个Flink节点没有配置HDFS的话，不指定HDFS的全路径 则无法识到，</span>
<span class="token comment" spellcheck="true"># storageDir存储了恢复一个JobManager所需的所有元数据。</span>
high-availability.storageDir: hdfs://hadoop101:9000/flink/h
1234567<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>把修改的配置文件拷贝其他服务器中</li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop101 conf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># scp masters flink-conf.yaml root@hadoop102:`pwd` </span>
<span class="token punctuation">[</span>root@hadoop101 conf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># scp masters flink-conf.yaml root@hadoop103:`pwd`</span>
12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ol>
<li>启动集群<br><img src="https://img-blog.csdnimg.cn/20200713172811146.png#pic_center" alt="在这里插入图片描述"><br>版本问题：目前使用 Flink1.7.1 版本测试没有问题，使用 Flink1.9 版本存在 HA 界面不能自动跳转到对应的 Alive jobManager。</li>
</ol>
<h5 id="Flink-On-Yarn-HA"><a href="#Flink-On-Yarn-HA" class="headerlink" title="Flink On Yarn HA"></a>Flink On Yarn HA</h5><p>正常基于 Yarn 提交 Flink 程序，无论是使用 <code>yarn-session</code> 模式还是 <code>yarn-cluster</code>模 式 ， 基 于 yarn 运 行 后 的 application 只 要 kill 掉 对 应 的 Flink 集 群 进 程<code>YarnSessionClusterEntrypoint</code>后，基于 Yarn 的 Flink 任务就失败了，<code>不会</code>自动进行重试，所以基于 Yarn 运行 Flink 任务，也有必要搭建 HA，这里同样还是需要借助 zookeeper 来完成，步骤如下：</p>
<ol>
<li>修改所有 Hadoop 节点的 yarn-site.xml 将所有 Hadoop 节点的 yarn-site.xml 中的提交应用程序最大尝试次数调大</li>
</ol>
<pre class="line-numbers language-xml"><code class="language-xml">#在每台hadoop节点yarn-site.xml中设置提交应用程序的最大尝试次数，建议不低于4，
# 这里重试指的ApplicationMaster 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.am.max-attempts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
123456<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>启动 zookeeper，启动 Hadoop 集群</li>
<li>修改 Flink 对应 flink-conf.yaml 配置，配置内容如下：</li>
</ol>
<pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#配置依赖zookeeper模式进行HA搭建 </span>
high-availability: zookeeper 
<span class="token comment" spellcheck="true">#配置JobManager原数据存储路径 high-availability.storageDir: hdfs://hadoop101:9000/flink/yarnha/ </span>
<span class="token comment" spellcheck="true">#配置zookeeper集群节点 </span>
high-availability.zookeeper.quorum: hadoop101:2181,hadoop102:2181,hadoop103:2181 
<span class="token comment" spellcheck="true">#yarn停止一个application重试的次数 </span>
yarn.application-attempts: 10
1234567<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>启动 yarn-session.sh 测试 HA： yarn-session.sh -n 2 ，也可以直接提交 Job 启动之后，可以登录 yarn 中对应的 flink WebUI，如下图示：<img src="https://img-blog.csdnimg.cn/20200713174155511.png#pic_center" alt="在这里插入图片描述"></li>
<li>点击对应的 Tracking UI，进入 Flink 集群 UI<br><img src="https://img-blog.csdnimg.cn/20200713174255954.png#pic_center" alt="在这里插入图片描述"><br>查看对应的 JobManager 在哪台节点上启动：<img src="https://img-blog.csdnimg.cn/20200713174342414.png#pic_center" alt="在这里插入图片描述"><br>进入对应的节点，kill 掉对应的<code>YarnSessionClusterEntrypoint</code>进程。然后进入到 Yarn 中观察<code>applicationxxxx_0001</code>job 信息：<img src="https://img-blog.csdnimg.cn/20200713174452942.png#pic_center" alt="在这里插入图片描述"><br>点击 job ID,发现会有对应的重试信息：<img src="https://img-blog.csdnimg.cn/20200713174527546.png#pic_center" alt="在这里插入图片描述"><br>点击对应的<code>Tracking U</code>进入到 Flink 集群 UI，查看新的 JobManager 节点由原来的 hadoop103 变成了 hadoop101，说明 HA 起作用。<img src="https://img-blog.csdnimg.cn/20200713174555148.png#pic_center" alt="在这里插入图片描述"></li>
</ol>
<h1 id="4-Flink-并行度和-Slot"><a href="#4-Flink-并行度和-Slot" class="headerlink" title="4. Flink 并行度和 Slot"></a>4. Flink 并行度和 Slot</h1><p>Flink中每一个worker(TaskManager)都是一个JVM进程，它可能会在独立的线程（Solt） 上执行一个或多个 subtask。Flink 的每个 TaskManager 为集群提供 Solt。<strong>Solt 的数量通常 与每个 TaskManager 节点的可用 CPU 内核数成比例</strong>，<code>一般情况下 Slot 的数量就是每个节点 的 CPU 的核数</code>。 Slot 的 数 量 由 集 群 中 flink-conf.yaml 配 置 文 件 中 设 置 taskmanager.numberOfTaskSlots，这个值的大小<code>建议</code>和节点 CPU 的数量保持一致。比如我设置=3。<br><code>并行度</code>=2的情况下：<br><img src="https://img-blog.csdnimg.cn/20200713175851646.png#pic_center" alt="在这里插入图片描述"><br>注意一点：一个TaskSlot可能执行多个job。</p>
<p>一个任务的并行度设置可以从 4 个层面指定:</p>
<ol>
<li>Operator Level（算子层面）。</li>
<li>Execution Environment Level（执行环境层面）。</li>
<li>Client Level（客户端层面）。</li>
<li>System Level（系统层面）。</li>
</ol>
<p>这 些 并 行 度 的 优 先 级 为 ：<br>Operator Level <code>&gt;</code>Execution Environment Level <code>&gt;</code> Client Level <code>&gt;</code> System Level。</p>
<h5 id="1-并行度设置之-Operator-Level"><a href="#1-并行度设置之-Operator-Level" class="headerlink" title="1. 并行度设置之 Operator Level"></a>1. 并行度设置之 Operator Level</h5><p>Operator、Source 和 Sink 目的地的并行度可以通过调用 <code>setParallelism()</code>方法来指定</p>
<pre class="line-numbers language-java"><code class="language-java">    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//分组算子  : 0 或者 1 代表下标。前面的DataStream[二元组] , 0代表单词 ，1代表单词出现的次数</span>
     <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//聚会累加算子</span>
      <span class="token comment" spellcheck="true">//5、打印结果</span>
   result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"结果"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token number">123456</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="2-并行度设置之-Execution-Environment-Level"><a href="#2-并行度设置之-Execution-Environment-Level" class="headerlink" title="2. 并行度设置之 Execution Environment Level"></a>2. 并行度设置之 Execution Environment Level</h5><p>任务的默认并行度可以通过调用 <code>setParallelism()</code>方法指定。为了以并行度 3 来执行 <code>所有</code>的 Operator、Source 和 Sink，可以通过如下方式设置执行环境的并行度</p>
<pre class="line-numbers language-java"><code class="language-java">    <span class="token comment" spellcheck="true">//1、初始化Flink流计算的环境</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//修改并行度</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//默认所有算子的并行度为3</span>
<span class="token number">1234</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="3-并行度设置之-Client-Level"><a href="#3-并行度设置之-Client-Level" class="headerlink" title="3. 并行度设置之 Client Level"></a>3. 并行度设置之 Client Level</h5><p>并行度还可以在客户端提交 Job 到 Flink 时设定。对于 CLI 客户端，可以通过-p 参数指定并行度。</p>
<pre class="line-numbers language-bash"><code class="language-bash">bin/flink run -p 10  WordCount.jar
1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h5 id="4-并行度设置之-System-Level"><a href="#4-并行度设置之-System-Level" class="headerlink" title="4. 并行度设置之 System Level"></a>4. 并行度设置之 System Level</h5><p>在系统级可以通过设置flink-conf.yaml文件中的parallelism.default属性来指定所 有执行环境的默认并行度。</p>
<pre class="line-numbers language-xml"><code class="language-xml"># The parallelism used for programs that did not specify and other parallelism.
parallelism.default: 1
12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h5 id="5-并行度案例分析"><a href="#5-并行度案例分析" class="headerlink" title="5. 并行度案例分析"></a>5. 并行度案例分析</h5><p>Flink 集群中有 3 个 TaskManager 节点，每个 TaskManager 的 Slot 数量为 3<br><img src="https://img-blog.csdnimg.cn/2020071318385934.png#pic_center" alt="在这里插入图片描述"><br>全部默认情况下：<br><img src="https://img-blog.csdnimg.cn/2020071318404774.png#pic_center" alt="在这里插入图片描述"><br>全局并行度=2<br><img src="https://img-blog.csdnimg.cn/20200713184201354.png#pic_center" alt="在这里插入图片描述"><br><code>End</code>：牢记并行度设置的优先级，根据集群配置合理设置参数。</p>
<h1 id="4-Flink-常用API详解"><a href="#4-Flink-常用API详解" class="headerlink" title="4. Flink 常用API详解"></a>4. Flink 常用API详解</h1><h3 id="1-函数阶层"><a href="#1-函数阶层" class="headerlink" title="1. 函数阶层"></a>1. 函数阶层</h3><p>Flink 根据抽象程度分层，提供了三种不同的 API 和库。每一种 API 在简洁性和表达力上有着不同的侧重，并且针对不同的应用场景。<img src="https://img-blog.csdnimg.cn/20200713190046742.png#pic_center" alt="在这里插入图片描述"></p>
<ol>
<li><code>ProcessFunction</code><br>ProcessFunction 是 Flink 所提供<code>最底层接口</code>。ProcessFunction 可以处理一或两条 输入数据流中的单个事件或者归入一个特定窗口内的多个事件。它提供了对于时间和状态的细粒度控制。开发者可以在其中任意地修改状态，也能够注册定时器用以在未来的 某一时刻触发回调函数。因此，你可以利用 ProcessFunction 实现许多有状态的事件 驱动应用所需要的基于单个事件的复杂业务逻辑。</li>
<li><code>DataStream API</code><br>DataStream API 为许多通用的流处理操作提供了<strong>处理原语</strong>。这些操作包括窗口、逐条 记录的转换操作，在处理事件时进行外部数据库查询等。DataStream API 支持 Java 和 Scala 语言，预先定义了例如<code>map()</code>、<code>reduce()</code>、<code>aggregate()</code> 等函数。你可以通过扩 展实现预定义接口或使用 Java、Scala 的 lambda 表达式实现自定义的函数。</li>
<li><code>SQL &amp; Table API</code>：<br>Flink 支持两种关系型的 API，Table API 和 SQL。这两个 API 都是<code>批处理</code>和<code>流处理</code>统一的 API，这意味着在无边界的实时数据流和有边界的历史记录数据流上，关系型 API 会以相同的语义执行查询，并产生相同的结果。Table API 和 SQL 借助了 Apache Calcite 来进行查询的解析，校验以及优化。它们可以与 DataStream 和 DataSet API 无缝集成，并支持用户自定义的标量函数，聚合函数以及表值函数。</li>
</ol>
<p>另外 Flink 具有数个适用于常见数据处理应用场景的<strong>扩展库</strong>。</p>
<ol>
<li><code>复杂事件处理(CEP)</code>：<br>模式检测是事件流处理中的一个非常常见的用例。Flink 的 CEP 库提供了 API，使用户能够以例如正则表达式或状态机的方式指定事件模式。CEP 库与 Flink 的 DataStream API 集成，以便在 DataStream 上评估模式。CEP 库的应用包括 网络入侵检测，业务流程监控和欺诈检测。</li>
<li><code>DataSet API</code>：<br>DataSet API 是 Flink 用于<code>批处理</code>应用程序的核心 API。DataSet API 所提供的基础算子包括 map、reduce、(outer) join、co-group、iterate 等。所有算子都有相应的算法和数据结构支持，对内存中的序列化数据进行操作。如果数据大小超过预留内存，则过量数据将存储到磁盘。Flink 的 DataSet API 的数据处理算法借鉴了传统数据库算法的实现，例如混合散列连接（hybrid hash-join）和外部归并排序 （external merge-sort）。</li>
<li><code>Gelly</code>:<br>Gelly 是一个可扩展的图形处理和分析库。Gelly 是在 DataSet API 之上实现 的，并与 DataSet API 集成。因此，它能够受益于其可扩展且健壮的操作符。Gelly 提 供了内置算法，如 label propagation、triangle enumeration 和 PageRank 算法， 也提供了一个简化自定义图算法实现的 Graph API。</li>
</ol>
<h3 id="2-DataStream-的编程模型"><a href="#2-DataStream-的编程模型" class="headerlink" title="2. DataStream 的编程模型"></a>2. DataStream 的编程模型</h3><p>DataStream 的编程模型包括<code>四</code>个部分：<code>Environment</code>，<code>DataSource</code>，<code>Transformation</code>，<code>Sink</code>。<code>此乃重点</code>，接下来主要按照这四部分讲解。<br><img src="https://img-blog.csdnimg.cn/20200713190722337.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="3-Flink-的-DataSource-数据源"><a href="#3-Flink-的-DataSource-数据源" class="headerlink" title="3. Flink 的 DataSource 数据源"></a>3. Flink 的 DataSource 数据源</h3><p>基于文件、基于集合、基于Kafka、自定义的DataSource</p>
<h5 id="1-基于文件的Source"><a href="#1-基于文件的Source" class="headerlink" title="1. 基于文件的Source"></a>1. 基于文件的Source</h5><p>读取本地文件系统的数据，前面的案例已经讲过了。本课程主要讲基于<code>HDFS</code>文件系统的 Source。首先需要配置 Hadoop 的依赖</p>
<pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
12345678910<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>代码：</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

object HDFSFileSource <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//1、初始化Flink流计算的环境</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//修改并行度</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//默认所有算子的并行度为1</span>
    <span class="token comment" spellcheck="true">//2、导入隐式转换</span>
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    <span class="token comment" spellcheck="true">//读取HDFS文件系统上的文件</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop101:9000/wc.txt"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//单词统计的计算</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//定义sink</span>
    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"wordcount"</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">123456789101112131415161718192021222324252627282930</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="2-基于集合的Source"><a href="#2-基于集合的Source" class="headerlink" title="2. 基于集合的Source"></a>2. 基于集合的Source</h5><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

<span class="token comment" spellcheck="true">/**
  * 基站日志
  * @param sid      基站的id
  * @param callOut  主叫号码
  * @param callInt  被叫号码
  * @param callType 呼叫类型
  * @param callTime 呼叫时间 (毫秒)
  * @param duration 通话时长 （秒）
  */</span>
<span class="token keyword">case</span> <span class="token keyword">class</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span>sid<span class="token operator">:</span> String<span class="token punctuation">,</span> var callOut<span class="token operator">:</span> String<span class="token punctuation">,</span> var callInt<span class="token operator">:</span> String<span class="token punctuation">,</span> callType<span class="token operator">:</span> String<span class="token punctuation">,</span> callTime<span class="token operator">:</span> Long<span class="token punctuation">,</span> duration<span class="token operator">:</span> Long<span class="token punctuation">)</span>

object CollectionSource <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//1、初始化Flink流计算的环境</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//修改并行度</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//默认所有算子的并行度为1</span>
    <span class="token comment" spellcheck="true">//2、导入隐式转换</span>
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromCollection</span><span class="token punctuation">(</span><span class="token function">Array</span><span class="token punctuation">(</span>
      <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token string">"001"</span><span class="token punctuation">,</span> <span class="token string">"1866"</span><span class="token punctuation">,</span> <span class="token string">"189"</span><span class="token punctuation">,</span> <span class="token string">"busy"</span><span class="token punctuation">,</span> System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token string">"002"</span><span class="token punctuation">,</span> <span class="token string">"1866"</span><span class="token punctuation">,</span> <span class="token string">"188"</span><span class="token punctuation">,</span> <span class="token string">"busy"</span><span class="token punctuation">,</span> System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token string">"004"</span><span class="token punctuation">,</span> <span class="token string">"1876"</span><span class="token punctuation">,</span> <span class="token string">"183"</span><span class="token punctuation">,</span> <span class="token string">"busy"</span><span class="token punctuation">,</span> System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token string">"005"</span><span class="token punctuation">,</span> <span class="token string">"1856"</span><span class="token punctuation">,</span> <span class="token string">"186"</span><span class="token punctuation">,</span> <span class="token string">"success"</span><span class="token punctuation">,</span> System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span>

    stream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="3-基于Kafka的Source"><a href="#3-基于Kafka的Source" class="headerlink" title="3. 基于Kafka的Source"></a>3. 基于Kafka的Source</h5><p>首 先 需 要 配 置 Kafka 连 接 器 的 依 赖 ， 另 外 更 多 的 连 接 器 可 以 查 看 官 网 ：<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/connectors/" target="_blank" rel="noopener">连接器</a></p>
<pre class="line-numbers language-xml"><code class="language-xml">   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.kafka<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>kafka-clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>0.11.0.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
12345678910<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>关于Kafka的demo参考 <a href="https://blog.csdn.net/qq_31821675/category_10138824.html" target="_blank" rel="noopener">文章</a></p>
<h6 id="1-消费普通String"><a href="#1-消费普通String" class="headerlink" title="1. 消费普通String"></a>1. 消费普通String</h6><p>Kafka生产者：</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>producer<span class="token punctuation">.</span>sh <span class="token operator">--</span>broker<span class="token operator">-</span>list hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic sowhat
<span class="token operator">></span>hello world
<span class="token operator">></span>sowhat 

<span class="token number">1234</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>消费者</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source

<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>SimpleStringSchema
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>FlinkKafkaConsumer
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>StringDeserializer

object KafkaSource1 <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//1、初始化Flink流计算的环境</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//修改并行度</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//默认所有算子的并行度为1</span>
    <span class="token comment" spellcheck="true">//2、导入隐式转换</span>
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    <span class="token comment" spellcheck="true">//连接Kafka，并且Kafka中的数据是普通字符串（String）</span>
    val props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">// 链接的Kafka 集群</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop101:9092,hadoop102:9092,hadoop103:9092"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">// 指定组名</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink01"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">// 指定KV序列化类</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">.</span>getName<span class="token punctuation">)</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">.</span>getName<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">// 从最新数据开始读</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">// 订阅主题</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"sowhat"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span><span class="token punctuation">)</span>

    stream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738394041</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h6 id="2-消费KV形式"><a href="#2-消费KV形式" class="headerlink" title="2. 消费KV形式"></a>2. 消费KV形式</h6><p>Kafka模式就是输入的KV只是平常只用V而已，如果用消费者KV则我们需要代码编写生产者跟消费者。<br><strong>生产者：</strong></p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source

<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span><span class="token punctuation">{</span>KafkaProducer<span class="token punctuation">,</span> ProducerRecord<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>StringSerializer

<span class="token keyword">import</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random

object MyKafkaProducer <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//连接Kafka的属性</span>
    val props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">// 链接的集群</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop101:9092,hadoop102:9092,hadoop103:9092"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">// 序列化KV类</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>StringSerializer<span class="token punctuation">]</span><span class="token punctuation">.</span>getName<span class="token punctuation">)</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>StringSerializer<span class="token punctuation">]</span><span class="token punctuation">.</span>getName<span class="token punctuation">)</span>

    var producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token punctuation">[</span>String<span class="token punctuation">,</span> String<span class="token punctuation">]</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span>
    var r <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Random</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//死循环生成键值对的数据</span>
      val data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token punctuation">[</span>String<span class="token punctuation">,</span> String<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"sowhat"</span><span class="token punctuation">,</span> <span class="token string">"key"</span> <span class="token operator">+</span> r<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"value"</span> <span class="token operator">+</span> r<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
      Thread<span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">123456789101112131415161718192021222324252627282930</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>消费者：</strong></p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source

<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span>TypeInformation
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span><span class="token punctuation">{</span>FlinkKafkaConsumer<span class="token punctuation">,</span> KafkaDeserializationSchema<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecord
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>StringDeserializer
<span class="token comment" spellcheck="true">//2、导入隐式转换</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

object KafkaSourceByKeyValue <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//1、初始化Flink流计算的环境</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//修改并行度</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//默认所有算子的并行度为1</span>
    <span class="token comment" spellcheck="true">//连接Kafka的属性</span>
    val props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop101:9092,hadoop102:9092,hadoop103:9092"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"flink002"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">.</span>getName<span class="token punctuation">)</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">.</span>getName<span class="token punctuation">)</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//设置Kafka数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"sowhat"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">MyKafkaReader</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span><span class="token punctuation">)</span>

    stream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  <span class="token comment" spellcheck="true">//自定义一个类，从Kafka中读取键值对的数据</span>
  <span class="token keyword">class</span> <span class="token class-name">MyKafkaReader</span> <span class="token keyword">extends</span> <span class="token class-name">KafkaDeserializationSchema</span><span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//是否流结束</span>
    override def <span class="token function">isEndOfStream</span><span class="token punctuation">(</span>nextElement<span class="token operator">:</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">:</span> Boolean <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token boolean">false</span>
    <span class="token punctuation">}</span>
    <span class="token comment" spellcheck="true">// 反序列化</span>
    override def <span class="token function">deserialize</span><span class="token punctuation">(</span>record<span class="token operator">:</span> ConsumerRecord<span class="token punctuation">[</span>Array<span class="token punctuation">[</span>Byte<span class="token punctuation">]</span><span class="token punctuation">,</span> Array<span class="token punctuation">[</span>Byte<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> String<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>record <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        var key <span class="token operator">=</span> <span class="token string">"null"</span>
        var value <span class="token operator">=</span> <span class="token string">"null"</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>
          key <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"UTF-8"</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//从Kafka记录中得到Value</span>
          value <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"UTF-8"</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
        <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
      <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true">//数据为空</span>
        <span class="token punctuation">(</span><span class="token string">"null"</span><span class="token punctuation">,</span> <span class="token string">"null"</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token comment" spellcheck="true">//指定类型</span>
    override def getProducedType<span class="token operator">:</span> TypeInformation<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token function">createTuple2TypeInformation</span><span class="token punctuation">(</span>createTypeInformation<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">,</span> createTypeInformation<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="4-自定义Source"><a href="#4-自定义Source" class="headerlink" title="4. 自定义Source"></a>4. 自定义Source</h5><p>当然也可以自定义数据源，有<code>两种</code>方式实现：</p>
<ol>
<li>通过实现 <code>SourceFunction</code>接口来自定义无并行度（也就是并行度只能为 1）的 Source。</li>
<li>通过实现 <code>ParallelSourceFunction</code> 接口或者继承 <code>RichParallelSourceFunction</code> 来自 定义有并行度的数据源。</li>
</ol>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>source<span class="token punctuation">.</span>SourceFunction
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span><span class="token punctuation">{</span>StreamExecutionEnvironment<span class="token punctuation">,</span> _<span class="token punctuation">}</span>

<span class="token keyword">import</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random


<span class="token keyword">case</span> <span class="token keyword">class</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span>sid<span class="token operator">:</span> String<span class="token punctuation">,</span> var callOut<span class="token operator">:</span> String<span class="token punctuation">,</span> var callInt<span class="token operator">:</span> String<span class="token punctuation">,</span> callType<span class="token operator">:</span> String<span class="token punctuation">,</span> callTime<span class="token operator">:</span> Long<span class="token punctuation">,</span> duration<span class="token operator">:</span> Long<span class="token punctuation">)</span>


<span class="token comment" spellcheck="true">/**
  * 自定义的Source,需求：每隔两秒钟，生成10条随机基站通话日志数据
  */</span>
<span class="token keyword">class</span> <span class="token class-name">MyCustomerSource</span> <span class="token keyword">extends</span> <span class="token class-name">SourceFunction</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token punctuation">{</span>
  <span class="token comment" spellcheck="true">//是否终止数据流的标记</span>
  var flag <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>

  <span class="token comment" spellcheck="true">/**
    * 主要的方法，启动一个Source，并且从Source中返回数据
    * 如果run方法停止，则数据流终止
    */</span>
  override def <span class="token function">run</span><span class="token punctuation">(</span>ctx<span class="token operator">:</span> SourceFunction<span class="token punctuation">.</span>SourceContext<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val r <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Random</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    var types <span class="token operator">=</span> <span class="token function">Array</span><span class="token punctuation">(</span><span class="token string">"fail"</span><span class="token punctuation">,</span> <span class="token string">"basy"</span><span class="token punctuation">,</span> <span class="token string">"barring"</span><span class="token punctuation">,</span> <span class="token string">"success"</span><span class="token punctuation">)</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span>flag<span class="token punctuation">)</span> <span class="token punctuation">{</span>
      <span class="token number">1</span><span class="token punctuation">.</span><span class="token function">to</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>_ <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        var callOut <span class="token operator">=</span> <span class="token string">"1860000%04d"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//主叫号码</span>
        var callIn <span class="token operator">=</span> <span class="token string">"1890000%04d"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//被叫号码</span>
        <span class="token comment" spellcheck="true">//生成一条数据</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token string">"station_"</span> <span class="token operator">+</span> r<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callOut<span class="token punctuation">,</span> callIn<span class="token punctuation">,</span> <span class="token function">types</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> r<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>ctx<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>_<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//发送数据到流</span>
      Thread<span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//每隔2秒发送一次数据</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
  <span class="token comment" spellcheck="true">//终止数据流</span>
  override def <span class="token function">cancel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    flag <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
object CustomerSource <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyCustomerSource</span><span class="token punctuation">)</span>
    stream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"SelfSource"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="4-Flink-的-Sink-数据目标"><a href="#4-Flink-的-Sink-数据目标" class="headerlink" title="4. Flink 的 Sink 数据目标"></a>4. Flink 的 Sink 数据目标</h3><p>Flink 针对 DataStream 提供了大量的已经实现的<code>数据目标</code>（Sink），包括<code>文件</code>、<code>Kafka</code>、<code>Redis</code>、<code>HDFS</code>、<code>Elasticsearch</code> 等等。</p>
<h5 id="1-基于-HDFS-的-Sink"><a href="#1-基于-HDFS-的-Sink" class="headerlink" title="1. 基于 HDFS 的 Sink"></a>1. 基于 HDFS 的 Sink</h5><p>首先配置支持 Hadoop FileSystem 的连接器依赖。</p>
<pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-filesystem_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
12345<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Streaming File Sink 能把数据写入 HDFS 中，还可以<code>支持分桶写入</code>，每一个 <a href="https://sowhat.blog.csdn.net/article/details/106488897" target="_blank" rel="noopener">分桶</a> 就对 应 HDFS 中的一个目录。默认按照<strong>小时来分桶</strong>，在一个桶内部，会进一步将输出基于滚动策 略切分成更小的文件。这有助于防止桶文件变得过大。滚动策略也是可以配置的，默认策略会根据文件大小和超时时间来滚动文件，超时时间是指没有新数据写入部分文件（part file）的时间。</p>
<p><code>需求</code>：把自定义的Source作为数据源，把基站日志数据 <a href="https://blog.csdn.net/bingque6535/article/details/107269077/" target="_blank" rel="noopener">写入HDFS</a> 并且每隔10秒钟生成一个文件</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>sink

<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span><span class="token punctuation">{</span>MyCustomerSource<span class="token punctuation">,</span> StationLog<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>SimpleStringEncoder
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>core<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>sink<span class="token punctuation">.</span>filesystem<span class="token punctuation">.</span>StreamingFileSink
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>sink<span class="token punctuation">.</span>filesystem<span class="token punctuation">.</span>rollingpolicies<span class="token punctuation">.</span>DefaultRollingPolicy
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span><span class="token punctuation">{</span>StreamExecutionEnvironment<span class="token punctuation">,</span> _<span class="token punctuation">}</span>

object HDFSSink <span class="token punctuation">{</span>

  <span class="token comment" spellcheck="true">//需求：把自定义的Source作为数据源，把基站日志数据写入HDFS并且每隔10钟生成一个文件</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//读取数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyCustomerSource</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//默认一个小时一个目录(分桶)</span>
    <span class="token comment" spellcheck="true">//设置一个滚动策略</span>
    val rolling<span class="token operator">:</span> DefaultRollingPolicy<span class="token punctuation">[</span>StationLog<span class="token punctuation">,</span> String<span class="token punctuation">]</span> <span class="token operator">=</span> DefaultRollingPolicy<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">withInactivityInterval</span><span class="token punctuation">(</span><span class="token number">5000</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//不活动的分桶时间</span>
      <span class="token punctuation">.</span><span class="token function">withRolloverInterval</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//每隔10 生成一个文件</span>
      <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//创建</span>

    <span class="token comment" spellcheck="true">//创建HDFS的Sink</span>
    val hdfsSink<span class="token operator">:</span> StreamingFileSink<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> StreamingFileSink<span class="token punctuation">.</span>forRowFormat<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">(</span>
      <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop101:9000/MySink001/"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token keyword">new</span> <span class="token class-name">SimpleStringEncoder</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">withRollingPolicy</span><span class="token punctuation">(</span>rolling<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">withBucketCheckInterval</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//检查间隔时间</span>
      <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    stream<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span>hdfsSink<span class="token punctuation">)</span>

    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token number">12345678910111213141516171819202122232425262728293031323334353637383940</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="2-基于-Redis的-Sink"><a href="#2-基于-Redis的-Sink" class="headerlink" title="2. 基于 Redis的 Sink"></a>2. 基于 Redis的 Sink</h5><p>Flink 除了内置的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/connectors/" target="_blank" rel="noopener">连接器</a> 外，还有一些额外的连接器通过 Apache Bahir 发布，包括：</p>
<ul>
<li>Apache ActiveMQ (source/sink)</li>
<li>Apache Flume (sink)</li>
<li>Redis (sink)</li>
<li>Akka (sink)</li>
<li>Netty (source)</li>
</ul>
<p>这里我用 Redis 来举例，首先需要配置 Redis 连接器的依赖：<br><code>需求</code>：把netcat作为数据源，并且统计每个单词的次数，统计的结果写入Redis数据库中。<br>导入依赖：</p>
<pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.bahir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-redis_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
12345<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>代码如下：</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>sink

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>redis<span class="token punctuation">.</span>RedisSink
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>redis<span class="token punctuation">.</span>common<span class="token punctuation">.</span>config<span class="token punctuation">.</span>FlinkJedisPoolConfig
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>redis<span class="token punctuation">.</span>common<span class="token punctuation">.</span>mapper<span class="token punctuation">.</span><span class="token punctuation">{</span>RedisCommand<span class="token punctuation">,</span> RedisCommandDescription<span class="token punctuation">,</span> RedisMapper<span class="token punctuation">}</span>

object RedisSink <span class="token punctuation">{</span>

  <span class="token comment" spellcheck="true">//需求：把netcat作为数据源，并且统计每个单词的次数，统计的结果写入Redis数据库中。</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    <span class="token comment" spellcheck="true">//读取数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">,</span> <span class="token number">8888</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//计算</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// 等价于groupbyKey</span>
      <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//把结果写入Redis中 设置连接Redis的配置</span>
    val config<span class="token operator">:</span> FlinkJedisPoolConfig <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlinkJedisPoolConfig<span class="token punctuation">.</span>Builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setDatabase</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setHost</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setPort</span><span class="token punctuation">(</span><span class="token number">6379</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//设置Redis的Sink</span>
    result<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">RedisSink</span><span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span>config<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">RedisMapper</span><span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">{</span>
      <span class="token comment" spellcheck="true">//设置redis的命令</span>
      override def getCommandDescription <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token keyword">new</span> <span class="token class-name">RedisCommandDescription</span><span class="token punctuation">(</span>RedisCommand<span class="token punctuation">.</span>HSET<span class="token punctuation">,</span> <span class="token string">"sowhat"</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">// https://bahir.apache.org/docs/flink/current/flink-streaming-redis/</span>
      <span class="token punctuation">}</span>
      <span class="token comment" spellcheck="true">//从数据中获取Key</span>
      override def <span class="token function">getKeyFromData</span><span class="token punctuation">(</span>data<span class="token operator">:</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
        data<span class="token punctuation">.</span>_1
      <span class="token punctuation">}</span>
      <span class="token comment" spellcheck="true">//从数据中获取Value</span>
      override def <span class="token function">getValueFromData</span><span class="token punctuation">(</span>data<span class="token operator">:</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
        data<span class="token punctuation">.</span>_2 <span class="token operator">+</span> <span class="token string">""</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"redisSink"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122232425262728293031323334353637383940414243</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="3-基于-Kafka的-Sink"><a href="#3-基于-Kafka的-Sink" class="headerlink" title="3. 基于 Kafka的 Sink"></a>3. 基于 Kafka的 Sink</h5><p>由于前面有的课程已经讲过 Flink 的 Kafka 连接器，所以还是一样需要配置 Kafka 连接 器的依赖配置，接下我们还是把 WordCout 的结果写入 Kafka：</p>
<h6 id="1-Kafka作为Sink的第一种（String）"><a href="#1-Kafka作为Sink的第一种（String）" class="headerlink" title="1. Kafka作为Sink的第一种（String）"></a>1. Kafka作为Sink的第一种（String）</h6><p><code>需求</code>：把netcat数据源中每个单词写入Kafka</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>sink

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>SimpleStringSchema
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>FlinkKafkaProducer

object KafkaSinkByString <span class="token punctuation">{</span>
  <span class="token comment" spellcheck="true">//Kafka作为Sink的第一种（String）</span>
  <span class="token comment" spellcheck="true">//需求：把netcat数据源中每个单词写入Kafka</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//读取数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">,</span><span class="token number">8888</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//计算</span>
    val words<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//把单词写入Kafka</span>
    words<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaProducer</span><span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"hadoop101:9092,hadoop102:9092,hadoop103:9092"</span><span class="token punctuation">,</span><span class="token string">"sowhat"</span><span class="token punctuation">,</span><span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafkaSink"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>写入到Kafka后可以在终端开一个消费者。</p>
<pre><code>bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic sowhat
1</code></pre><h6 id="2-Kafka作为Sink的第二种-KV"><a href="#2-Kafka作为Sink的第二种-KV" class="headerlink" title="2. Kafka作为Sink的第二种(KV)"></a>2. Kafka作为Sink的第二种(KV)</h6><p><code>需求</code>：把<code>netcat</code>作为数据源，统计每个单词的数量，并且把统计的结果写入Kafka</p>
<pre class="line-numbers language-java"><code class="language-java"> <span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>sink

<span class="token keyword">import</span> java<span class="token punctuation">.</span>lang
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span><span class="token punctuation">{</span>FlinkKafkaProducer<span class="token punctuation">,</span> KafkaSerializationSchema<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord

object KafkaSinkByKeyValue <span class="token punctuation">{</span>
  <span class="token comment" spellcheck="true">//Kafka作为Sink的第二种（KV）</span>
  <span class="token comment" spellcheck="true">//把netcat作为数据源，统计每个单词的数量，并且把统计的结果写入Kafka</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_<span class="token punctuation">;</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//读取数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">,</span> <span class="token number">8888</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//计算</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//创建连接Kafka的属性</span>
    var props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop101:9092,hadoop102:9092,hadoop103:9092"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//创建一个Kafka的sink</span>
    var kafkaSink <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaProducer</span><span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
      <span class="token string">"sowhat"</span><span class="token punctuation">,</span>
      <span class="token keyword">new</span> <span class="token class-name">KafkaSerializationSchema</span><span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//自定义的匿名内部类</span>
        override def <span class="token function">serialize</span><span class="token punctuation">(</span>element<span class="token operator">:</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> timestamp<span class="token operator">:</span> lang<span class="token punctuation">.</span>Long<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
          <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token punctuation">(</span><span class="token string">"sowhat"</span><span class="token punctuation">,</span> element<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>getBytes<span class="token punctuation">,</span> <span class="token punctuation">(</span>element<span class="token punctuation">.</span>_2 <span class="token operator">+</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
      props<span class="token punctuation">,</span> <span class="token comment" spellcheck="true">//连接Kafka的数学</span>
      FlinkKafkaProducer<span class="token punctuation">.</span>Semantic<span class="token punctuation">.</span>EXACTLY_ONCE <span class="token comment" spellcheck="true">//精确一次</span>
    <span class="token punctuation">)</span>
    result<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span>kafkaSink<span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka的sink的第二种"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//--property print.key=true Kafka的命令加一个参数</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738394041</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>生成写入KV后可以定义消费者：</p>
<pre class="line-numbers language-java"><code class="language-java">bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>from<span class="token operator">-</span>beginning \
 <span class="token operator">--</span>topic sowhat <span class="token operator">--</span>property print<span class="token punctuation">.</span>key<span class="token operator">=</span><span class="token boolean">true</span> 
 Kafka的命令加一个参数

<span class="token number">1234</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="4-基于HBase的Sink"><a href="#4-基于HBase的Sink" class="headerlink" title="4. 基于HBase的Sink"></a>4. 基于HBase的Sink</h5><p>引入依赖：</p>
<pre class="line-numbers language-xml"><code class="language-xml">        <span class="token comment" spellcheck="true">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-hbase --></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-hbase_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.10.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
123456<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>代码：</p>
<pre class="line-numbers language-java"><code class="language-java">packge com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>demo
<span class="token keyword">import</span> java<span class="token punctuation">.</span>text<span class="token punctuation">.</span>SimpleDateFormat
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Date

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span>Configuration
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>sink<span class="token punctuation">.</span><span class="token punctuation">{</span>RichSinkFunction<span class="token punctuation">,</span> SinkFunction<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span><span class="token punctuation">{</span>HBaseConfiguration<span class="token punctuation">,</span> HConstants<span class="token punctuation">,</span> TableName<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span>_
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Bytes

<span class="token keyword">class</span> <span class="token class-name">HBaseWriter</span> <span class="token keyword">extends</span> <span class="token class-name">RichSinkFunction</span><span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token punctuation">{</span>
  var conn<span class="token operator">:</span> Connection <span class="token operator">=</span> null
  val scan<span class="token operator">:</span> Scan <span class="token operator">=</span> null
  var mutator<span class="token operator">:</span> BufferedMutator <span class="token operator">=</span> null
  var count<span class="token operator">:</span>Int <span class="token operator">=</span> <span class="token number">0</span>

  override def <span class="token function">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val config<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span>create
    config<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>HConstants<span class="token punctuation">.</span>ZOOKEEPER_QUORUM<span class="token punctuation">,</span> <span class="token string">"IP1,IP2,IP3"</span><span class="token punctuation">)</span>
    config<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>HConstants<span class="token punctuation">.</span>ZOOKEEPER_CLIENT_PORT<span class="token punctuation">,</span> <span class="token string">"2181"</span><span class="token punctuation">)</span>
    config<span class="token punctuation">.</span><span class="token function">setInt</span><span class="token punctuation">(</span>HConstants<span class="token punctuation">.</span>HBASE_CLIENT_OPERATION_TIMEOUT<span class="token punctuation">,</span> <span class="token number">30000</span><span class="token punctuation">)</span>
    config<span class="token punctuation">.</span><span class="token function">setInt</span><span class="token punctuation">(</span>HConstants<span class="token punctuation">.</span>HBASE_CLIENT_SCANNER_TIMEOUT_PERIOD<span class="token punctuation">,</span> <span class="token number">30000</span><span class="token punctuation">)</span>
    conn <span class="token operator">=</span> ConnectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span>

    val tableName<span class="token operator">:</span> TableName <span class="token operator">=</span> TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span><span class="token string">"sowhat"</span><span class="token punctuation">)</span>
    val params<span class="token operator">:</span> BufferedMutatorParams <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedMutatorParams</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//设置缓存1m，当达到1m时数据会自动刷到hbase</span>
    params<span class="token punctuation">.</span><span class="token function">writeBufferSize</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
    mutator <span class="token operator">=</span> conn<span class="token punctuation">.</span><span class="token function">getBufferedMutator</span><span class="token punctuation">(</span>params<span class="token punctuation">)</span>
    count <span class="token operator">=</span> <span class="token number">0</span>
  <span class="token punctuation">}</span>

  override def <span class="token function">invoke</span><span class="token punctuation">(</span>value<span class="token operator">:</span> String<span class="token punctuation">,</span> context<span class="token operator">:</span> SinkFunction<span class="token punctuation">.</span>Context<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val cf1 <span class="token operator">=</span> <span class="token string">"m"</span>
    val value1 <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">replace</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span>
    val put<span class="token operator">:</span> Put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"rk"</span> <span class="token operator">+</span> value1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>cf1<span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"time"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"v"</span> <span class="token operator">+</span> value1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    mutator<span class="token punctuation">.</span><span class="token function">mutate</span><span class="token punctuation">(</span>put<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//每满2000条刷新一下数据</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>count <span class="token operator">>=</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      mutator<span class="token punctuation">.</span><span class="token function">flush</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      count <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token punctuation">}</span>
    count <span class="token operator">=</span> count <span class="token operator">+</span> <span class="token number">1</span>
  <span class="token punctuation">}</span>
  <span class="token comment" spellcheck="true">/**
    * 关闭
    */</span>
  override def <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>conn <span class="token operator">!=</span> null<span class="token punctuation">)</span> conn<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token operator">--</span><span class="token operator">-</span>
<span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>demo
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>SimpleStringSchema
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>FlinkKafkaConsumer011

object HbaseRw <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"10.100.34.111:9092,10.100.34.133:9092"</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"timer.hbase"</span><span class="token punctuation">)</span>

    val env<span class="token operator">:</span>StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment

    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer011</span><span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"sowhat"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">)</span>

    stream<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">HBaseWriter</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"hbase write"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="5-自定义-的-Sink"><a href="#5-自定义-的-Sink" class="headerlink" title="5. 自定义 的 Sink"></a>5. 自定义 的 Sink</h5><p>当然你可以自己定义 Sink，有两种实现方式：<br>1、实现 <code>SinkFunction</code>接口。<br>2、实现 <code>RichSinkFunction</code>类。后者增加了生命周期的管理功能。比如需要在 Sink 初始化的时候创 建连接对象，则最好使用第二种。<br><code>需求</code>：随机生成StationLog对象，写入MySQL数据库的表<code>t_station_log</code>中<br>引入依赖：</p>
<pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.1.44<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
12345<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>代码如下：</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>sink

<span class="token keyword">import</span> java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span>

<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span><span class="token punctuation">{</span>MyCustomerSource<span class="token punctuation">,</span> StationLog<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span>Configuration
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>sink<span class="token punctuation">.</span><span class="token punctuation">{</span>RichSinkFunction<span class="token punctuation">,</span> SinkFunction<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

<span class="token keyword">case</span> <span class="token keyword">class</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span>sid<span class="token operator">:</span> String<span class="token punctuation">,</span> var callOut<span class="token operator">:</span> String<span class="token punctuation">,</span> var callInt<span class="token operator">:</span> String<span class="token punctuation">,</span> callType<span class="token operator">:</span> String<span class="token punctuation">,</span> callTime<span class="token operator">:</span> Long<span class="token punctuation">,</span> duration<span class="token operator">:</span> Long<span class="token punctuation">)</span>

object CustomerJdbcSink <span class="token punctuation">{</span>

  <span class="token comment" spellcheck="true">//需求：随机生成StationLog对象，写入Mysql数据库的表（t_station_log）中</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyCustomerSource</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//数据写入Mysql，所有需要创建一个自定义的sink</span>
    stream<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyCustomerJdbcSink</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"jdbcSink"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  <span class="token comment" spellcheck="true">/**
   * 自定义的Sink类
   */</span>
  <span class="token keyword">class</span> <span class="token class-name">MyCustomerJdbcSink</span> <span class="token keyword">extends</span> <span class="token class-name">RichSinkFunction</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">{</span>
    var conn <span class="token operator">:</span>Connection<span class="token operator">=</span>_
    var pst <span class="token operator">:</span>PreparedStatement<span class="token operator">=</span>_

    <span class="token comment" spellcheck="true">//把StationLog对象写入Mysql表中，每写入一条执行一次</span>
    override def <span class="token function">invoke</span><span class="token punctuation">(</span>value<span class="token operator">:</span> StationLog<span class="token punctuation">,</span> context<span class="token operator">:</span> SinkFunction<span class="token punctuation">.</span>Context<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      pst<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>value<span class="token punctuation">.</span>sid<span class="token punctuation">)</span>
      pst<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>value<span class="token punctuation">.</span>callOut<span class="token punctuation">)</span>
      pst<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>value<span class="token punctuation">.</span>callInt<span class="token punctuation">)</span>
      pst<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span>value<span class="token punctuation">.</span>callType<span class="token punctuation">)</span>
      pst<span class="token punctuation">.</span><span class="token function">setLong</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span>value<span class="token punctuation">.</span>callTime<span class="token punctuation">)</span>
      pst<span class="token punctuation">.</span><span class="token function">setLong</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span>value<span class="token punctuation">.</span>duration<span class="token punctuation">)</span>
      pst<span class="token punctuation">.</span><span class="token function">executeUpdate</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    <span class="token comment" spellcheck="true">//Sink初始化的时候调用一次，一个并行度初始化一次</span>
    <span class="token comment" spellcheck="true">//创建连接对象，和Statement对象</span>
    override def <span class="token function">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      conn <span class="token operator">=</span>DriverManager<span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:mysql://localhost/test"</span><span class="token punctuation">,</span><span class="token string">"root"</span><span class="token punctuation">,</span><span class="token string">"123123"</span><span class="token punctuation">)</span>
      pst <span class="token operator">=</span>conn<span class="token punctuation">.</span><span class="token function">prepareStatement</span><span class="token punctuation">(</span><span class="token string">"insert into t_station_log (sid,call_out,call_in,call_type,call_time,duration) values (?,?,?,?,?,?)"</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

    override def <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      pst<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      conn<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="5-DataStream转换算子"><a href="#5-DataStream转换算子" class="headerlink" title="5. DataStream转换算子"></a>5. DataStream转换算子</h1><p>此时再将中间的转换算子<code>Transformation</code>，即<strong>通过从一个或多个 DataStream 生成新的 DataStream 的过程被称为 Transformation 操作</strong>。在转换过程中，每种操作类型被定义为不同的 <strong>Operator</strong>，Flink 程序能够将多个 <strong>Transformation</strong> 组成一个 <strong>DataFlow</strong> 的拓扑。</p>
<h3 id="1-Map-DataStream-gt-DataStream"><a href="#1-Map-DataStream-gt-DataStream" class="headerlink" title="1. Map [DataStream->DataStream]"></a>1. Map [DataStream-&gt;DataStream]</h3><p>调 用 用 户 定 义 的 MapFunction 对 DataStream[T] 数 据 进 行 处 理 ， 形 成 新 的 DataStream[T]，其中数据格式可能会发生变化，常用作对数据集内数据的<code>清洗</code>和<code>转换</code>。例如将输入数据集中的每个数值全部加 1 处理，并且将数据输出到下游数据集。<br><img src="https://img-blog.csdnimg.cn/20200714144116504.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-FlatMap-DataStream-gt-DataStream"><a href="#2-FlatMap-DataStream-gt-DataStream" class="headerlink" title="2. FlatMap [DataStream->DataStream]"></a>2. FlatMap [DataStream-&gt;DataStream]</h3><p>该算子主要应用处理输入一个元素产生一个或者多个元素的计算场景，比较常见的是在 经典例子 WordCount 中，将每一行的文本数据切割，生成单词序列如在图所示，对于输入 DataStream[String]通过 FlatMap 函数进行处理，字符串数字按逗号切割，然后形成新的整 数数据集。</p>
<pre class="line-numbers language-java"><code class="language-java"> val resultStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> dataStream<span class="token punctuation">.</span>flatMap <span class="token punctuation">{</span> str <span class="token operator">=</span><span class="token operator">></span> str<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span> <span class="token punctuation">}</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/2020071415253321.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="3-Filter-DataStream-gt-DataStream"><a href="#3-Filter-DataStream-gt-DataStream" class="headerlink" title="3. Filter [DataStream->DataStream]"></a>3. Filter [DataStream-&gt;DataStream]</h3><p>该算子将按照条件对输入数据集进行筛选操作，将符合条件(过滤表达式=true)的数据集输出，将不符合条件的数据过滤掉。如下图所示将输入数据集中偶数过滤出来，奇数从数据集中去除。</p>
<pre class="line-numbers language-java"><code class="language-java">val filter<span class="token operator">:</span>DataStream<span class="token punctuation">[</span>Int<span class="token punctuation">]</span> <span class="token operator">=</span> dataStream<span class="token punctuation">.</span>filter <span class="token punctuation">{</span> _ <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">}</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/20200714153037535.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="4-KeyBy-DataStream-gt-KeyedStream"><a href="#4-KeyBy-DataStream-gt-KeyedStream" class="headerlink" title="4. KeyBy [DataStream->KeyedStream]"></a>4. KeyBy [DataStream-&gt;KeyedStream]</h3><p>该算子根据指定的 Key 将输入的 DataStream[T]数据格式转换为 KeyedStream[T]，也就是在数据集中执行 Partition 操作，将相同的 Key 值的数据放置在相同的分区中。<br>默认是根据注定数据的<code>hashcode</code>来分的。</p>
<pre class="line-numbers language-java"><code class="language-java">    val test<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"2"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"2"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    val value<span class="token operator">:</span> KeyedStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> String<span class="token punctuation">]</span> <span class="token operator">=</span> test<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
     <span class="token comment" spellcheck="true">/**
      * （String,Int)   => 是进行keyBy的数据类型
      *   String        =>  是分流的key的数据类型
      */</span>
<span class="token operator">--</span><span class="token operator">-</span>
    val test<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"2"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"2"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    val value<span class="token operator">:</span> KeyedStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> Tuple<span class="token punctuation">]</span> <span class="token operator">=</span> test<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">/**
      * （String,Int)   => 是进行keyBy的数据类型
      *  Tuple        =>  是分流的key的数据类型
      */</span>
<span class="token number">12345678910111213</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="5-Reduce-KeyedStream-gt-DataStream"><a href="#5-Reduce-KeyedStream-gt-DataStream" class="headerlink" title="5. Reduce [KeyedStream->DataStream]"></a>5. Reduce [KeyedStream-&gt;DataStream]</h3><p>该算子和 MapReduce 中 Reduce 原理基本一致，主要目的是将输入的<code>KeyedStream</code>通过 传 入 的 用 户 自 定 义 的 <code>ReduceFunction</code>滚 动 地 进 行 数 据 聚 合 处 理 ， 其 中 定 义 的 ReduceFunciton 必须满足运算<code>结合律</code>和<code>交换律</code>。如下代码对传入 keyedStream 数据集中相同的 key 值的数据独立进行求和运算，得到每个 key 所对应的求和值。</p>
<pre class="line-numbers language-java"><code class="language-java">    val test<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"d"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    val value<span class="token operator">:</span> KeyedStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> Tuple<span class="token punctuation">]</span> <span class="token operator">=</span> test<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">// 滚动对第二个字段进行reduce相加求和</span>
    val reduceStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">.</span>reduce <span class="token punctuation">{</span> <span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span>t1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t1<span class="token punctuation">.</span>_2 <span class="token operator">+</span> t2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span> <span class="token punctuation">}</span>
<span class="token number">1234</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果：</p>
<pre><code>2&gt; (c,2)
3&gt; (a,3)
3&gt; (d,4)
2&gt; (c,7)
3&gt; (a,8)
12345</code></pre><p><code>PS</code>：<strong>对于该结果需要说明下为什么key相同的出现了多次，这主要是Flink流式处理思想的体现，迭代式的输出结果</strong>。</p>
<h3 id="6-Aggregations-KeyedStream-gt-DataStream"><a href="#6-Aggregations-KeyedStream-gt-DataStream" class="headerlink" title="6. Aggregations[KeyedStream->DataStream]"></a>6. Aggregations[KeyedStream-&gt;DataStream]</h3><p>Aggregations 是 KeyedDataStream 接口提供的聚合算子，根据指定的字段进行聚合操 作，滚动地产生一系列数据聚合结果。<code>其实是将 Reduce 算子中的函数进行了封装</code>，封装的 聚合操作有 sum、min、minBy、max、maxBy等，这样就不需要用户自己定义 Reduce 函数。 如下代码所示，指定数据集中第一个字段作为 key，用第二个字段作为累加字段，然后<code>滚动</code>地对第二个字段的数值进行累加并输出</p>
<pre class="line-numbers language-java"><code class="language-java">    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    val test<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"d"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    val value<span class="token operator">:</span> KeyedStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> Tuple<span class="token punctuation">]</span> <span class="token operator">=</span> test<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">// 滚动对第二个字段进行reduce相加求和</span>
    val reduceStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">.</span>reduce <span class="token punctuation">{</span> <span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span>t1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t1<span class="token punctuation">.</span>_2 <span class="token operator">+</span> t2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span> <span class="token punctuation">}</span>
    <span class="token comment" spellcheck="true">// 相当于reduce更简化版的 聚合</span>
    val sumStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token number">1234567</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果：</p>
<pre><code>(a,3)
(d,4)
(c,2)
(c,7)
(a,8)
12345</code></pre><h3 id="7-Union-DataStream-gt-DataStream"><a href="#7-Union-DataStream-gt-DataStream" class="headerlink" title="7. Union[DataStream ->DataStream]"></a>7. Union[DataStream -&gt;DataStream]</h3><p>Union 算子主要是将两个或者多个输入的数据集合并成一个数据集，需要保证两个数据 集的<code>格式一致</code>，输出的数据集的格式和输入的数据集格式保持一致。</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

object TestUnion <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    var stream1 <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    var stream2 <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"d"</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    var stream3 <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"e"</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"f"</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream1<span class="token punctuation">.</span><span class="token function">union</span><span class="token punctuation">(</span>stream2<span class="token punctuation">,</span> stream3<span class="token punctuation">)</span>
    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果：</p>
<pre><code>(a,1)
(b,2)
(e,7)
(f,8)
(b,5)
(d,6)
123456</code></pre><h3 id="8-Connect、CoMap、CoFlatMap-DataStream-gt-ConnectedStream-gt-DataStream"><a href="#8-Connect、CoMap、CoFlatMap-DataStream-gt-ConnectedStream-gt-DataStream" class="headerlink" title="8. Connect、CoMap、CoFlatMap[DataStream ->ConnectedStream->DataStream]"></a>8. Connect、CoMap、CoFlatMap[DataStream -&gt;ConnectedStream-&gt;DataStream]</h3><p>Connect 算子主要是为了<code>合并</code>两种或者<code>多种不同数据类型</code>的数据集，<strong>合并后会保留原来 数据集的数据类型</strong>。<br>例如：dataStream1 数据集为(String, Int)元祖类型，dataStream2 数据集为 Int 类型，通过 connect 连接算子将两个不同数据类型的流结合在一起，形成格式 为 ConnectedStreams 的数据集，其内部数据为<code>[(String, Int), Int]</code>的混合数据类型，保留了两个原始数据集的数据类型。</p>
<p>需要注意的是，对于 ConnectedStreams 类型的数据集<code>不能</code>直接进行类似 Print()的操 作，需要再转换成 DataStream 类型数据集，在 Flink 中 ConnectedStreams 提供的 <code>map()</code>方 法和<code>flatMap()</code></p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

object TestConnect <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

    val stream1<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    val stream2<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token string">"e"</span><span class="token punctuation">,</span> <span class="token string">"f"</span><span class="token punctuation">,</span> <span class="token string">"g"</span><span class="token punctuation">)</span>
    val stream3<span class="token operator">:</span> ConnectedStreams<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> String<span class="token punctuation">]</span> <span class="token operator">=</span> stream1<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>stream2<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//注意得到ConnectedStreams，实际上里面的数据没有真正合并</span>
    <span class="token comment" spellcheck="true">//使用CoMap,或者CoFlatmap</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream3<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>
      <span class="token comment" spellcheck="true">//第一个处理的函数</span>
      t <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        <span class="token punctuation">(</span>t<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true">//第二个处理的函数</span>
      t <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        <span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">)</span>
    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">123456789101112131415161718192021222324252627</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果：</p>
<pre><code>(e,0)
(f,0)
(g,0)
(a,1)
(b,2)
(c,3)
123456</code></pre><p><code>注意</code>：</p>
<ul>
<li>Union 之前两个流的类型<code>必须是一样</code>，Connect <code>可以不一样</code>，在之后的 coMap 中再去调 整成为一样的。</li>
<li>Connect <code>只能</code>操作两个流，Union <code>可以</code>操作多个。</li>
</ul>
<h3 id="9-Split-和-select-DataStream-gt-SplitStream-gt-DataStream"><a href="#9-Split-和-select-DataStream-gt-SplitStream-gt-DataStream" class="headerlink" title="9. Split 和 select [DataStream->SplitStream->DataStream]"></a>9. Split 和 select [DataStream-&gt;SplitStream-&gt;DataStream]</h3><p>Split 算子是将一个 DataStream 数据集<code>按照条件进行拆分</code>，形成两个数据集的过程， 也是 union 算子的逆向实现。每个接入的数据都会被<code>路由</code>到一个或者多个输出数据集中。<a href="https://blog.csdn.net/duxu24/article/details/105910476" target="_blank" rel="noopener">Side Output</a></p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span><span class="token punctuation">{</span>MyCustomerSource<span class="token punctuation">,</span> StationLog<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>ProcessFunction
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Collector

object TestSplitAndSelect <span class="token punctuation">{</span>

  <span class="token comment" spellcheck="true">//需求：从自定义的数据源中读取基站通话日志，把通话成功的和通话失败的分离出来</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//读取数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyCustomerSource</span><span class="token punctuation">)</span>


    <span class="token comment" spellcheck="true">// this needs to be an anonymous inner class, so that we can analyze the type</span>
    val successTag <span class="token operator">=</span> OutputTag<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"success"</span><span class="token punctuation">)</span>
    val nosuccessTag <span class="token operator">=</span> OutputTag<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"nosuccess"</span><span class="token punctuation">)</span>

    val sideoutputStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProcessFunction</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">,</span> StationLog<span class="token punctuation">]</span> <span class="token punctuation">{</span>
      override def <span class="token function">processElement</span><span class="token punctuation">(</span>value<span class="token operator">:</span> StationLog<span class="token punctuation">,</span> ctx<span class="token operator">:</span> ProcessFunction<span class="token punctuation">[</span>StationLog<span class="token punctuation">,</span> StationLog<span class="token punctuation">]</span>#Context<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>value<span class="token punctuation">.</span>callType<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"success"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
          ctx<span class="token punctuation">.</span><span class="token function">output</span><span class="token punctuation">(</span>successTag<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">else</span> <span class="token punctuation">{</span>
          ctx<span class="token punctuation">.</span><span class="token function">output</span><span class="token punctuation">(</span>nosuccessTag<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    sideoutputStream<span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span>successTag<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"成功数据"</span><span class="token punctuation">)</span>
    sideoutputStream<span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span>nosuccessTag<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"未成功数据"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//切割</span>
    val splitStream<span class="token operator">:</span> SplitStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span> <span class="token comment" spellcheck="true">//流并没有真正切割</span>
      log <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>log<span class="token punctuation">.</span>callType<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"success"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
          <span class="token function">Seq</span><span class="token punctuation">(</span><span class="token string">"Success"</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
          <span class="token function">Seq</span><span class="token punctuation">(</span><span class="token string">"NOSuccess"</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//选择不同的流  根据标签得到不同流</span>
    val stream1<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> splitStream<span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span><span class="token string">"Success"</span><span class="token punctuation">)</span>
    val stream2<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> splitStream<span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span><span class="token string">"NOSuccess"</span><span class="token punctuation">)</span>
    stream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"原始数据"</span><span class="token punctuation">)</span>
    stream1<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"通话成功"</span><span class="token punctuation">)</span>
    stream2<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"通话不成功"</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="函数类和富函数类"><a href="#函数类和富函数类" class="headerlink" title="函数类和富函数类"></a>函数类和富函数类</h2><p><strong>前面学过的所有算子几乎都可以自定义一个函数类、富函数类作为参数</strong>。因为 Flink 暴露者两种函数类的接口，常见的函数接口有：</p>
<ul>
<li>MapFunction</li>
<li>FlatMapFunction</li>
<li>ReduceFunction</li>
<li>。。。。。</li>
</ul>
<p><code>富函数接口</code>它其他常规函数接口的不同在于：<code>可以获取运行环境的上下文，在上下文环境中可以管理状态</code>，并拥有一些生命周期方法，所以可以实现更复杂的功能。富函数的接口有：</p>
<ul>
<li>RichMapFunction</li>
<li>RichFlatMapFunction</li>
<li>RichFilterFunction</li>
<li>RichSinkFunction</li>
</ul>
<h5 id="1-普通函数类型"><a href="#1-普通函数类型" class="headerlink" title="1. 普通函数类型"></a>1. 普通函数类型</h5><p>普通函数类举例：按照指定的时间格式输出每个通话的拨号时间和结束时间。resources目录下station.log文件内容如下：</p>
<pre><code>station_0,18600003612,18900004575,barring,1577080453123,0
station_9,18600003186,18900002113,success,1577080453123,32
station_3,18600003794,18900009608,success,1577080453123,4
station_1,18600000005,18900007729,fail,1577080453123,0
station_1,18600000005,18900007729,success,1577080603123,349
station_8,18600007461,18900006987,barring,1577080453123,0
station_5,18600009356,18900006066,busy,1577080455129,0
station_4,18600001941,18900003949,busy,1577080455129,0
12345678</code></pre><p>代码如下：</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>transformation

<span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URLDecoder
<span class="token keyword">import</span> java<span class="token punctuation">.</span>text<span class="token punctuation">.</span>SimpleDateFormat
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Date

<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span>StationLog
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>MapFunction
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

object TestFunctionClass <span class="token punctuation">{</span>

  <span class="token comment" spellcheck="true">//计算出每个通话成功的日志中呼叫起始和结束时间,并且按照指定的时间格式</span>
  <span class="token comment" spellcheck="true">//数据源来自本地文件</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    <span class="token comment" spellcheck="true">//读取数据源</span>
    var filePath <span class="token operator">=</span> getClass<span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"/station.log"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getPath
    filePath <span class="token operator">=</span> URLDecoder<span class="token punctuation">.</span><span class="token function">decode</span><span class="token punctuation">(</span>filePath<span class="token punctuation">,</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span>filePath<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        var arr <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//定义一个时间格式</span>
    val format <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SimpleDateFormat</span><span class="token punctuation">(</span><span class="token string">"yyyy-MM-dd HH:mm:ss"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//计算通话成功的起始和结束时间</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>callType<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"success"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyMapFunction</span><span class="token punctuation">(</span>format<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//result.print()</span>

    val result1<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>callType<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"success"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map <span class="token punctuation">{</span>
      x <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        val startTime <span class="token operator">=</span> x<span class="token punctuation">.</span>callTime
        val endTime <span class="token operator">=</span> startTime <span class="token operator">+</span> x<span class="token punctuation">.</span>duration <span class="token operator">*</span> <span class="token number">1000</span>
        <span class="token string">"主叫号码："</span> <span class="token operator">+</span> x<span class="token punctuation">.</span>callOut <span class="token operator">+</span> <span class="token string">",被叫号码:"</span> <span class="token operator">+</span> x<span class="token punctuation">.</span>callInt <span class="token operator">+</span> <span class="token string">",呼叫起始时间:"</span> <span class="token operator">+</span> format<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span>startTime<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">",呼叫结束时间:"</span> <span class="token operator">+</span> format<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span>endTime<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    result1<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  <span class="token comment" spellcheck="true">//自定义一个函数类  指定输入 跟输出类型</span>
  <span class="token keyword">class</span> <span class="token class-name">MyMapFunction</span><span class="token punctuation">(</span>format<span class="token operator">:</span> SimpleDateFormat<span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token class-name">MapFunction</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">,</span> String<span class="token punctuation">]</span> <span class="token punctuation">{</span>
    override def <span class="token function">map</span><span class="token punctuation">(</span>value<span class="token operator">:</span> StationLog<span class="token punctuation">)</span><span class="token operator">:</span> String <span class="token operator">=</span> <span class="token punctuation">{</span>
      val startTime <span class="token operator">=</span> value<span class="token punctuation">.</span>callTime
      val endTime <span class="token operator">=</span> startTime <span class="token operator">+</span> value<span class="token punctuation">.</span>duration <span class="token operator">*</span> <span class="token number">1000</span>
      <span class="token string">"主叫号码："</span> <span class="token operator">+</span> value<span class="token punctuation">.</span>callOut <span class="token operator">+</span> <span class="token string">",被叫号码:"</span> <span class="token operator">+</span> value<span class="token punctuation">.</span>callInt <span class="token operator">+</span> <span class="token string">",呼叫起始时间:"</span> <span class="token operator">+</span> format<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span>startTime<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">",呼叫结束时间:"</span> <span class="token operator">+</span> format<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span>endTime<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="2-富函数类型"><a href="#2-富函数类型" class="headerlink" title="2. 富函数类型"></a>2. 富函数类型</h5><p><code>富函数类举例</code>：把呼叫成功的通话信息转化成真实的用户姓名，通话用户对应的用户表 （在 Mysql 数据中）<br>由于需要从数据库中查询数据，就需要创建连接，创建连接的代码必须写在生命周期的 open 方法中。所以需要使用富函数类。<code>Rich Function</code> 有一个生命周期的概念。典型的生命周期方法有：</p>
<ul>
<li>open()方法是 rich function 的<code>初始化</code>方法，当一个算子例如 map 或者 filter 被调用 之前 open()会被调用。</li>
<li>close()方法是生命周期中的最后一个调用的方法，做一些<code>清理工作</code>。</li>
<li>getRuntimeContext()方法提供了函数的 RuntimeContext 的一些信息，例如函数执行的 并行度，任务的名字，以及 state 状态</li>
</ul>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>transformation

<span class="token keyword">import</span> java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">,</span> ResultSet<span class="token punctuation">}</span>

<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span>StationLog
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>RichMapFunction
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span>Configuration
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

object TestRichFunctionClass <span class="token punctuation">{</span>
  <span class="token comment" spellcheck="true">/**
    * 把通话成功的电话号码转换成真是用户姓名，用户姓名保存在Mysql表中
    * @param args
    */</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    <span class="token comment" spellcheck="true">//读取数据源</span>
    var filePath <span class="token operator">=</span> getClass<span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"/station.log"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getPath
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span>filePath<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        var arr <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//计算：把电话号码变成用户姓名</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>callType<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"success"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyRichMapFunction</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  <span class="token comment" spellcheck="true">//自定义一个富函数类</span>
  <span class="token keyword">class</span> <span class="token class-name">MyRichMapFunction</span> <span class="token keyword">extends</span> <span class="token class-name">RichMapFunction</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">,</span> StationLog<span class="token punctuation">]</span> <span class="token punctuation">{</span>
    var conn<span class="token operator">:</span> Connection <span class="token operator">=</span> _
    var pst<span class="token operator">:</span> PreparedStatement <span class="token operator">=</span> _

    override def <span class="token function">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      conn <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:mysql://localhost/test"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">,</span> <span class="token string">"123123"</span><span class="token punctuation">)</span>
      pst <span class="token operator">=</span> conn<span class="token punctuation">.</span><span class="token function">prepareStatement</span><span class="token punctuation">(</span><span class="token string">"select name from t_phone where phone_number=?"</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    override def <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      pst<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      conn<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    override def <span class="token function">map</span><span class="token punctuation">(</span>value<span class="token operator">:</span> StationLog<span class="token punctuation">)</span><span class="token operator">:</span> StationLog <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token comment" spellcheck="true">// 获取上下文信息 比如获取子线程</span>
      <span class="token function">println</span><span class="token punctuation">(</span>getRuntimeContext<span class="token punctuation">.</span>getTaskNameWithSubtasks<span class="token punctuation">)</span>
      <span class="token comment" spellcheck="true">//查询主叫号码对应的姓名</span>
      pst<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span>callOut<span class="token punctuation">)</span>
      val result<span class="token operator">:</span> ResultSet <span class="token operator">=</span> pst<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>result<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        value<span class="token punctuation">.</span>callOut <span class="token operator">=</span> result<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      <span class="token comment" spellcheck="true">//查询被叫号码对应的姓名</span>
      pst<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span>callInt<span class="token punctuation">)</span>
      val result2<span class="token operator">:</span> ResultSet <span class="token operator">=</span> pst<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>result2<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        value<span class="token punctuation">.</span>callInt <span class="token operator">=</span> result2<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      value
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="3-底层-ProcessFunctionAPI"><a href="#3-底层-ProcessFunctionAPI" class="headerlink" title="3. 底层 ProcessFunctionAPI"></a>3. 底层 ProcessFunctionAPI</h5><p>ProcessFunction 是一个低层次的流处理操作，允许返回所有 Stream 的基础构建模块，可以说是Flink的<code>杀手锏</code>了。</p>
<ul>
<li>访问 Event 本身数据（比如：Event 的时间，Event 的当前 Key 等）</li>
<li>管理状态 State（仅在 Keyed Stream 中）</li>
<li>管理定时器 Timer（包括：注册定时器，删除定时器等） 总而言之，ProcessFunction 是 Flink 最底层的 API，也是功能最强大的。</li>
</ul>
<p><code>需求</code>：监控每一个手机，如果在 5 秒内呼叫它的通话都是失败的，发出警告信息。<br><code>注意</code>： 本demo中会用到状态编程，只要知道状态的意思，不需要掌握。<a href="https://sowhat.blog.csdn.net/article/details/107379410" target="_blank" rel="noopener">后面的文章</a>中会详细讲解 State 编程。</p>
<pre class="line-numbers language-java"><code class="language-java">  <span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>transformation

<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span>StationLog
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>state<span class="token punctuation">.</span><span class="token punctuation">{</span>ValueState<span class="token punctuation">,</span> ValueStateDescriptor<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>KeyedProcessFunction
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Collector
<span class="token comment" spellcheck="true">/**
  * 监控每一个手机号码，如果这个号码在5秒内，所有呼叫它的日志都是失败的，则发出告警信息
  * 如果在5秒内只要有一个呼叫不是fail则不用告警
  */</span>
<span class="token comment" spellcheck="true">/**
  * 基站日志
  * @param sid      基站的id
  * @param callOut  主叫号码
  * @param callInt  被叫号码
  * @param callType 呼叫类型
  * @param callTime 呼叫时间 (毫秒)
  * @param duration 通话时长 （秒）
  */</span>
<span class="token keyword">case</span> <span class="token keyword">class</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span>sid<span class="token operator">:</span> String<span class="token punctuation">,</span> var callOut<span class="token operator">:</span> String<span class="token punctuation">,</span> var callInt<span class="token operator">:</span> String<span class="token punctuation">,</span> callType<span class="token operator">:</span> String<span class="token punctuation">,</span> callTime<span class="token operator">:</span> Long<span class="token punctuation">,</span> duration<span class="token operator">:</span> Long<span class="token punctuation">)</span>
object TestProcessFunction <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    <span class="token comment" spellcheck="true">//读取数据源 通过 netcat 发送 数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"IP1"</span><span class="token punctuation">,</span> <span class="token number">8888</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        val arr <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">// 按照呼入电话分组</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>callInt<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MonitorCallFail</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  <span class="token comment" spellcheck="true">//自定义一个底层的类 第一个是key类型，第二个是处理对象类型，第三个是返回类型</span>
  <span class="token keyword">class</span> <span class="token class-name">MonitorCallFail</span> <span class="token keyword">extends</span> <span class="token class-name">KeyedProcessFunction</span><span class="token punctuation">[</span>String<span class="token punctuation">,</span> StationLog<span class="token punctuation">,</span> String<span class="token punctuation">]</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//使用一个状态对象记录时间</span>
    lazy val timeState<span class="token operator">:</span> ValueState<span class="token punctuation">[</span>Long<span class="token punctuation">]</span> <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span><span class="token function">getState</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ValueStateDescriptor</span><span class="token punctuation">[</span>Long<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"time"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>Long<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    override def <span class="token function">processElement</span><span class="token punctuation">(</span>value<span class="token operator">:</span> StationLog<span class="token punctuation">,</span> ctx<span class="token operator">:</span> KeyedProcessFunction<span class="token punctuation">[</span>String<span class="token punctuation">,</span> StationLog<span class="token punctuation">,</span> String<span class="token punctuation">]</span>#Context<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token comment" spellcheck="true">//从状态中取得时间</span>
      val time<span class="token operator">:</span>Long <span class="token operator">=</span> timeState<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>time <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> value<span class="token punctuation">.</span>callType<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"fail"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//表示第一次发现呼叫失败，记录当前的时间</span>
        <span class="token comment" spellcheck="true">//获取当前系统时间，并注册定时器</span>
        val nowTime<span class="token operator">:</span>Long  <span class="token operator">=</span> ctx<span class="token punctuation">.</span><span class="token function">timerService</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">currentProcessingTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">//定时器在5秒后触发</span>
        val onTime<span class="token operator">:</span>Long  <span class="token operator">=</span> nowTime <span class="token operator">+</span> <span class="token number">5</span> <span class="token operator">*</span> 1000L
        ctx<span class="token punctuation">.</span><span class="token function">timerService</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">registerProcessingTimeTimer</span><span class="token punctuation">(</span>onTime<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">//把触发时间保存到状态中</span>
        timeState<span class="token punctuation">.</span><span class="token function">update</span><span class="token punctuation">(</span>onTime<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>time <span class="token operator">!=</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>value<span class="token punctuation">.</span>callType<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"fail"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//表示有一次成功的呼叫,必须要删除定时器</span>
        ctx<span class="token punctuation">.</span><span class="token function">timerService</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">deleteProcessingTimeTimer</span><span class="token punctuation">(</span>time<span class="token punctuation">)</span>
        timeState<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//清空状态中的时间</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token comment" spellcheck="true">//时间到了，定时器执行,</span>
    override def <span class="token function">onTimer</span><span class="token punctuation">(</span>timestamp<span class="token operator">:</span> Long<span class="token punctuation">,</span> ctx<span class="token operator">:</span> KeyedProcessFunction<span class="token punctuation">[</span>String<span class="token punctuation">,</span> StationLog<span class="token punctuation">,</span> String<span class="token punctuation">]</span>#OnTimerContext<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      val warnStr<span class="token operator">:</span>String  <span class="token operator">=</span> <span class="token string">"触发的时间："</span> <span class="token operator">+</span> timestamp <span class="token operator">+</span> <span class="token string">" 手机号 ："</span> <span class="token operator">+</span> ctx<span class="token punctuation">.</span>getCurrentKey
      out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>warnStr<span class="token punctuation">)</span>
      timeState<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="4-侧输出流-Side-Output"><a href="#4-侧输出流-Side-Output" class="headerlink" title="4. 侧输出流 Side Output"></a>4. 侧输出流 Side Output</h5><p>在 Flink 处理数据流时，我们经常会遇到这样的情况：在处理一个数据源时，往往需要<strong>将该源中的不同类型的数据做分割处理</strong>，如果使用 filter 算子对数据源进行筛选分割的话，势必会造成数据流的<code>多次复制</code>，造成不必要的性能浪费；flink 中的<code>侧输出</code>就是将数据 流进行分割，而不对流进行复制的一种分流机制。flink 的侧输出的另一个作用就是<code>对延时迟到</code>的数据进行处理，这样就可以不必丢弃迟到的数据。在后面的文章中会讲到！<br><code>案例</code>：根据基站的日志，请把呼叫成功的 Stream（主流）和不成功的 Stream（侧流） 分别输出。</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>transformation

<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span>StationLog
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>ProcessFunction
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Collector
object TestSideOutputStream <span class="token punctuation">{</span>
  <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
  var notSuccessTag<span class="token operator">:</span> OutputTag<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">OutputTag</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"not_success"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//不成功的侧流标签</span>
  <span class="token comment" spellcheck="true">//把呼叫成功的日志输出到主流，不成功的到侧流</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//读取数据源</span>
    var filePath<span class="token operator">:</span> String <span class="token operator">=</span> getClass<span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"/station.log"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getPath
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span>filePath<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        var arr<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">CreateSideOuputStream</span><span class="token punctuation">(</span>notSuccessTag<span class="token punctuation">)</span><span class="token punctuation">)</span>

    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"主流"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//一定要根据主流得到侧流</span>
    val sideStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> result<span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span>notSuccessTag<span class="token punctuation">)</span>
    sideStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"侧流"</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">class</span> <span class="token class-name">CreateSideOuputStream</span><span class="token punctuation">(</span>tag<span class="token operator">:</span> OutputTag<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token class-name">ProcessFunction</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">,</span> StationLog<span class="token punctuation">]</span> <span class="token punctuation">{</span>
    override def <span class="token function">processElement</span><span class="token punctuation">(</span>value<span class="token operator">:</span> StationLog<span class="token punctuation">,</span> ctx<span class="token operator">:</span> ProcessFunction<span class="token punctuation">[</span>StationLog<span class="token punctuation">,</span> StationLog<span class="token punctuation">]</span>#Context<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>value<span class="token punctuation">.</span>callType<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"success"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true">//输出主流</span>
        out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span>
      <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true">//输出侧流</span>
        ctx<span class="token punctuation">.</span><span class="token function">output</span><span class="token punctuation">(</span>tag<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="5-Flink-State管理跟恢复"><a href="#5-Flink-State管理跟恢复" class="headerlink" title="5. Flink State管理跟恢复"></a>5. Flink State管理跟恢复</h1><p>Flink 是一个<strong>默认就有状态的分析引擎</strong>，前面的 <a href="https://sowhat.blog.csdn.net/article/details/107296787" target="_blank" rel="noopener">WordCount</a> 案例可以做到单词的数量的累加，其实是因为在内存中保证了每个单词的出现的次数，这些数据其实就是状态数据。但是如果一个 Task 在处理过程中挂掉了，那么它在内存中的状态都会丢失，所有的数据都需要重新计算。从容错和消息处理的语义（At -least-once 和 Exactly-once）上来说，Flink 引入了 <code>State</code> 和<code>CheckPoint</code>。</p>
<ul>
<li><code>State</code> 一般指一个具体的 Task/Operator 的状态(Task Slot/ 转换算子)，State 数据默认保存在 Java 的<code>堆</code>内存中。</li>
<li>CheckPoint（可以理解为<code>CheckPoint是把State数据持久化存储了</code>）则表示了一个 Flink Job 在一个特定时刻的一份全局<strong>状态快照</strong>，即包含了所有<code>Task/Operator</code> 的状态。<br><img src="https://img-blog.csdnimg.cn/20200722191330798.png#pic_center" alt="在这里插入图片描述"></li>
</ul>
<h3 id="1-常用-State"><a href="#1-常用-State" class="headerlink" title="1. 常用 State"></a>1. 常用 State</h3><p>Flink 有两种常见的 State 类型，分别是:</p>
<ul>
<li><code>Keyed State</code>(键控状态)</li>
<li><code>Operator State</code>(算子状态)</li>
</ul>
<h5 id="1-Keyed-State（键控状态）"><a href="#1-Keyed-State（键控状态）" class="headerlink" title="1. Keyed State（键控状态）"></a>1. Keyed State（键控状态）</h5><p>Keyed State：顾名思义就是基于 <code>KeyedStream</code>上的状态，这个状态是跟特定的 Key 绑定的。KeyedStream 流上的每一个 Key，都对应一个 State。Flink 针对 Keyed State 提供了 以下可以保存 State 的数据结构：</p>
<ol>
<li><code>ValueState&lt;T&gt;</code>:<br>保存一个可以更新和检索的值（如上所述，每个值都对应到当前的输入数据的 key，因此算子接收到的每个 key 都可能对应一个值）。 这个值可以通过 update(T) 进行更新，通过 T value() 进行检索。</li>
<li><code>ListState&lt;T&gt;</code>:<br>保存一个元素的列表。可以往这个列表中追加数据，并在当前的列表上 进行检索。可以通过 add(T) 或者 addAll(List) 进行添加元素，通过 Iterable <code>get()</code>获得整个列表。还可以通过 <code>update</code>(List) 覆盖当前的列表。</li>
<li><code>ReducingState&lt;T&gt;</code>:<br>保存一个单值，表示添加到状态的所有值的聚合。接口与 ListState 类似，但使用 add(T) 增加元素，会使用提供的 ReduceFunction 进行聚合。</li>
<li><code>AggregatingState&lt;IN, OUT&gt;</code>:<br>保留一个单值，表示添加到状态的所有值的聚合。和 ReducingState 相反的是, 聚合类型可能与 添加到状态的元素的类型不同。 接口与 ListState 类似，但使用 add(IN) 添加的元素会用指定的 AggregateFunction 进行聚 合。</li>
<li><code>FoldingState&lt;T, ACC&gt;</code>:<br>保留一个单值，表示添加到状态的所有值的聚合。 与 ReducingState 相反，聚合类型可能与添加到状态的元素类型不同。接口与 ListState 类似，但使用 add（T）添加的元素会用指定的 FoldFunction 折叠成聚合值。</li>
<li><code>MapState&lt;UK, UV&gt;</code>:<br>维护了一个映射列表。 你可以添加键值对到状态中，也可以获得 反映当前所有映射的迭代器。使用 put(UK，UV) 或者 putAll(Map&lt;UK，UV&gt;) 添加映射。 使用 get(UK) 检索特定 key。 使用 entries()，keys() 和 values() 分别检索映射、 键和值的可迭代视图。</li>
</ol>
<h5 id="2-Operator-State（算子状态）"><a href="#2-Operator-State（算子状态）" class="headerlink" title="2. Operator State（算子状态）"></a>2. Operator State（算子状态）</h5><p>Operator State 与 Key 无关，而是与<code>Operator</code>绑定，整个 Operator 只对应一个 State。 比如：Flink 中的 Kafka Connector 就使用了 Operator State，它会在每个 Connector 实例 中，保存该实例消费 Topic 的所有(partition, offset)映射。<img src="https://img-blog.csdnimg.cn/20200716120444192.png#pic_center" alt="在这里插入图片描述"></p>
<h5 id="3-Keyed-State-案例"><a href="#3-Keyed-State-案例" class="headerlink" title="3. Keyed State 案例"></a>3. Keyed State 案例</h5><p><a href="https://sowhat.blog.csdn.net/article/details/107323074" target="_blank" rel="noopener">demo1</a>：监控每一个手机号码，如果这个号码在5秒内，所有呼叫它的日志都是失败的，<br><code>demo2 需求</code>：计算每个手机的呼叫间隔时间，单位是毫秒。</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>state

<span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span><span class="token punctuation">{</span>URL<span class="token punctuation">,</span> URLDecoder<span class="token punctuation">}</span>

<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>BatchWordCount<span class="token punctuation">.</span>getClass
<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span>StationLog
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>RichFlatMapFunction
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>state<span class="token punctuation">.</span><span class="token punctuation">{</span>ValueState<span class="token punctuation">,</span> ValueStateDescriptor<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span>Configuration
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Collector

<span class="token comment" spellcheck="true">/**
  * 基站日志
  * @param sid      基站的id
  * @param callOut  主叫号码
  * @param callInt  被叫号码
  * @param callType 呼叫类型
  * @param callTime 呼叫时间 (毫秒)
  * @param duration 通话时长 （秒）
  */</span>
<span class="token keyword">case</span> <span class="token keyword">class</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span>sid<span class="token operator">:</span> String<span class="token punctuation">,</span> var callOut<span class="token operator">:</span> String<span class="token punctuation">,</span> var callInt<span class="token operator">:</span> String<span class="token punctuation">,</span> callType<span class="token operator">:</span> String<span class="token punctuation">,</span> callTime<span class="token operator">:</span> Long<span class="token punctuation">,</span> duration<span class="token operator">:</span> Long<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">/**
  * 第一种方法的实现
  * 统计每个手机的呼叫时间间隔，单位是毫秒
  */</span>
object TestKeyedState1 <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    <span class="token comment" spellcheck="true">//读取数据源</span>
    val filePath<span class="token operator">:</span> URL <span class="token operator">=</span> getClass<span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"/station.log"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//使用相对路径来得到完整的文件路径</span>
    val packagePath<span class="token operator">:</span> String <span class="token operator">=</span> filePath<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">replaceAll</span><span class="token punctuation">(</span><span class="token string">"%20"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//解决路径中含有空格的情况</span>
    val str<span class="token operator">:</span>String <span class="token operator">=</span> URLDecoder<span class="token punctuation">.</span><span class="token function">decode</span><span class="token punctuation">(</span>packagePath<span class="token punctuation">,</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//解决路径包含中文的情况</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        val arr<span class="token operator">:</span>Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    stream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>callOut<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//分组</span>
      <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">CallIntervalFunction</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token comment" spellcheck="true">//输出的是一个二元组（手机号码，时间间隔）</span>
  <span class="token keyword">class</span> <span class="token class-name">CallIntervalFunction</span> <span class="token keyword">extends</span> <span class="token class-name">RichFlatMapFunction</span><span class="token punctuation">[</span>StationLog<span class="token punctuation">,</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//定义一个状态，用于保存前一次呼叫的时间</span>
    <span class="token keyword">private</span> var preCallTimeState<span class="token operator">:</span> ValueState<span class="token punctuation">[</span>Long<span class="token punctuation">]</span> <span class="token operator">=</span> _

    override def <span class="token function">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      preCallTimeState <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span><span class="token function">getState</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ValueStateDescriptor</span><span class="token punctuation">[</span>Long<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"pre"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>Long<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    override def <span class="token function">flatMap</span><span class="token punctuation">(</span>value<span class="token operator">:</span> StationLog<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token comment" spellcheck="true">//从状态中取得前一次呼叫的时间</span>
      val preCallTime<span class="token operator">:</span>Long <span class="token operator">=</span> preCallTimeState<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>preCallTime <span class="token operator">==</span> null <span class="token operator">||</span> preCallTime <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//状态中没有，肯定是第一次呼叫</span>
        preCallTimeState<span class="token punctuation">.</span><span class="token function">update</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span>callTime<span class="token punctuation">)</span>
      <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//状态中有数据,则要计算时间间隔</span>
        val interval<span class="token operator">:</span>Long <span class="token operator">=</span> Math<span class="token punctuation">.</span><span class="token function">abs</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span>callTime <span class="token operator">-</span> preCallTime<span class="token punctuation">)</span>
        out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span>callOut<span class="token punctuation">,</span> interval<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果：</p>
<pre><code>4&gt; (18600003532,7000)
2&gt; (18600003713,0)
1&gt; (18600003502,9000)
1&gt; (18600003502,0)
1&gt; (18600003502,9000)
1&gt; (18600007699,0)
1&gt; (18600000005,150000)
1234567</code></pre><p>stationlog.txt文件信息如下：</p>
<pre><code>station_1,18600000005,18900007729,fail,1577080453123,0
station_1,18600000005,18900007729,success,1577080603123,349
station_8,18600007461,18900006987,barring,1577080453123,0
station_5,18600009356,18900006066,busy,1577080455129,0
station_4,18600001941,18900003949,busy,1577080455129,0
...自己造数据即可
123456</code></pre><p>还有第二种简单的方法：调用<code>flatMapWithState</code> 算子</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>state

<span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span><span class="token punctuation">{</span>URL<span class="token punctuation">,</span> URLDecoder<span class="token punctuation">}</span>

<span class="token keyword">import</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>source<span class="token punctuation">.</span>StationLog
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

<span class="token comment" spellcheck="true">/**
  * 第二种方法的实现
  * 统计每个手机的呼叫时间间隔，单位是毫秒
  */</span>
object TestKeyedState2 <span class="token punctuation">{</span>

  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    <span class="token comment" spellcheck="true">//读取数据源</span>
    val filePath<span class="token operator">:</span> URL <span class="token operator">=</span> getClass<span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"/station.log"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//使用相对路径来得到完整的文件路径</span>
    val packagePath<span class="token operator">:</span> String <span class="token operator">=</span> filePath<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">replaceAll</span><span class="token punctuation">(</span><span class="token string">"%20"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//解决路径中含有空格的情况</span>
    val str<span class="token operator">:</span> String <span class="token operator">=</span> URLDecoder<span class="token punctuation">.</span><span class="token function">decode</span><span class="token punctuation">(</span>packagePath<span class="token punctuation">,</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//解决路径包含中文的情况</span>

    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        var arr <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    stream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>callOut<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//分组</span>
      <span class="token comment" spellcheck="true">//有两种情况1、状态中有上一次的通话时间，2、没有。采用scala中的模式匹配</span>
      <span class="token punctuation">.</span>mapWithState<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">)</span><span class="token punctuation">,</span> StationLog<span class="token punctuation">]</span> <span class="token punctuation">{</span>
      <span class="token keyword">case</span> <span class="token punctuation">(</span>in<span class="token operator">:</span> StationLog<span class="token punctuation">,</span> None<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span><span class="token punctuation">(</span>in<span class="token punctuation">.</span>callOut<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">Some</span><span class="token punctuation">(</span>in<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//状态中没有值 是第一次呼叫</span>
      <span class="token keyword">case</span> <span class="token punctuation">(</span>in<span class="token operator">:</span> StationLog<span class="token punctuation">,</span> pre<span class="token operator">:</span> Some<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//状态中有值，是第二次呼叫</span>
        var interval<span class="token operator">:</span>Long <span class="token operator">=</span> Math<span class="token punctuation">.</span><span class="token function">abs</span><span class="token punctuation">(</span>in<span class="token punctuation">.</span>callTime <span class="token operator">-</span> pre<span class="token punctuation">.</span>get<span class="token punctuation">.</span>callTime<span class="token punctuation">)</span>
        <span class="token punctuation">(</span><span class="token punctuation">(</span>in<span class="token punctuation">.</span>callOut<span class="token punctuation">,</span> interval<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">Some</span><span class="token punctuation">(</span>in<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>_2 <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738394041</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="2-CheckPoint"><a href="#2-CheckPoint" class="headerlink" title="2. CheckPoint"></a>2. CheckPoint</h3><p>当程序出现问题需要恢复<code>State</code> 数据的时候，只有程序提供支持才可以实现<code>State</code> 的容错。<code>State</code> 的容错需要依靠 <code>CheckPoint</code>机制，这样才可以保证 <code>Exactly-once</code> 这种语义，但是注意，<strong>它只能保证 Flink 系统内的 Exactly-once</strong>，比如 Flink 内置支持的算子。针对 Source 和 Sink 组件，如果想要保证 Exactly-once 的话，则<strong>这些组件本身应支持这种语义</strong>。</p>
<h5 id="1-CheckPoint-原理"><a href="#1-CheckPoint-原理" class="headerlink" title="1. CheckPoint 原理"></a>1. CheckPoint 原理</h5><p>Flink 中基于<code>异步</code>轻量级的分布式快照技术提供了 <code>Checkpoints</code>容错机制，分布式快照可以将同一时间点 <code>Task/Operator</code> 的状态数据全局统一快照处理，包括前面提到的 <code>Keyed State</code>和 <code>Operator State</code>。Flink 会在输入的数据集上间隔性地生成 <code>checkpoint barrier</code>， 通过<code>栅栏</code>（barrier）将间隔时间段内的数据划分到相应的 checkpoint 中。如下图:<br><img src="https://img-blog.csdnimg.cn/20200716181419653.png#pic_center" alt="在这里插入图片描述"><br>比如序列偶数求和跟奇数求和：<br><img src="https://img-blog.csdnimg.cn/2020071618421655.png#pic_center" alt="在这里插入图片描述"></p>
<h5 id="2-CheckPoint-参数和设置"><a href="#2-CheckPoint-参数和设置" class="headerlink" title="2. CheckPoint 参数和设置"></a>2. CheckPoint 参数和设置</h5><p>默认情况下 Flink <code>不开启</code>检查点的，用户需要在程序中通过调用方法配置和开启检查点，另外还可以调整其他相关参数：</p>
<ol>
<li>Checkpoint 开启和时间间隔指定： 开启检查点并且指定检查点时间间隔为 1000ms，根据实际情况自行选择，如果状态比较大，则建议适当增加该值。<code>streamEnv.enableCheckpointing(1000)</code></li>
<li><code>exactly-ance</code> 和 <code>at-least-once</code> 语义选择：<br>选择 exactly-once 语义保证<strong>整个应用内端到端的数据一致性</strong>，这种情况比较适合于数据要求比较高，不允许出现丢数据或者数据重复，与此同时，Flink 的性能也<strong>相对较弱</strong>，而 at-least-once 语义更适合于时廷和吞吐量要求非常高但对数据的一致性要求不高的场景。 如下通过<code>setCheckpointingMode()</code>方法来设 定语义模式， <strong>默认情况 使用的是 exactly-once 模式</strong>。</li>
</ol>
<pre class="line-numbers language-java"><code class="language-java"> streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">setCheckpointingMode</span><span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>EXACT LY_ONCE<span class="token punctuation">)</span>；
 <span class="token comment" spellcheck="true">//或者 </span>
 streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">setCheckpointingMode</span><span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>AT_LE AST_ONCE<span class="token punctuation">)</span>
<span class="token number">123</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>Checkpoint 超时时间：<br>超时时间指定了每次 Checkpoint 执行过程中的上限时间范围，一旦 Checkpoint 执行时 间超过该阈值，Flink 将会中断 Checkpoint 过程，并按照超时处理。该指标可以通过 <code>setCheckpointTimeout</code> 方法设定，默认为 <code>10</code>分钟。<code>streamEnv.getCheckpointConfig.setCheckpointTimeout(50000)</code></li>
<li>检查点之间最小时间间隔：<br>该参数主要目的是<strong>设定两个 Checkpoint 之间的最小时间间隔</strong>，防止出现例如状态数据过大而导致 Checkpoint 执行时间过长，从而导致 Checkpoint 积压过多，最终 Flink 应用密集地触发 Checkpoint 操作，会占用了大量计算资源而影响到整个应用的性能。</li>
</ol>
<pre class="line-numbers language-java"><code class="language-java">streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">setMinPauseBetweenCheckpoints</span><span class="token punctuation">(</span><span class="token number">600</span><span class="token punctuation">)</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<ol>
<li>最大并行执行的检查点数量：<br>通过 <code>setMaxConcurrentCheckpoints()</code>方法设定能够最大同时执行的 Checkpoint 数量。 在默认情况下只有一个检查点可以运行，根据用户指定的数量可以同时触发多个 Checkpoint，进而提升 Checkpoint 整体的效率。</li>
</ol>
<pre class="line-numbers language-java"><code class="language-java">streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">setMaxConcurrentCheckpoints</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<ol>
<li>是否删除 Checkpoint 中保存的数据：<br>设置为 <code>RETAIN_ON_CANCELLATION</code>：表示一旦 Flink 处理程序被 cancel 后，会保留 CheckPoint 数据，以便根据实际需要恢复到指定的 CheckPoint。 设置为 <code>DELETE_ON_CANCELLATION</code>：表示一旦 Flink 处理程序被 cancel 后，会删除 CheckPoint 数据，只有 Job 执行失败的时候才会保存 CheckPoint。</li>
</ol>
<pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//删除 </span>
streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">enableExternalizedCheckpoints</span><span class="token punctuation">(</span>ExternalizedCheckp ointCleanup<span class="token punctuation">.</span>DELETE_ON_CANCELLATION<span class="token punctuation">)</span> 
<span class="token comment" spellcheck="true">//保留</span>
streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">enableExternalizedCheckpoints</span><span class="token punctuation">(</span>ExternalizedCheckp ointCleanup<span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span>
<span class="token number">1234</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>TolerableCheckpointFailureNumber：<br>设置可以容忍的检查的失败数，超过这个数量则系统自动关闭和停止任务。</li>
</ol>
<pre class="line-numbers language-java"><code class="language-java"> streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">setTolerableCheckpointFailureNumber</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h5 id="3-保存机制-StateBackend-状态后端"><a href="#3-保存机制-StateBackend-状态后端" class="headerlink" title="3. 保存机制 StateBackend(状态后端)"></a>3. 保存机制 StateBackend(状态后端)</h5><p>默认情况下，State 会保存在 TaskManager 的<code>内存</code>中，<code>CheckPoint</code>会存储在 <code>JobManager</code>的内存中。<code>State</code>和 <code>CheckPoint</code>的存储位置取决于<code>StateBackend</code>的配置。Flink 一共提供 了 3 种 <code>StateBackend</code>。包括基于内存的 <code>MemoryStateBackend</code>、基于文件系统的<code>FsStateBackend</code>，以及基于 <code>RockDB</code> 作为存储介质的 <code>RocksDBState-Backend</code>。</p>
<h6 id="1-MemoryStateBackend"><a href="#1-MemoryStateBackend" class="headerlink" title="1. MemoryStateBackend"></a>1. MemoryStateBackend</h6><p>基于内存的状态管理具有非常<code>快速</code>和<code>高效</code>的特点，但也具有非常多的限制，最主要的就 是内存的容量限制，一旦存储的状态数据过多就会导致系统内存溢出等问题，从而影响整个 应用的正常运行。同时如果机器出现问题，整个主机内存中的状态数据都会丢失，进而无法 恢复任务中的状态数据。因此从数据安全的角度建议用户<code>尽可能地避免</code>在生产环境中使用 MemoryStateBackend。<br><img src="https://img-blog.csdnimg.cn/20200716211157372.png#pic_center" alt="在这里插入图片描述"></p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 设定存储空间为10G</span>
streamEnv<span class="token punctuation">.</span><span class="token function">setStateBackend</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MemoryStateBackend</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token operator">*</span><span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token number">12</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h6 id="2-FsStateBackend"><a href="#2-FsStateBackend" class="headerlink" title="2. FsStateBackend"></a>2. FsStateBackend</h6><p>和 <code>MemoryStateBackend</code>有所不同，FsStateBackend 是<code>基于文件系统</code>的一种状态管理器， 这里的文件系统可以是本地文件系统，也可以是 HDFS 分布式文件系统。FsStateBackend 更适合任务状态非常大的情况，例如应用中含有时间范围非常长的窗口计算，或 Key/value State 状态数据量非常大的场景。<br>TaskManager仍然使用内存保存数据，但是进行CheckPoint的时候是<strong>将数据保存到FS中</strong>。<br><img src="https://img-blog.csdnimg.cn/20200716211942762.png#pic_center" alt="在这里插入图片描述"></p>
<pre class="line-numbers language-java"><code class="language-java"> streamEnv<span class="token punctuation">.</span><span class="token function">setStateBackend</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FsStateBackend</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop101:9000/checkpoint/cp1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h6 id="3-RocksDBStateBackend"><a href="#3-RocksDBStateBackend" class="headerlink" title="3. RocksDBStateBackend"></a>3. RocksDBStateBackend</h6><p>RocksDBStateBackend 是 Flink 中内置的第三方状态管理器，和前面的状态管理器不同，RocksDBStateBackend 需要单独引入相关的依赖包到工程中。</p>
<pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-statebackend-rocksdb_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
12345<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>RocksDBStateBackend 采用<code>异步</code>的方式进行状态数据的 <code>Snapshot</code>，任务中的状态数据首先被写入本地 RockDB 中，这样在 RockDB 仅会存储正在进行计算的热数据，而需要进行 CheckPoint 的时候，会把本地的数据直接复制到远端的 FileSystem 中。</p>
<p>与 FsStateBackend 相比，RocksDBStateBackend 在性能上要比 FsStateBackend 高一些，主要是因为借助于 RocksDB 在本地存储了最新热数据，然后通过异步的方式再同步到文件系 统中，但 <code>RocksDBStateBackend</code>和 <code>MemoryStateBackend</code>相比性能就会较弱一些。RocksDB 克服了 State 受内存限制的缺点，同时又能够持久化到远端文件系统中，推荐在生产中使用。</p>
<pre class="line-numbers language-java"><code class="language-java"> streamEnv<span class="token punctuation">.</span><span class="token function">setStateBackend</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">RocksDBStateBackend</span> <span class="token punctuation">(</span><span class="token string">"hdfs://hadoop101:9000/checkpoint/cp2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/20200716212307419.png#pic_center" alt="在这里插入图片描述"></p>
<h6 id="4-全局配置-StateBackend"><a href="#4-全局配置-StateBackend" class="headerlink" title="4. 全局配置 StateBackend"></a>4. 全局配置 StateBackend</h6><p>以上的代码都是<code>单 job</code> 配置状态后端，也可以全局配置状态后端，需要修改 flink-conf.yaml 配置文件:</p>
<pre class="line-numbers language-java"><code class="language-java">state<span class="token punctuation">.</span>backend<span class="token operator">:</span> filesystem
filesystem 表示使用 FsStateBackend<span class="token punctuation">,</span> 
jobmanager 表示使用 MemoryStateBackend 
rocksdb 表示使用 RocksDBStateBackend。
<span class="token operator">--</span><span class="token operator">-</span>
flink<span class="token operator">-</span>conf<span class="token punctuation">.</span>yaml 配置文件中
state<span class="token punctuation">.</span>checkpoints<span class="token punctuation">.</span>dir<span class="token operator">:</span> hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop101<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">/</span>checkpoints
<span class="token number">1234567</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>默认情况下，如果设置了 CheckPoint 选项，则 Flink 只保留最近成功生成的 1 个 CheckPoint，而当 Flink 程序失败时，可以通过最近的 CheckPoint 来进行恢复。但是，如果希望保留多个CheckPoint，并能够根据实际需要选择其中一个进行恢复，就会更加灵活。 添加如下配置，指定最多可以保存的 CheckPoint 的个数。</p>
<pre class="line-numbers language-java"><code class="language-java">state<span class="token punctuation">.</span>checkpoints<span class="token punctuation">.</span>num<span class="token operator">-</span>retained<span class="token operator">:</span> <span class="token number">2</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h5 id="4-Checkpoint案例"><a href="#4-Checkpoint案例" class="headerlink" title="4. Checkpoint案例"></a>4. Checkpoint案例</h5><p><code>案例</code>:设置 HDFS 文件系统的状态后端，取消 Job 之后再次恢复 Job。<br>使用WordCount案例来测试一下HDFS的状态后端，先运行一段时间Job，然后cancel，在重新启动，看看状态是否是连续的</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>state

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>filesystem<span class="token punctuation">.</span>FsStateBackend
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>CheckpointingMode
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span>CheckpointConfig<span class="token punctuation">.</span>ExternalizedCheckpointCleanup
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment

object TestCheckPointByHDFS <span class="token punctuation">{</span>
  <span class="token comment" spellcheck="true">//使用WordCount案例来测试一下HDFS的状态后端，先运行一段时间Job，然后cancel，在重新启动，看看状态是否是连续的</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//1、初始化Flink流计算的环境</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//开启CheckPoint并且设置一些参数</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">enableCheckpointing</span><span class="token punctuation">(</span><span class="token number">5000</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//每隔5秒开启一次CheckPoint</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setStateBackend</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FsStateBackend</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop101:9000/checkpoint/cp1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//存放检查点数据</span>

    streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">setCheckpointingMode</span><span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">setCheckpointTimeout</span><span class="token punctuation">(</span><span class="token number">5000</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">setMaxConcurrentCheckpoints</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span><span class="token function">enableExternalizedCheckpoints</span><span class="token punctuation">(</span>ExternalizedCheckpointCleanup<span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//终止job保留检查的数据</span>
    <span class="token comment" spellcheck="true">//修改并行度</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//默认所有算子的并行度为1</span>
    <span class="token comment" spellcheck="true">//2、导入隐式转换</span>
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    <span class="token comment" spellcheck="true">//3、读取数据,读取sock流中的数据</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">,</span> <span class="token number">8888</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//DataStream ==> spark 中Dstream</span>
    <span class="token comment" spellcheck="true">//4、转换和处理数据</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//分组算子  : 0 或者 1 代表下标。前面的DataStream[二元组] , 0代表单词 ，1代表单词出现的次数</span>
      <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//聚会累加算子</span>

    <span class="token comment" spellcheck="true">//5、打印结果</span>
    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"结果"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//6、启动流计算程序</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"wordcount"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>打包上传到WebUI:<br><img src="https://img-blog.csdnimg.cn/20200722193339771.png#pic_center" alt="在这里插入图片描述"></p>
<p>在<code>nc -lk 8888</code> 输入若干单词。然后查找 WebUI 的输出。然后通过WebUI将任务取消。最后尝试将任务重启。</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token punctuation">.</span>/flink run <span class="token operator">-</span>d <span class="token operator">-</span>s hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop101<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">/</span>checkpoint<span class="token operator">/</span>cp1<span class="token operator">/</span>精确到跟meta数据同级目录 <span class="token operator">-</span>c com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>state<span class="token punctuation">.</span>CheckpointOnFsBackend <span class="token operator">/</span>home<span class="token operator">/</span>Flink<span class="token operator">-</span>Demo<span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span>SNAPSHOT<span class="token punctuation">.</span>jar
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>也可以通过WebUI 重启，指定 MainClass跟 CheckPoint即可。此处关键在于CheckPoint路径要写对！</p>
<h5 id="5-SavePoint"><a href="#5-SavePoint" class="headerlink" title="5. SavePoint"></a>5. SavePoint</h5><p><strong>Savepoints 是检查点的一种特殊实现</strong>，底层实现其实也是使用 Checkpoints 的机制。 Savepoints 是用户以<code>手工命令</code>的方式触发 Checkpoint,并将结果持久化到指定的存储路径 中，其主要目的是帮助用户在升级和维护集群过程中保存系统中的状态数据，避免因为停机运维或者升级应用等正常终止应用的操作而导致系统无法恢复到原有的计算状态的情况，从而无法实现从端到端的 Excatly-Once 语义保证。</p>
<p><strong>配置 Savepoints 的存储路径</strong><br>在 flink-conf.yaml 中配置 SavePoint 存储的位置，设置后，如果要创建指定 Job 的 SavePoint，可以不用在手动执行命令时指定 SavePoint 的位置。</p>
<pre class="line-numbers language-java"><code class="language-java">state<span class="token punctuation">.</span>savepoints<span class="token punctuation">.</span>dir<span class="token operator">:</span> hdfs<span class="token operator">:</span><span class="token operator">/</span>hadoop101<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">/</span>savepoints
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><strong>在代码中设置算子 ID</strong><br>为了能够在作业的不同版本之间以及 Flink 的不同版本之间顺利升级，<strong>强烈推荐程序员 通过手动给算子赋予 ID</strong>，这些 ID 将用于确定每一个算子的状态范围。如果不手动给各算子 指定 ID，则会由 Flink 自动给每个算子生成一个 ID。而这些自动生成的 ID 依赖于程序的结 构，并且对代码的更改是很敏感的。因此，强烈建议用户手动设置 ID。</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>sowhat<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>state

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>StreamExecutionEnvironment
object TestSavePoints <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//1、初始化Flink流计算的环境</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment" spellcheck="true">//修改并行度</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//默认所有算子的并行度为1</span>
    <span class="token comment" spellcheck="true">//2、导入隐式转换</span>
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    <span class="token comment" spellcheck="true">//3、读取数据,读取sock流中的数据</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">,</span><span class="token number">8888</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//DataStream ==> spark 中Dstream</span>
    <span class="token punctuation">.</span><span class="token function">uid</span><span class="token punctuation">(</span><span class="token string">"socket001"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//4、转换和处理数据</span>
    val result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">uid</span><span class="token punctuation">(</span><span class="token string">"flatmap001"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">uid</span><span class="token punctuation">(</span><span class="token string">"map001"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//分组算子  : 0 或者 1 代表下标。前面的DataStream[二元组] , 0代表单词 ，1代表单词出现的次数</span>
      <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">uid</span><span class="token punctuation">(</span><span class="token string">"sum001"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//5、打印结果</span>
    result<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"结果"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//6、启动流计算程序</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"wordcount"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>触发 SavePoint</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//先启动Job</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop101</span> bin<span class="token punctuation">]</span># <span class="token punctuation">.</span>/flink run <span class="token operator">-</span>c com<span class="token punctuation">.</span>bjsxt<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>state<span class="token punctuation">.</span>TestSavepoints <span class="token operator">-</span>d <span class="token operator">/</span>home<span class="token operator">/</span>Flink<span class="token operator">-</span>Demo<span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span>SNAPSHOT<span class="token punctuation">.</span>jar
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop101</span> bin<span class="token punctuation">]</span># <span class="token punctuation">.</span>/flink list 获取 job 对应ID
<span class="token comment" spellcheck="true">//再取消Job </span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop101</span> bin<span class="token punctuation">]</span># <span class="token punctuation">.</span>/flink savepoint 6ecb8cfda5a5200016ca6b01260b94ce 
<span class="token comment" spellcheck="true">// 触发SavePoint</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop101</span> bin<span class="token punctuation">]</span># <span class="token punctuation">.</span>/flink cancel 6ecb8cfda5a5200016ca6b01260b94ce
<span class="token number">1234567</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>从 SavePoint 启动 Job</strong><br>大致方法跟上面的CheckPoint启动Job类似。</p>
<h5 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h5><p>若干个常用的状态算子大致如何存储的要了解。<br>CheckPoint的原理主要是<strong>图示</strong>，理解如何保证精准一致性的。<br>CheckPoint一般有基于内存的，基于HDFS的跟基于DB的，整体来说基于DB的把数据存储早DB中跟HDFS中是最好的。<br>SavePoint是手动触发的CheckPoint，一般方便线上迁移的功能等，并且尽量给每一个算子自定义一个UID，</p>
<h1 id="6-Window-窗口"><a href="#6-Window-窗口" class="headerlink" title="6. Window 窗口"></a>6. Window 窗口</h1><p><code>无界数据变为若干个有界数据</code>。Windows 计算是流式计算中非常常用的数据计算方式之一，通过按照固定时间或长度将数据流切分成不同的窗口，然后对数据进行相应的聚合运算，从而得到一定时间范围内的统计结果。例如统计最近 5 分钟内某基站的呼叫数，此时基站的数据在不断地产生，但是通过 5 分钟的窗口将数据限定在固定时间范围内，就可以对该范围内的有界数据执行聚合处理， 得出最近 5 分钟的基站的呼叫数量。</p>
<h3 id="1-Window分类"><a href="#1-Window分类" class="headerlink" title="1. Window分类"></a>1. Window分类</h3><h5 id="1-Global-Window-和-Keyed-Window"><a href="#1-Global-Window-和-Keyed-Window" class="headerlink" title="1. Global Window 和 Keyed Window"></a>1. Global Window 和 Keyed Window</h5><p>在运用窗口计算时，Flink根据上游数据集<strong>是否为KeyedStream类型</strong>，对应的Windows 也 会有所不同。</p>
<ul>
<li>Keyed Window: 上游数据集如果是 KeyedStream 类型，则调用 DataStream API 的<code>window()</code>方法，数据会根据 Key 在不同的 Task 实例中并行分别计算，最后得出针对每个 Key 统计的结果。</li>
<li>Global Window:如果是 Non-Keyed 类型，则调用 <code>WindowsAll()</code>方法，所有的<strong>数据都会在窗口算子中由到一个 Task 中计算</strong>，并得到全局统计结果。</li>
</ul>
<pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//读取文件数据</span>
val data <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span>getClass<span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"/station.log"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getPath<span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line<span class="token operator">=</span><span class="token operator">></span><span class="token punctuation">{</span>
var arr <span class="token operator">=</span>line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span> <span class="token keyword">new</span>
<span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>to Long<span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">//Global Window </span>
data<span class="token punctuation">.</span><span class="token function">windowAll</span><span class="token punctuation">(</span>自定义的WindowAssigner<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">//Keyed Window</span>
data<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>sid<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span>自定义的WindowAssigner<span class="token punctuation">)</span>
<span class="token number">12345678910</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="2-Time-Window-和-Count-Window"><a href="#2-Time-Window-和-Count-Window" class="headerlink" title="2. Time Window 和 Count Window"></a>2. Time Window 和 Count Window</h5><p>基于业务数据的方面考虑，Flink 又支持两种类型的窗口，一种是基于时间的窗口叫<code>Time Window</code>。还有一种基于输入数据数量的窗口叫 <code>Count Window</code></p>
<h5 id="3-Time-Window-时间窗口"><a href="#3-Time-Window-时间窗口" class="headerlink" title="3. Time Window(时间窗口)"></a>3. Time Window(时间窗口)</h5><p>根据不同的业务场景，Time Window 也可以分为三种类型，分别是<code>滚动窗口</code>(Tumbling Window)、<code>滑动窗口</code>(Sliding Window)和<code>会话窗口</code>(Session Window)</p>
<ol>
<li>滚动窗口(Tumbling Window)<br>滚动窗口是根据固定时间进行切分，且窗口和窗口之间的元素<code>互不重叠</code>。这种类型的窗 口的最大特点是比较简单。只需要指定一个窗口长度(window size)。<br><img src="https://img-blog.csdnimg.cn/20200716230654378.png#pic_center" alt="在这里插入图片描述"></li>
</ol>
<pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//每隔5秒统计每个基站的日志数量 </span>
data<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>stationLog<span class="token operator">=</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">(</span>stationLog<span class="token punctuation">.</span>sid<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token comment" spellcheck="true">//.window(TumblingEventTimeWindows.of(Time.seconds(5))) 跟上面同样功能</span>
<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//聚合</span>
<span class="token number">123456</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>其中时间间隔可以是 Time.milliseconds(x)、Time.seconds(x)或 Time.minutes(x)。</p>
<ol>
<li>滑动窗口(Sliding Window)<br>滑动窗口也是一种比较常见的窗口类型，其特点是在滚动窗口基础之上增加了窗口滑动时间(Slide Time)，且允许窗口数据发生重叠。当 Windows size 固定之后，窗口并不像 滚动窗口按照 Windows Size 向前移动，而是根据设定的 Slide Time 向前滑动。窗口之间的 数据重叠大小根据 Windows size 和 Slide time 决定，当 Slide time 小于 Windows size 便会发生窗口重叠，Slide size 大于 Windows size 就会出现窗口不连续，数据可能不能在 任何一个窗口内计算，Slide size 和 Windows size 相等时，Sliding Windows 其实就是 Tumbling Windows。<br><img src="https://img-blog.csdnimg.cn/20200716230931751.png#pic_center" alt="在这里插入图片描述"></li>
</ol>
<pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//每隔3秒计算最近5秒内，每个基站的日志数量 </span>
data<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>stationLog<span class="token operator">=</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">(</span>stationLog<span class="token punctuation">.</span>sid<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//.window(SlidingEventTimeWindows.of(Time.seconds(5),Time.seconds(3)))</span>
<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token number">12345</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>会话窗口(Session Window)<br>会话窗口(Session Windows)主要是将某段时间内活跃度较高的数据聚合成一个窗口 进行计算，窗口的触发的条件是 <code>Session Gap</code>，是指<code>在规定的时间内如果没有数据活跃接入</code>， 则认为窗口结束，然后触发窗口计算结果。需要注意的是如果数据一直不间断地进入窗口， 也会导致窗口始终不触发的情况。与滑动窗口、滚动窗口不同的是，Session Windows 不需 要有固定 windows size 和 slide time，只需要定义 session gap，来规定不活跃数据的时 间上限即可。<br><img src="https://img-blog.csdnimg.cn/20200716231110572.png#pic_center" alt="在这里插入图片描述"></li>
</ol>
<pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//3秒内如果没有数据进入，则计算每个基站的日志数量</span>
 data<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>stationLog<span class="token operator">=</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">(</span>stationLog<span class="token punctuation">.</span>sid<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span>EventTimeSessionWindows<span class="token punctuation">.</span><span class="token function">withGap</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token number">123</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="4-Count-Window-数量窗口"><a href="#4-Count-Window-数量窗口" class="headerlink" title="4. Count Window(数量窗口)"></a>4. Count Window(数量窗口)</h5><p>Count Window 也有滚动窗口、滑动窗口等。由于使用比较少TODO，比如五条数据算一批次这样的统计。</p>
<h3 id="2-Window的API"><a href="#2-Window的API" class="headerlink" title="2. Window的API"></a>2. Window的API</h3><p>在以后的实际案例中 <code>Keyed Window</code>使用最多，所以我们需要掌握 Keyed Window 的算子， 在每个窗口算子中包含了 Windows Assigner、Windows Trigger(窗口触发器)、Evictor (数据剔除器)、Lateness(时延设定)、Output Tag(输出标签)以及 Windows Funciton 等组成部分，其中 Windows Assigner 和 Windows Funciton 是所有窗口算子<code>必须指定</code>的属性， 其余的属性都是根据实际情况选择指定。</p>
<pre class="line-numbers language-java"><code class="language-java">stream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// 是Keyed类型数据集</span>
<span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//指定窗口分配器类型</span>
<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">trigger</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">//指定触发器类型(可选)</span>
<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">evictor</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">//指定evictor或者不指定(可选) </span>
<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">allowedLateness</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">//指定是否延迟处理数据(可选) </span>
<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">sideOutputLateData</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">//指定Output Lag(可选) </span>
<span class="token punctuation">.</span>reduce<span class="token operator">/</span>aggregate<span class="token operator">/</span>fold<span class="token operator">/</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//指定窗口计算函数</span>
<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">//根据Tag输出数据(可选)</span>
<span class="token number">12345678</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>Windows Assigner: 指定窗口的类型，定义如何将数据流分配到一个或多个窗口。</li>
<li>Windows Trigger: 指定窗口触发的时机，定义窗口满足什么样的条件触发计算。</li>
<li>Evictor: 用于数据剔除。</li>
<li>allowedLateness: 标记是否处理迟到数据，当迟到数据到达窗口中是否触发计算。</li>
<li>Output Tag: 标记输出标签，然后在通过 getSideOutput 将窗口中的数据根据标签输出。</li>
<li>Windows Funciton: 定义窗口上数据处理的逻辑，例如对数据进行 sum 操作。</li>
</ul>
<h3 id="3-窗口聚合函数"><a href="#3-窗口聚合函数" class="headerlink" title="3. 窗口聚合函数"></a>3. 窗口聚合函数</h3><p>如果定义了 Window Assigner 之后，下一步就可以定义窗口内数据的计算逻辑，这也就是 Window Function 的定义。Flink 中提供了四种类型的 Window Function，分别为 <code>ReduceFunction</code>、<code>AggregateFunction</code> 以及 <code>ProcessWindowFunction</code>,<code>（sum 和 max)</code>等。 前三种类型的 Window Fucntion 按照计算原理的不同可以分为两大类：</p>
<ul>
<li>一类是<strong>增量</strong>聚合函数：对应有 <code>ReduceFunction</code>、<code>AggregateFunction</code>；</li>
<li>另一类是全量窗口函数，对应有 <code>ProcessWindowFunction</code>（还有 <code>WindowFunction</code>）。</li>
</ul>
<p>增量聚合函数计算性能较高，占用存储空间少，主要因为<strong>基于中间状态的计算结果</strong>，窗口中只维护中间结果状态值，不需要缓存原始数据。而全量窗口函数使用的代价相对较高， 性能比较弱，主要因为此时算子需要对所有属于该窗口的接入数据进行缓存，然后等到窗口触发的时候，对所有的原始数据进行汇总计算。</p>
<h5 id="1-ReduceFunction"><a href="#1-ReduceFunction" class="headerlink" title="1. ReduceFunction"></a>1. ReduceFunction</h5><p>Reduce要求输入跟输出类型要一样！这点切记。<br><code>需求</code>：每隔5秒统计每个基站的日志数量</p>
<pre class="line-numbers language-java"><code class="language-java">object TestReduceFunctionByWindow <span class="token punctuation">{</span>

  <span class="token comment" spellcheck="true">//每隔5秒统计每个基站的日志数量</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    <span class="token comment" spellcheck="true">//读取数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">,</span> <span class="token number">8888</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        val arr <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//开窗</span>
    stream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>log <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span><span class="token punctuation">(</span>log<span class="token punctuation">.</span>sid<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//开窗</span>
      <span class="token punctuation">.</span><span class="token function">reduce</span><span class="token punctuation">(</span><span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span>t1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t1<span class="token punctuation">.</span>_2 <span class="token operator">+</span> t2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">123456789101112131415161718192021222324</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="2-AggregateFunction"><a href="#2-AggregateFunction" class="headerlink" title="2. AggregateFunction"></a>2. AggregateFunction</h5><p>和 ReduceFunction 相似，AggregateFunction 也是基于<strong>中间</strong>状态计算结果的增量计算 函数，但 AggregateFunction 在窗口计算上更加通用。AggregateFunction 接口相对 ReduceFunction 更加灵活，输入跟输出类型不要求完全一致，实现复杂度也相对较高。AggregateFunction 接口中定义了三个 需要复写的方法，其中 add()定义数据的添加逻辑，getResult 定义了根据 accumulator 计 算结果的逻辑，merge 方法定义合并 accumulator 的逻辑。初始化，<a href="https://blog.csdn.net/chilimei8516/article/details/100796930" target="_blank" rel="noopener">分区内如何处理</a>，分区间如何处理，最终如何输出。</p>
<p><code>需求</code>：每隔3秒计算最近5秒内，每个基站的日志数量</p>
<pre class="line-numbers language-java"><code class="language-java">object TestAggregatFunctionByWindow <span class="token punctuation">{</span>

  <span class="token comment" spellcheck="true">//每隔3秒计算最近5秒内，每个基站的日志数量</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_

    <span class="token comment" spellcheck="true">//读取数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">,</span> <span class="token number">8888</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        val arr <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//开窗</span>
    val value<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>log <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span><span class="token punctuation">(</span>log<span class="token punctuation">.</span>sid<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span>SlidingProcessingTimeWindows<span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//开窗，滑动窗口</span>
      <span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyAggregateFunction</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">MyWindowFunction</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">// 到底是数字对应哪个基站</span>
      <span class="token comment" spellcheck="true">// aggregate(增量函数，全量函数)</span>
    value<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token comment" spellcheck="true">/**
    * 里面的add方法，是来一条数据执行一次，getResult在窗口结束的时候执行一次
    * in,累加器acc,out
    * https://blog.csdn.net/chilimei8516/article/details/100796930
    */</span>
  <span class="token keyword">class</span> <span class="token class-name">MyAggregateFunction</span> <span class="token keyword">extends</span> <span class="token class-name">AggregateFunction</span><span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Long<span class="token punctuation">]</span> <span class="token punctuation">{</span>
    override def <span class="token function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Long <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment" spellcheck="true">//初始化一个累加器 acc，开始的时候为0</span>
    <span class="token comment" spellcheck="true">// 分区内操作</span>
    override def <span class="token function">add</span><span class="token punctuation">(</span>value<span class="token operator">:</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> accumulator<span class="token operator">:</span> Long<span class="token punctuation">)</span><span class="token operator">:</span> Long <span class="token operator">=</span> accumulator <span class="token operator">+</span> value<span class="token punctuation">.</span>_2
    <span class="token comment" spellcheck="true">// 结果返回</span>
    override def <span class="token function">getResult</span><span class="token punctuation">(</span>accumulator<span class="token operator">:</span> Long<span class="token punctuation">)</span><span class="token operator">:</span> Long <span class="token operator">=</span> accumulator
    <span class="token comment" spellcheck="true">// 分区间操作</span>
    override def <span class="token function">merge</span><span class="token punctuation">(</span>a<span class="token operator">:</span> Long<span class="token punctuation">,</span> b<span class="token operator">:</span> Long<span class="token punctuation">)</span><span class="token operator">:</span> Long <span class="token operator">=</span> a <span class="token operator">+</span> b
  <span class="token punctuation">}</span>

  <span class="token comment" spellcheck="true">// WindowFunction 输入数据来自于AggregateFunction ，</span>
  <span class="token comment" spellcheck="true">// 在窗口结束的时候先执行AggregateFunction对象的getResult，然后再执行apply</span>
  <span class="token comment" spellcheck="true">// in,out,key,window   </span>
  <span class="token keyword">class</span> <span class="token class-name">MyWindowFunction</span> <span class="token keyword">extends</span> <span class="token class-name">WindowFunction</span><span class="token punctuation">[</span>Long<span class="token punctuation">,</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">)</span><span class="token punctuation">,</span> String<span class="token punctuation">,</span> TimeWindow<span class="token punctuation">]</span> <span class="token punctuation">{</span>
    override def <span class="token function">apply</span><span class="token punctuation">(</span>key<span class="token operator">:</span> String<span class="token punctuation">,</span> window<span class="token operator">:</span> TimeWindow<span class="token punctuation">,</span> input<span class="token operator">:</span> Iterable<span class="token punctuation">[</span>Long<span class="token punctuation">]</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
      out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> input<span class="token punctuation">.</span>iterator<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//next得到第一个值，迭代器中只有一个值</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">123456789101112131415161718192021222324252627282930313233343536373839404142434445464748</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="3-ProcessWindowFunction"><a href="#3-ProcessWindowFunction" class="headerlink" title="3. ProcessWindowFunction"></a>3. ProcessWindowFunction</h5><p>前面提到的<code>ReduceFunction</code>和 <code>AggregateFunction</code> 都是基于中间状态实现增量计算的 窗口函数，虽然已经满足绝大多数场景，但在某些情况下，统计更复杂的指标可能需要依赖于窗口中<strong>所有</strong>的数据元素，或需要操作窗口中的状态数据和窗口元数据，这时就需要使用到 <code>ProcessWindowsFunction</code>，<code>ProcessWindowsFunction</code>能够更加灵活地支持基于窗口全部数据元素的结果计算 ， 例如对整个窗口 数 据排序取TopN， 这样的需要就必须使用<code>ProcessWindowFunction</code>。</p>
<p><code>需求</code>：每隔5秒统计每个基站的日志数量</p>
<pre class="line-numbers language-java"><code class="language-java">object TestProcessWindowFunctionByWindow <span class="token punctuation">{</span>

  <span class="token comment" spellcheck="true">//每隔5秒统计每个基站的日志数量</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val streamEnv<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>_
    streamEnv<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//读取数据源</span>
    val stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>StationLog<span class="token punctuation">]</span> <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"hadoop101"</span><span class="token punctuation">,</span> <span class="token number">8888</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
        var arr <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token keyword">new</span> <span class="token class-name">StationLog</span><span class="token punctuation">(</span><span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> <span class="token function">arr</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">//开窗</span>
    stream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>log <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span><span class="token punctuation">(</span>log<span class="token punctuation">.</span>sid<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// .timeWindow(Time.seconds(5))//开窗</span>
      <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span>TumblingProcessingTimeWindows<span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProcessWindowFunction</span><span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">)</span><span class="token punctuation">,</span> String<span class="token punctuation">,</span> TimeWindow<span class="token punctuation">]</span> <span class="token punctuation">{</span> 
      <span class="token comment" spellcheck="true">//一个窗口结束的时候调用一次(一个分组执行一次)    in,out,key,windows</span>
        override def <span class="token function">process</span><span class="token punctuation">(</span>key<span class="token operator">:</span> String<span class="token punctuation">,</span> context<span class="token operator">:</span> Context<span class="token punctuation">,</span> elements<span class="token operator">:</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
          <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"------------"</span><span class="token punctuation">)</span>
          <span class="token comment" spellcheck="true">//注意：整个窗口的数据保存到Iterable，里面有很多行数据。Iterable的size就是日志的总条数</span>
          out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> elements<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamEnv<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>需求</code>：窗口函数读数据然后将数据写入到neo4j，感觉其实应该用 <a href="https://sowhat.blog.csdn.net/article/details/107323074" target="_blank" rel="noopener">自定的Sink</a> 更合适一些。</p>
<pre class="line-numbers language-java"><code class="language-java">object DealDataFromKafka <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
    val environment<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    environment<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    val properties<span class="token operator">:</span> Properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"IP1:9092,IP2:9092"</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"timer"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">// 从最新数据开始读</span>
    properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">//val dataStream: DataStream[String] = environment.addSource(new FlinkKafkaConsumer011[String]("sowhat", new SimpleStringSchema(), properties))</span>
    val dataStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> environment<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"IP"</span><span class="token punctuation">,</span> <span class="token number">8889</span><span class="token punctuation">)</span>

    val winData<span class="token operator">:</span> AllWindowedStream<span class="token punctuation">[</span>String<span class="token punctuation">,</span> TimeWindow<span class="token punctuation">]</span> <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">timeWindowAll</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    var pre<span class="token operator">:</span> Int <span class="token operator">=</span> <span class="token number">0</span>
    var tmp<span class="token operator">:</span> Int <span class="token operator">=</span> <span class="token number">0</span>
    val timeWithHashCode<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span>Int<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> winData<span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProcessAllWindowFunction</span><span class="token punctuation">[</span>String<span class="token punctuation">,</span> <span class="token punctuation">(</span>Int<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">,</span> TimeWindow<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      override def <span class="token function">process</span><span class="token punctuation">(</span>context<span class="token operator">:</span> Context<span class="token punctuation">,</span> elements<span class="token operator">:</span> Iterable<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span>Int<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>
        val driver<span class="token operator">:</span> Driver <span class="token operator">=</span> GraphDatabase<span class="token punctuation">.</span><span class="token function">driver</span><span class="token punctuation">(</span><span class="token string">"bolt://IP:9314"</span><span class="token punctuation">,</span> AuthTokens<span class="token punctuation">.</span><span class="token function">basic</span><span class="token punctuation">(</span><span class="token string">"neo4j"</span><span class="token punctuation">,</span> <span class="token string">"neo4j0fcredithc"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        val session<span class="token operator">:</span> Session <span class="token operator">=</span> driver<span class="token punctuation">.</span><span class="token function">session</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        elements<span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>value <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">{</span>
          tmp <span class="token operator">+=</span> <span class="token number">1</span>
          var now<span class="token operator">:</span> Int <span class="token operator">=</span> value<span class="token punctuation">.</span>hashCode
          now <span class="token operator">=</span> tmp
          session<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>s<span class="token string">"CREATE (a:Test {id:${now}, time:'${value}'})"</span><span class="token punctuation">)</span>
          <span class="token keyword">if</span> <span class="token punctuation">(</span>pre <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            session<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>s<span class="token string">"MATCH (begin:Test{id:${pre}}) ,(end:Test{id:${now}})   MERGE (begin)-[like:Time_Link]->(end)"</span><span class="token punctuation">)</span>
          <span class="token punctuation">}</span>
          out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">(</span>tmp<span class="token punctuation">,</span> s<span class="token string">" MATCH (begin:Test{id:${pre}}) ,(end:Test{id:${now}})   MERGE (begin)-[like:Time_Link]->(end)"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          pre <span class="token operator">=</span> now
        <span class="token punctuation">}</span>
        <span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">//        session.close()</span>
        <span class="token comment" spellcheck="true">//        driver.close()</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    timeWithHashCode<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"HashCode With time:"</span><span class="token punctuation">)</span>
    environment<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"getData"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token number">1234567891011121314151617181920212223242526272829303132333435363738394041</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>窗口的分类从不同的维度来说，</p>
<ol>
<li>上游是否为KeyedStream，不同数据集调用不同方法。</li>
<li>根据上游数据是时间窗口(滚动窗口、滑动窗口、会话窗口)还是数据量窗口。</li>
<li>窗口若干API调用方法，窗口的聚合函数(reduceFunction、AggregateFunction、ProcessWindowFunction、WindowFunction)。</li>
</ol>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://dataquaner.github.io" rel="external nofollow noreferrer">Leon</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://dataquaner.github.io/2020/11/11/flink-san-tian-ru-men/">https://dataquaner.github.io/2020/11/11/flink-san-tian-ru-men/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://dataquaner.github.io" target="_blank">Leon</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Flink/">
                                    <span class="chip bg-color">Flink</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'c5c6577b4ba11079d15e',
        clientSecret: '525eed73bef797acbfdb9332bc45bdbfe28010da',
        repo: 'dataquaner.github.io',
        owner: 'dataquaner',
        admin: "dataquaner",
        id: '2020-11-11T14-35-00',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    
    <div class="livere-card card" data-aos="fade-up">
    <!-- 来必力City版安装代码 -->
    <div id="lv-container" class="card-content" data-id="city" data-uid="MTAyMC80OTYwOC8yNjA5OQ">
        <script type="text/javascript">
            (function (d, s) {
                let j, e = d.getElementsByTagName(s)[0];
                if (typeof LivereTower === 'function') {
                    return;
                }

                j = d.createElement(s);
                j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                j.async = true;

                e.parentNode.insertBefore(j, e);
            })(document, 'script');
        </script>
        <noscript>为正常使用来必力评论功能请激活JavaScript。</noscript>
    </div>
    <!-- City版安装代码已完成 -->
</div>
    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/11/12/java-cheng-xu-de-ceng-ji-jie-gou-controller-service-dao-entity-ceng/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="Java程序的层级结构（Controller、Service、Dao、Entity层）">
                        
                        <span class="card-title">Java程序的层级结构（Controller、Service、Dao、Entity层）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Java基础
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-11-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Java/" class="post-category">
                                    Java
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Java/">
                        <span class="chip bg-color">Java</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/09/13/hive-ri-chang-shi-yong-wen-ti-ji-lu-hive-jian-biao-dao-zhi-de-orc-xu-lie-hua-cuo-wu/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/12.jpg" class="responsive-img" alt="【hive日常使用问题记录】Hive建表导致的ORC序列化错误">
                        
                        <span class="card-title">【hive日常使用问题记录】Hive建表导致的ORC序列化错误</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            问题描述：hive表在创建时候指定存储格式
STORED AS ORC 
tblproperties ('orc.compress'='SNAPPY');
 当insert数据到表时抛出异常
Caused by: java.lang.Cla
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-09-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Hive/" class="post-category">
                                    -- Hive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Hive/">
                        <span class="chip bg-color">-- Hive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>

    
<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://dataquaner.github.io" target="_blank">Leon</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">220k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2019";
                    var startMonth = "6";
                    var startDate = "28";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/dataquaner" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:dataquanerleo@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2077689752" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2077689752" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    
    <script>
        (function (i, s, o, g, r, a, m) {
            i["DaoVoiceObject"] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o), m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            a.charset = "utf-8";
            m.parentNode.insertBefore(a, m)
        })(window, document, "script", ('https:' == document.location.protocol ? 'https:' : 'http:') +
            "//widget.daovoice.io/widget/6984b559.js", "daovoice")
        daovoice('init', {
            app_id: "6de85cbf"
        });
        daovoice('update');
    </script>
    

    

    

    
    
    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
