<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>DataQuaner</title>
  
  <subtitle>DataQuaner</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://dataquaner.github.io/"/>
  <updated>2020-05-06T11:17:26.029Z</updated>
  <id>https://dataquaner.github.io/</id>
  
  <author>
    <name>Leon</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【Hive日常问题】导入数据成功，查询显示NULL</title>
    <link href="https://dataquaner.github.io/2020/05/06/hive-ri-chang-wen-ti-dao-ru-shu-ju-cheng-gong-cha-xun-xian-shi-null/"/>
    <id>https://dataquaner.github.io/2020/05/06/hive-ri-chang-wen-ti-dao-ru-shu-ju-cheng-gong-cha-xun-xian-shi-null/</id>
    <published>2020-05-06T13:40:00.000Z</published>
    <updated>2020-05-06T11:17:26.029Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><strong>问题描述</strong></h2><p>hive导入数据成功，但是查询结果为NULL：</p><pre class="line-numbers language-powershell"><code class="language-powershell">load <span class="token keyword">data</span> local inpath <span class="token string">'/user/hive/student.txt'</span> into table hive_test<span class="token punctuation">.</span>students<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-powershell"><code class="language-powershell">Loading <span class="token keyword">data</span> to table hive_test<span class="token punctuation">.</span>studentsOK<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> hive_test<span class="token punctuation">.</span>students<span class="token punctuation">;</span>OK<span class="token boolean">NULL</span>    <span class="token boolean">NULL</span><span class="token boolean">NULL</span>    <span class="token boolean">NULL</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>查其原因是创建表格时没有对导入的数据格式没有处理，比如每行数据以tab键隔开，以换行键结尾，就要以如下语句创建表格：</p><p>OK<br>NULL    NULL<br>NULL    NULL<br>查其原因是创建表格时没有对导入的数据格式没有处理，比如每行数据以tab键隔开，以换行键结尾，就要以如下语句创建表格：</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> students<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> students<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED BY</span> <span class="token string">' '</span> <span class="token keyword">LINES</span> <span class="token keyword">TERMINATED BY</span> <span class="token string">'\n'</span> STORED <span class="token keyword">AS</span> TEXTFILE<span class="token punctuation">;</span>OK<span class="token number">1</span>    sun<span class="token number">2</span>    lin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;&lt;strong&gt;问题描述&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;hive导入数据成功，但是查询结果为NULL：&lt;/p&gt;
&lt;pre class=&quot;line-
      
    
    </summary>
    
    
      <category term="Data Question" scheme="https://dataquaner.github.io/categories/Data-Question/"/>
    
    
      <category term="Hive" scheme="https://dataquaner.github.io/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>Python高级特性之切片</title>
    <link href="https://dataquaner.github.io/2020/04/25/python-gao-ji-te-xing-zhi-qie-pian/"/>
    <id>https://dataquaner.github.io/2020/04/25/python-gao-ji-te-xing-zhi-qie-pian/</id>
    <published>2020-04-25T14:14:00.000Z</published>
    <updated>2020-04-25T10:10:47.302Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Python可切片对象的索引方式"><a href="#1-Python可切片对象的索引方式" class="headerlink" title="1. Python可切片对象的索引方式"></a>1. Python可切片对象的索引方式</h2><p>​       包括：正索引和负索引两部分，如下图所示，以list对象a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]为例：</p><p><img src="https:////upload-images.jianshu.io/upload_images/14029140-3da45bbfe1029df4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/464/format/webp" alt="img"></p><h2 id="2-Python切片操作的一般方式"><a href="#2-Python切片操作的一般方式" class="headerlink" title="2. Python切片操作的一般方式"></a>2. Python切片操作的一般方式</h2><p>​       一个完整的切片表达式包含两个“:”，用于分隔三个参数(start_index、end_index、step)。</p><ul><li>当只有一个“:”时，默认第三个参数step=1；</li><li>当一个“:”也没有时，start_index=end_index，表示切取start_index指定的那个元素。</li></ul><p>​       切片操作基本表达式：object[start_index:end_index:step]</p><ul><li>step：正负数均可，其绝对值大小决定了切取数据时的‘‘步长”，而正负号决定了“切取方向”，正表示“从左往右”取值，负表示“从右往左”取值。当step省略时，默认为1，即从左往右以步长1取值。“切取方向非常重要！”“切取方向非常重要！”“切取方向非常重要！”，重要的事情说三遍！</li><li>start_index：表示起始索引（包含该索引对应值）；该参数省略时，表示从对象“端点”开始取值，至于是从“起点”还是从“终点”开始，则由step参数的正负决定，step为正从“起点”开始，为负从“终点”开始。</li><li>end_index：表示终止索引（不包含该索引对应值）；该参数省略时，表示一直取到数据“端点”，至于是到“起点”还是到“终点”，同样由step参数的正负决定，step为正时直到“终点”，为负时直到“起点”。</li></ul><h2 id="3-Python切片操作详细例子"><a href="#3-Python切片操作详细例子" class="headerlink" title="3. Python切片操作详细例子"></a>3. Python切片操作详细例子</h2><p>​      以下示例均以list对象a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]为例：</p><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="1-切取单个元素"><a href="#1-切取单个元素" class="headerlink" title="1. 切取单个元素"></a>1. 切取单个元素</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token number">0</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token number">6</span>当索引只有一个数时，表示切取某一个元素。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-切取完整对象"><a href="#2-切取完整对象" class="headerlink" title="2. 切取完整对象"></a>2. 切取完整对象</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#从左往右</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#从左往右</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#从右往左</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-start-index和end-index全为正（-）索引的情况"><a href="#3-start-index和end-index全为正（-）索引的情况" class="headerlink" title="3. start_index和end_index全为正（+）索引的情况"></a>3. start_index和end_index全为正（+）索引的情况</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token number">1</span>，从左往右取值，start_index<span class="token operator">=</span><span class="token number">1</span>到end_index<span class="token operator">=</span><span class="token number">6</span>同样表示从左往右取值。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token punctuation">]</span>输出为空列表，说明没取到数据。step<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>，决定了从右往左取值，而start_index<span class="token operator">=</span><span class="token number">1</span>到end_index<span class="token operator">=</span><span class="token number">6</span>决定了从左往右取值，两者矛盾，所以为空。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token punctuation">]</span>同样输出为空列表。step<span class="token operator">=</span><span class="token number">1</span>，决定了从左往右取值，而start_index<span class="token operator">=</span><span class="token number">6</span>到end_index<span class="token operator">=</span><span class="token number">2</span>决定了从右往左取值，两者矛盾，所以为空。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token number">1</span>，表示从左往右取值，而start_index省略时，表示从端点开始，因此这里的端点是“起点”，即从“起点”值<span class="token number">0</span>开始一直取到end_index<span class="token operator">=</span><span class="token number">6</span>（该点不包括）。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>，从右往左取值，而start_index省略时，表示从端点开始，因此这里的端点是“终点”，即从“终点”值<span class="token number">9</span>开始一直取到end_index<span class="token operator">=</span><span class="token number">6</span>（该点不包括）。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token number">1</span>，从左往右取值，从start_index<span class="token operator">=</span><span class="token number">6</span>开始，一直取到“终点”值<span class="token number">9</span>。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>，从右往左取值，从start_index<span class="token operator">=</span><span class="token number">6</span>开始，一直取到“起点”<span class="token number">0</span>。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="4-start-index和end-index全为负（-）索引的情况"><a href="#4-start-index和end-index全为负（-）索引的情况" class="headerlink" title="4. start_index和end_index全为负（-）索引的情况"></a>4. start_index和end_index全为负（-）索引的情况</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token number">1</span>，从左往右取值，而start_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>到end_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>决定了从右往左取值，两者矛盾，所以为空。索引<span class="token operator">-</span><span class="token number">1</span>在<span class="token operator">-</span><span class="token number">6</span>的右边（如上图）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>，从右往左取值，start_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>到end_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>同样是从右往左取值。索引<span class="token operator">-</span><span class="token number">1</span>在<span class="token number">6</span>的右边（如上图）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token number">1</span>，从左往右取值，而start_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>到end_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>同样是从左往右取值。索引<span class="token operator">-</span><span class="token number">6</span>在<span class="token operator">-</span><span class="token number">1</span>的左边（如上图）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token number">1</span>，从左往右取值，从“起点”开始一直取到end_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>（该点不包括）。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>，从右往左取值，从“终点”开始一直取到end_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>（该点不包括）。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token number">1</span>，从左往右取值，从start_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>开始，一直取到“终点”。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>step<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>，从右往左取值，从start_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>开始，一直取到“起点”。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="5-start-index和end-index正（-）负（-）混合索引的情况"><a href="#5-start-index和end-index正（-）负（-）混合索引的情况" class="headerlink" title="5. start_index和end_index正（+）负（-）混合索引的情况"></a>5. start_index和end_index正（+）负（-）混合索引的情况</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>start_index<span class="token operator">=</span><span class="token number">1</span>在end_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>的左边，因此从左往右取值，而step<span class="token operator">=</span><span class="token number">1</span>同样决定了从左往右取值，因此结果正确<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token punctuation">]</span>start_index<span class="token operator">=</span><span class="token number">1</span>在end_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">6</span>的左边，因此从左往右取值，但step<span class="token operator">=</span><span class="token operator">-</span>则决定了从右往左取值，两者矛盾，因此为空。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token punctuation">]</span>start_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>在end_index<span class="token operator">=</span><span class="token number">6</span>的右边，因此从右往左取值，但step<span class="token operator">=</span><span class="token number">1</span>则决定了从左往右取值，两者矛盾，因此为空。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>start_index<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>在end_index<span class="token operator">=</span><span class="token number">6</span>的右边，因此从右往左取值，而step<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>同样决定了从右往左取值，因此结果正确。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="6-多层切片操作"><a href="#6-多层切片操作" class="headerlink" title="6. 多层切片操作"></a>6. 多层切片操作</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span>相当于：a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span>理论上可无限次多层切片操作，只要上一次返回的是非空可切片对象即可。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="7-切片操作的三个参数可以用表达式"><a href="#7-切片操作的三个参数可以用表达式" class="headerlink" title="7. 切片操作的三个参数可以用表达式"></a>7. 切片操作的三个参数可以用表达式</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">7</span><span class="token operator">%</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>即：a<span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">7</span><span class="token operator">%</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="8-其他对象的切片操作"><a href="#8-其他对象的切片操作" class="headerlink" title="8. 其他对象的切片操作"></a>8. 其他对象的切片操作</h3><p>​       前面的切片操作以list对象为例进行说明，但实际上可进行切片操作的数据类型还有很多，包括元组、字符串等等。</p><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>元组的切片操作<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token string">'ABCDEFG'</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token string">'ACEG'</span>字符串的切片操作<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token function">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token number">87</span><span class="token number">90</span><span class="token number">93</span><span class="token number">96</span><span class="token number">99</span>就是利用<span class="token function">range</span><span class="token punctuation">(</span><span class="token punctuation">)</span>函数生成<span class="token number">1</span><span class="token operator">-</span><span class="token number">99</span>的整数，然后从start_index<span class="token operator">=</span><span class="token number">2</span>（即<span class="token number">3</span>）开始以step<span class="token operator">=</span><span class="token number">3</span>取值，直到终点，再在新序列中取最后五个数。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-常用切片操作"><a href="#4-常用切片操作" class="headerlink" title="4. 常用切片操作"></a>4. 常用切片操作</h2><h3 id="1-取偶数位置"><a href="#1-取偶数位置" class="headerlink" title="1.取偶数位置"></a>1.取偶数位置</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>b <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-取奇数位置"><a href="#2-取奇数位置" class="headerlink" title="2.取奇数位置"></a>2.取奇数位置</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>b <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-拷贝整个对象"><a href="#3-拷贝整个对象" class="headerlink" title="3.拷贝整个对象"></a>3.拷贝整个对象</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>b <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token function">id</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#41946376</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token function">id</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#41921864</span>或<span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>b <span class="token operator">=</span> a<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token function">id</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#39783752</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token function">id</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#39759176</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要注意的是：<strong>[:]和.copy()都属于“浅拷贝”，只拷贝最外层元素，内层嵌套元素则通过引用方式共享，而非独立分配内存</strong>，如果需要彻底拷贝则需采用“深拷贝”方式，如下例所示：</p><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span><span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'a={}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>b <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">9</span> <span class="token comment" spellcheck="true">#修改b的最外层元素，将1变成9</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>b<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'D'</span> <span class="token comment" spellcheck="true">#修改b的内嵌层元素</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'a={}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'b={}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'id(a)={}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token function">id</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'id(b)={}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token function">id</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>a<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#原始a</span>a<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'D'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#b修改内部元素A为D后，a中的A也变成了D，说明共享内部嵌套元素，但外部元素1没变。</span>b<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'D'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#修改后的b</span><span class="token function">id</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">38669128</span><span class="token function">id</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">38669192</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-修改单个元素"><a href="#4-修改单个元素" class="headerlink" title="4.修改单个元素"></a>4.修改单个元素</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span><span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="5-在某个位置插入元素"><a href="#5-在某个位置插入元素" class="headerlink" title="5.在某个位置插入元素"></a>5.在某个位置插入元素</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span><span class="token string">'B'</span><span class="token punctuation">,</span><span class="token string">'C'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span><span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-替换一部分元素"><a href="#6-替换一部分元素" class="headerlink" title="6.替换一部分元素"></a>6.替换一部分元素</h3><pre class="line-numbers language-ruby"><code class="language-ruby"><span class="token operator">></span><span class="token operator">></span><span class="token operator">></span>a<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span><span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><ul><li>start_index、end_index、step三者可同为正、同为负，或正负混合。但必须遵循一个原则，即：当start_index表示的实际位置在end_index的左边时，从左往右取值，此时step必须是正数（同样表示从左往右）；当start_index表示的实际位置在end_index的右边时，表示从右往左取值，此时step必须是负数（同样表示从右往左），即两者的取值顺序必须相同。</li><li>当start_index或end_index省略时，取值的起始索引和终止索引由step的正负来决定，这种情况不会有取值方向矛盾（即不会返回空列表[]），但正和负取到的结果顺序是相反的，因为一个向左一个向右。</li><li>step的正负是必须要考虑的，尤其是当step省略时。比如a[-1:]，很容易就误认为是从“终点”开始一直取到“起点”，即a[-1:]= [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]，但实际上a[-1:]=[9]（注意不是9），原因在于step省略时step=1表示从左往右取值，而起始索引start_index=-1本身就是对象的最右边元素了，再往右已经没数据了，因此结果只含有9一个元素。</li><li>需要注意：“取单个元素（不带“:”）”时，返回的是对象的某个元素，其类型由元素本身的类型决定，而与母对象无关，如上面的a[0]=0、a[-4]=6，元素0和6都是“数值型”，而母对象a却是“list”型；“取连续切片（带“:”）”时，返回结果的类型与母对象相同，哪怕切取的连续切片只包含一个元素，如上面的a[-1:]=[9]，返回的是一个只包含元素“9”的list，而非数值型“9”。</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-Python可切片对象的索引方式&quot;&gt;&lt;a href=&quot;#1-Python可切片对象的索引方式&quot; class=&quot;headerlink&quot; title=&quot;1. Python可切片对象的索引方式&quot;&gt;&lt;/a&gt;1. Python可切片对象的索引方式&lt;/h2&gt;&lt;p&gt;​   
      
    
    </summary>
    
    
      <category term="Python" scheme="https://dataquaner.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://dataquaner.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode数组系列之#88：合并两个有序数组</title>
    <link href="https://dataquaner.github.io/2020/04/25/1.leetcode-shua-ti-shu-zu-xi-lie-zhi-88-he-bing-shu-zu/"/>
    <id>https://dataquaner.github.io/2020/04/25/1.leetcode-shua-ti-shu-zu-xi-lie-zhi-88-he-bing-shu-zu/</id>
    <published>2020-04-25T08:16:16.000Z</published>
    <updated>2020-04-25T11:02:08.816Z</updated>
    
    <content type="html"><![CDATA[<h3 id="题目：合并两个有序数组"><a href="#题目：合并两个有序数组" class="headerlink" title="题目：合并两个有序数组"></a>题目：合并两个有序数组</h3><h3 id="难度：Easy"><a href="#难度：Easy" class="headerlink" title="难度：Easy"></a>难度：Easy</h3><h3 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h3><blockquote><h4 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h4><p>​        给你两个有序整数数组 nums1 和 nums2，请你将 nums2 合并到 nums1 中，使 nums1 成为一个有序数组。</p><h4 id="说明"><a href="#说明" class="headerlink" title="说明:"></a>说明:</h4><ul><li>初始化 nums1 和 nums2 的元素数量分别为 m 和 n 。</li><li>你可以假设 nums1 有足够的空间（空间大小大于或等于 m + n）来保存 nums2 中的元素。</li></ul><h4 id="示例"><a href="#示例" class="headerlink" title="示例:"></a>示例:</h4><p>​    输入:<br>​        nums1 = [1,2,3,0,0,0], m = 3<br>​        nums2 = [2,5,6],           n = 3</p><p>​     输出: </p><p>​        [1,2,2,3,5,6]</p><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode-cn.com/problems/merge-sorted-array" target="_blank" rel="noopener">https://leetcode-cn.com/problems/merge-sorted-array</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p></blockquote><h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><h4 id="方法一：合并后排序"><a href="#方法一：合并后排序" class="headerlink" title="方法一：合并后排序"></a>方法一：合并后排序</h4><h5 id="直觉"><a href="#直觉" class="headerlink" title="直觉"></a>直觉</h5><p>​      最朴素的解法就是将两个数组合并之后再排序。</p><p>​      该算法只需要一行(Java是2行)，时间复杂度较差，为O((n + m)log(n + m))。这是由于这种方法没有利用两个数组本身已经有序这一点。</p><h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><h6 id="Python版"><a href="#Python版" class="headerlink" title="Python版"></a>Python版</h6><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">merge</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums1<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span> m<span class="token punctuation">:</span> int<span class="token punctuation">,</span> nums2<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span> n<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Do not return anything, modify nums1 in-place instead.        """</span>         nums1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> sorted<span class="token punctuation">(</span>nums1<span class="token punctuation">[</span><span class="token punctuation">:</span>m<span class="token punctuation">]</span> <span class="token operator">+</span> nums2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="Java版"><a href="#Java版" class="headerlink" title="Java版"></a>Java版</h5><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">merge</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums1<span class="token punctuation">,</span> <span class="token keyword">int</span> m<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums2<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>    System<span class="token punctuation">.</span><span class="token function">arraycopy</span><span class="token punctuation">(</span>nums2<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> nums1<span class="token punctuation">,</span> m<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">;</span>    Arrays<span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span>nums1<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h6 id="Scala版"><a href="#Scala版" class="headerlink" title="Scala版"></a>Scala版</h6><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">object</span> Solution <span class="token punctuation">{</span>    <span class="token keyword">def</span> merge<span class="token punctuation">(</span>nums1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> m<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> nums2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h5><ul><li>时间复杂度 : <em>O</em>((<em>n</em>+<em>m</em>)log(<em>n</em>+<em>m</em>))</li><li>空间复杂度 : O(1)</li></ul><h4 id="方法二：双指针-从前往后"><a href="#方法二：双指针-从前往后" class="headerlink" title="方法二：双指针 / 从前往后"></a>方法二：双指针 / 从前往后</h4><h5 id="直觉-1"><a href="#直觉-1" class="headerlink" title="直觉"></a>直觉</h5><p>​       一般而言，对于有序数组可以通过双指针法达到O(n+m)的时间复杂度。</p><p>最直接的算法实现是将指针p1 置为 nums1的开头， p2为 nums2的开头，在每一步将最小值放入输出数组中。</p><p>​      由于 nums1 是用于输出的数组，需要将nums1中的前m个元素放在其他地方，也就需要O(m) 的空间复杂度。</p><p><img src="https://pic.leetcode-cn.com/992f95361c37ad06deadb6f14a9970d0184fd47330365400dd1d6f7be239e0ff-image.png" alt="image.png"></p><h5 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h5><h5 id="Python版-1"><a href="#Python版-1" class="headerlink" title="Python版"></a>Python版</h5><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">merge</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums1<span class="token punctuation">,</span> m<span class="token punctuation">,</span> nums2<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums1: List[int]        :type m: int        :type nums2: List[int]        :type n: int        :rtype: void Do not return anything, modify nums1 in-place instead.        """</span>        <span class="token comment" spellcheck="true"># Make a copy of nums1.</span>        nums1_copy <span class="token operator">=</span> nums1<span class="token punctuation">[</span><span class="token punctuation">:</span>m<span class="token punctuation">]</span>         nums1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Two get pointers for nums1_copy and nums2.</span>        p1 <span class="token operator">=</span> <span class="token number">0</span>         p2 <span class="token operator">=</span> <span class="token number">0</span>        <span class="token comment" spellcheck="true"># Compare elements from nums1_copy and nums2</span>        <span class="token comment" spellcheck="true"># and add the smallest one into nums1.</span>        <span class="token keyword">while</span> p1 <span class="token operator">&lt;</span> m <span class="token operator">and</span> p2 <span class="token operator">&lt;</span> n<span class="token punctuation">:</span>             <span class="token keyword">if</span> nums1_copy<span class="token punctuation">[</span>p1<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums2<span class="token punctuation">[</span>p2<span class="token punctuation">]</span><span class="token punctuation">:</span>                 nums1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nums1_copy<span class="token punctuation">[</span>p1<span class="token punctuation">]</span><span class="token punctuation">)</span>                p1 <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                nums1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nums2<span class="token punctuation">[</span>p2<span class="token punctuation">]</span><span class="token punctuation">)</span>                p2 <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># if there are still elements to add</span>        <span class="token keyword">if</span> p1 <span class="token operator">&lt;</span> m<span class="token punctuation">:</span>             nums1<span class="token punctuation">[</span>p1 <span class="token operator">+</span> p2<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> nums1_copy<span class="token punctuation">[</span>p1<span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> p2 <span class="token operator">&lt;</span> n<span class="token punctuation">:</span>            nums1<span class="token punctuation">[</span>p1 <span class="token operator">+</span> p2<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> nums2<span class="token punctuation">[</span>p2<span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a><strong>复杂度分析</strong></h5><ul><li>时间复杂度 : O(n + m)</li><li>空间复杂度 : O(m)</li></ul><h4 id="方法三-双指针-从后往前"><a href="#方法三-双指针-从后往前" class="headerlink" title="方法三 : 双指针 / 从后往前"></a>方法三 : 双指针 / 从后往前</h4><h5 id="直觉-2"><a href="#直觉-2" class="headerlink" title="直觉"></a>直觉</h5><p>​       方法二已经取得了最优的时间复杂度O(n + m)，但需要使用额外空间。这是由于在从头改变nums1的值时，需要把nums1中的元素存放在其他位置。</p><p>​       如果我们从结尾开始改写 nums1 的值又会如何呢？这里没有信息，因此不需要额外空间。</p><p>这里的指针 p 用于追踪添加元素的位置。</p><p><img src="https://pic.leetcode-cn.com/57c1daae7dab21c175f0a3acc18e4535aecde350c5100832bd2fdb0e4279180e-image.png" alt="img"></p><p><img src="https://pic.leetcode-cn.com/bac9fc86e104b5fa65f144e0604e0f4ffe4585efac12c1942b618be1c70363ca-image.png" alt="img"></p><h5 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h5><p>Python版</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">merge</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums1<span class="token punctuation">,</span> m<span class="token punctuation">,</span> nums2<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums1: List[int]        :type m: int        :type nums2: List[int]        :type n: int        :rtype: void Do not return anything, modify nums1 in-place instead.        """</span>        <span class="token comment" spellcheck="true"># two get pointers for nums1 and nums2</span>        p1 <span class="token operator">=</span> m <span class="token operator">-</span> <span class="token number">1</span>        p2 <span class="token operator">=</span> n <span class="token operator">-</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># set pointer for nums1</span>        p <span class="token operator">=</span> m <span class="token operator">+</span> n <span class="token operator">-</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># while there are still elements to compare</span>        <span class="token keyword">while</span> p1 <span class="token operator">>=</span> <span class="token number">0</span> <span class="token operator">and</span> p2 <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> nums1<span class="token punctuation">[</span>p1<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums2<span class="token punctuation">[</span>p2<span class="token punctuation">]</span><span class="token punctuation">:</span>                nums1<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> nums2<span class="token punctuation">[</span>p2<span class="token punctuation">]</span>                p2 <span class="token operator">-=</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                nums1<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span>  nums1<span class="token punctuation">[</span>p1<span class="token punctuation">]</span>                p1 <span class="token operator">-=</span> <span class="token number">1</span>            p <span class="token operator">-=</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># add missing elements from nums2</span>        nums1<span class="token punctuation">[</span><span class="token punctuation">:</span>p2 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> nums2<span class="token punctuation">[</span><span class="token punctuation">:</span>p2 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Java版</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">merge</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums1<span class="token punctuation">,</span> <span class="token keyword">int</span> m<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums2<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// two get pointers for nums1 and nums2</span>    <span class="token keyword">int</span> p1 <span class="token operator">=</span> m <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> p2 <span class="token operator">=</span> n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// set pointer for nums1</span>    <span class="token keyword">int</span> p <span class="token operator">=</span> m <span class="token operator">+</span> n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// while there are still elements to compare</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>p1 <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>p2 <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">// compare two elements from nums1 and nums2 </span>      <span class="token comment" spellcheck="true">// and add the largest one in nums1 </span>      nums1<span class="token punctuation">[</span>p<span class="token operator">--</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>nums1<span class="token punctuation">[</span>p1<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums2<span class="token punctuation">[</span>p2<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">?</span> nums2<span class="token punctuation">[</span>p2<span class="token operator">--</span><span class="token punctuation">]</span> <span class="token operator">:</span> nums1<span class="token punctuation">[</span>p1<span class="token operator">--</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// add missing elements from nums2</span>    System<span class="token punctuation">.</span><span class="token function">arraycopy</span><span class="token punctuation">(</span>nums2<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> nums1<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> p2 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><ul><li>时间复杂度 : O(n + m)</li><li>空间复杂度 : O(1)</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;题目：合并两个有序数组&quot;&gt;&lt;a href=&quot;#题目：合并两个有序数组&quot; class=&quot;headerlink&quot; title=&quot;题目：合并两个有序数组&quot;&gt;&lt;/a&gt;题目：合并两个有序数组&lt;/h3&gt;&lt;h3 id=&quot;难度：Easy&quot;&gt;&lt;a href=&quot;#难度：Easy&quot; c
      
    
    </summary>
    
    
      <category term="LeetCode" scheme="https://dataquaner.github.io/categories/LeetCode/"/>
    
    
      <category term="LeetCode" scheme="https://dataquaner.github.io/tags/LeetCode/"/>
    
  </entry>
  
  <entry>
    <title>数据倾斜问题总结</title>
    <link href="https://dataquaner.github.io/2020/04/22/shu-ju-qing-xie-wen-ti-zong-jie/"/>
    <id>https://dataquaner.github.io/2020/04/22/shu-ju-qing-xie-wen-ti-zong-jie/</id>
    <published>2020-04-22T14:14:00.000Z</published>
    <updated>2020-04-22T14:35:55.073Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0-什么是数据倾斜"><a href="#0-什么是数据倾斜" class="headerlink" title="0. 什么是数据倾斜"></a>0. 什么是数据倾斜</h2><blockquote><p>​        对于集群系统，一般缓存是分布式的，即不同节点负责一定范围的缓存数据。我们把缓存数据分散度不够，导致大量的缓存数据集中到了一台或者几台服务节点上，称为数据倾斜。一般来说数据倾斜是由于负载均衡实施的效果不好引起的。</p><p>来源百度百科</p></blockquote><p>​        对于数据计算过程来说，数据倾斜指的是，并行处理的数据集中，某一部分（如Spark或Kafka的一个Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈。</p><h2 id="1-数据倾斜的现象"><a href="#1-数据倾斜的现象" class="headerlink" title="1. 数据倾斜的现象"></a>1. 数据倾斜的现象</h2><p>​       多数task执行速度较快,少数task执行时间非常长，或者等待很长时间后提示你内存不足，执行失败。</p><h2 id="2-数据倾斜的影响"><a href="#2-数据倾斜的影响" class="headerlink" title="2. 数据倾斜的影响"></a>2. 数据倾斜的影响</h2><p>1）数过多的数据在同一个task中执行，将会把executor撑爆，造成OOM，程序终止运行。,据倾斜直接会导致一种情况：<strong>Out Of Memory</strong>。</p><p>2）<strong>运行速度慢</strong> ,spark中一个stage的执行时间受限于最后那个执行完的task，因此运行缓慢的任务会拖累整个程序的运行速度（分布式程序运行的速度是由最慢的那个task决定的）。要是发生在Shuffle阶段。同样Key的数据条数太多了。导致了某个key(下图中的80亿条)所在的Task数据量太大了。远远超过其他Task所处理的数据量。</p><p><img src="https://pic1.zhimg.com/80/v2-b26e15f4b1c3ce2f78fba64397b6fd60_1440w.jpg" alt="img"></p><p><strong><em>一个经验结论是：一般情况下，OOM的原因都是数据倾斜\</em></strong></p><h2 id="3-如何定位数据倾斜"><a href="#3-如何定位数据倾斜" class="headerlink" title="3. 如何定位数据倾斜"></a>3. 如何定位数据倾斜</h2><p>​         数据倾斜一般会发生在shuffle过程中。很大程度上是你使用了可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。</p><p><strong>原因</strong>： 查看任务-》查看Stage-》查看代码</p><p>​        某个task执行特别慢的情况</p><p>​        某个task莫名其妙内存溢出的情况</p><p>​        查看导致数据倾斜的key的数据分布情况</p><p><img src="https://pic1.zhimg.com/80/v2-b1b26a9b5e6a1d68d9aea4d1f2bc551c_1440w.jpg" alt="img"></p><p>也可从以下几种情况考虑：</p><p>1、是不是有OOM情况出现，一般是少数内存溢出的问题</p><p>2、是不是应用运行时间差异很大，总体时间很长</p><p>3、需要了解你所处理的数据Key的分布情况，如果有些Key有大量的条数，那么就要小心数据倾斜的问题</p><p>4、一般需要通过Spark Web UI和其他一些监控方式出现的异常来综合判断</p><p>5、看看代码里面是否有一些导致Shuffle的算子出现</p><h2 id="4-数据倾斜的几种典型情况（重点）"><a href="#4-数据倾斜的几种典型情况（重点）" class="headerlink" title="4. 数据倾斜的几种典型情况（重点）"></a><strong>4. 数据倾斜的几种典型情况（重点）</strong></h2><ul><li>数据源中的数据分布不均匀，Spark需要频繁交互</li><li>数据集中的不同Key由于分区方式，导致数据倾斜</li><li>JOIN操作中，一个数据集中的数据分布不均匀，另一个数据集较小（主要）</li><li>聚合操作中，数据集中的数据分布不均匀（主要）</li><li>JOIN操作中，两个数据集都比较大，其中只有几个Key的数据分布不均匀</li><li>JOIN操作中，两个数据集都比较大，有很多Key的数据分布不均匀</li><li>数据集中少数几个key数据量很大，不重要，其他数据均匀</li></ul><p>注意：</p><ul><li><p>需要处理的数据倾斜问题就是Shuffle后数据的分布是否均匀问题</p></li><li><p>只要保证最后的结果是正确的，可以采用任何方式来处理数据倾斜，只要保证在处理过程中不发生数据倾斜就可以</p></li></ul><h2 id="5-数据倾斜的处理方法"><a href="#5-数据倾斜的处理方法" class="headerlink" title="5. 数据倾斜的处理方法"></a>5. 数据倾斜的处理方法</h2><p>​         发现数据倾斜的时候，不要急于提高executor的资源，修改参数或是修改程序，首先要检查数据本身，是否存在异常数据。</p><h3 id="5-1-检查数据，找出异常的key"><a href="#5-1-检查数据，找出异常的key" class="headerlink" title="5.1 检查数据，找出异常的key"></a>5.1 检查数据，找出异常的key</h3><p>​          如果任务长时间卡在最后1个(几个)任务，首先要对key进行抽样分析，判断是哪些key造成的。</p><p>选取key，对数据进行抽样，统计出现的次数，根据出现次数大小排序取出前几个</p><pre class="line-numbers language-scala"><code class="language-scala">df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"key"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">(</span>k<span class="token keyword">=></span><span class="token punctuation">(</span>k<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceBykey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>k<span class="token keyword">=></span><span class="token punctuation">(</span>k<span class="token punctuation">.</span>_2<span class="token punctuation">,</span>k<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​        如果发现多数数据分布都较为平均，而个别数据比其他数据大上若干个数量级，则说明发生了数据倾斜。</p><p>经过分析，倾斜的数据主要有以下三种情况:</p><ul><li><p>null（空值）或是一些无意义的信息()之类的,大多是这个原因引起。</p></li><li><p>无效数据，大量重复的测试数据或是对结果影响不大的有效数据。</p></li><li><p>有效数据，业务导致的正常数据分布。</p></li></ul><p><strong>解决办法</strong><br>  第1，2种情况，直接对数据进行过滤即可。</p><p>  第3种情况则需要进行一些特殊操作，常见的有以下几种做法。</p><ul><li><p>隔离执行，将异常的key过滤出来单独处理，最后与正常数据的处理结果进行union操作。</p></li><li><p>对key先添加随机值，进行操作后，去掉随机值，再进行一次操作。</p></li><li><p>使用reduceByKey 代替 groupByKey</p></li><li><p>使用map join。</p><p><strong>举例</strong>：<br>如果使用reduceByKey因为数据倾斜造成运行失败的问题。具体操作如下：</p><p>将原始的 key 转化为 key + 随机值(例如Random.nextInt)<br>对数据进行 reduceByKey(func)<br>将 key + 随机值 转成 key<br>再对数据进行 reduceByKey(func)<br>tip1: 如果此时依旧存在问题，建议筛选出倾斜的数据单独处理。最后将这份数据与正常的数据进行union即可。</p><p>tips2: 单独处理异常数据时，可以配合使用Map Join解决</p></li></ul><h4 id="5-1-1-数据源中的数据分布不均匀，Spark需要频繁交互"><a href="#5-1-1-数据源中的数据分布不均匀，Spark需要频繁交互" class="headerlink" title="5.1.1 数据源中的数据分布不均匀，Spark需要频繁交互"></a><strong>5.1.1</strong> 数据源中的数据分布不均匀，Spark需要频繁交互</h4><p><strong>解决方案</strong>1：避免数据源的数据倾斜</p><p><strong>实现原理</strong>：通过在Hive中对倾斜的数据进行预处理，以及在进行kafka数据分发时尽量进行平均分配。这种方案从根源上解决了数据倾斜，彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。</p><p><strong>方案优点</strong>：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</p><p><strong>方案缺点</strong>：治标不治本，Hive或者Kafka中还是会发生数据倾斜。</p><p><strong>适用情况</strong>：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。</p><p><strong>总结</strong>：前台的Java系统和Spark有很频繁的交互，这个时候如果Spark能够在最短的时间内处理数据，往往会给前端有非常好的体验。这个时候可以将数据倾斜的问题抛给数据源端，在数据源端进行数据倾斜的处理。但是这种方案没有真正的处理数据倾斜问题</p><h4 id="5-1-2-数据集中的不同Key由于分区方式，导致数据倾斜"><a href="#5-1-2-数据集中的不同Key由于分区方式，导致数据倾斜" class="headerlink" title="5.1.2 数据集中的不同Key由于分区方式，导致数据倾斜"></a><strong>5.1.2</strong> 数据集中的不同Key由于分区方式，导致数据倾斜</h4><p><strong>解决方案1</strong>：调整并行度</p><p><strong>实现原理</strong>：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。</p><p><strong>方案优点</strong>：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。</p><p><strong>方案缺点</strong>：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。</p><p><strong>实践经验</strong>：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，都无法处理。</p><p><img src="https://pic4.zhimg.com/80/v2-9a1722a9ceb6fe125f7b36715f6dcfff_1440w.jpg" alt="img"></p><p><strong>总结</strong>：调整并行度：适合于有大量key由于分区算法或者分区数的问题，将key进行了不均匀分区，可以通过调大或者调小分区数来试试是否有效</p><p><strong>解决方案2</strong>：</p><p><strong>缓解数据倾斜**</strong>（自定义Partitioner）**</p><p><strong>适用场景</strong>：大量不同的Key被分配到了相同的Task造成该Task数据量过大。</p><p><strong>解决方案</strong>： 使用自定义的Partitioner实现类代替默认的HashPartitioner，尽量将所有不同的Key均匀分配到不同的Task中。</p><p><strong>优势</strong>： 不影响原有的并行度设计。如果改变并行度，后续Stage的并行度也会默认改变，可能会影响后续Stage。</p><p><strong>劣势</strong>： 适用场景有限，只能将不同Key分散开，对于同一Key对应数据集非常大的场景不适用。效果与调整并行度类似，只能缓解数据倾斜而不能完全消除数据倾斜。而且需要根据数据特点自定义专用的Partitioner，不够灵活。</p><h3 id="5-2-检查Spark运行过程相关操作"><a href="#5-2-检查Spark运行过程相关操作" class="headerlink" title="5.2 检查Spark运行过程相关操作"></a>5.2 检查Spark运行过程相关操作</h3><h4 id="5-2-1-JOIN操作中，一个数据集中的数据分布不均匀，另一个数据集较小（主要）"><a href="#5-2-1-JOIN操作中，一个数据集中的数据分布不均匀，另一个数据集较小（主要）" class="headerlink" title="5.2.1 JOIN操作中，一个数据集中的数据分布不均匀，另一个数据集较小（主要）"></a>5.2.1 JOIN操作中，一个数据集中的数据分布不均匀，另一个数据集较小（主要）</h4><p><strong>解决方案</strong>：Reduce side Join转变为Map side Join</p><p><strong>方案适用场景</strong>：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M），比较适用此方案。</p><p><strong>方案实现原理</strong>：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。</p><p><strong>方案优点</strong>：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。</p><p><strong>方案缺点</strong>：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。</p><h4 id="5-2-2-聚合操作中，数据集中的数据分布不均匀（主要）"><a href="#5-2-2-聚合操作中，数据集中的数据分布不均匀（主要）" class="headerlink" title="5.2.2  聚合操作中，数据集中的数据分布不均匀（主要）"></a>5.2.2  聚合操作中，数据集中的数据分布不均匀（主要）</h4><p><strong>解决方案</strong>：两阶段聚合（局部聚合+全局聚合）</p><p><strong>适用场景</strong>：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案</p><p><strong>实现原理</strong>：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。</p><p><strong>优点</strong>：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</p><p><strong>缺点</strong>：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案</p><p>将相同key的数据分拆处理</p><p><img src="https://pic3.zhimg.com/80/v2-495a5fed7eb38db37d2f0bd13c45a30e_1440w.jpg" alt="img"></p><h4 id="5-2-3-JOIN操作中，两个数据集都比较大，其中只有几个Key的数据分布不均匀"><a href="#5-2-3-JOIN操作中，两个数据集都比较大，其中只有几个Key的数据分布不均匀" class="headerlink" title="5.2.3 JOIN操作中，两个数据集都比较大，其中只有几个Key的数据分布不均匀"></a><strong>5.2.3</strong> JOIN操作中，两个数据集都比较大，其中只有几个Key的数据分布不均匀</h4><p><strong>解决方案</strong>：为倾斜key增加随机前/后缀</p><p><strong>适用场景</strong>：两张表都比较大，无法使用Map侧Join。其中一个RDD有少数几个Key的数据量过大，另外一个RDD的Key分布较为均匀。</p><p><strong>解决方案</strong>：将有数据倾斜的RDD中倾斜Key对应的数据集单独抽取出来加上随机前缀，另外一个RDD每条数据分别与随机前缀结合形成新的RDD（笛卡尔积，相当于将其数据增到到原来的N倍，N即为随机前缀的总个数），然后将二者Join后去掉前缀。然后将不包含倾斜Key的剩余数据进行Join。最后将两次Join的结果集通过union合并，即可得到全部Join结果。</p><p><strong>优势</strong>：相对于Map侧Join，更能适应大数据集的Join。如果资源充足，倾斜部分数据集与非倾斜部分数据集可并行进行，效率提升明显。且只针对倾斜部分的数据做数据扩展，增加的资源消耗有限。</p><p><strong>劣势</strong>：如果倾斜Key非常多，则另一侧数据膨胀非常大，此方案不适用。而且此时对倾斜Key与非倾斜Key分开处理，需要扫描数据集两遍，增加了开销。</p><p><strong>注意</strong>：具有倾斜Key的RDD数据集中，key的数量比较少</p><p><img src="https://pic4.zhimg.com/80/v2-248b0cead5e9fb8a7b1cec840dd61b2f_1440w.jpg" alt="img"></p><h4 id="5-2-4-JOIN操作中，两个数据集都比较大，有很多Key的数据分布不均匀"><a href="#5-2-4-JOIN操作中，两个数据集都比较大，有很多Key的数据分布不均匀" class="headerlink" title="5.2.4 JOIN操作中，两个数据集都比较大，有很多Key的数据分布不均匀"></a><strong>5.2.4</strong> JOIN操作中，两个数据集都比较大，有很多Key的数据分布不均匀</h4><p><strong>解决方案</strong>：随机前缀和扩容RDD进行join</p><p><strong>适用场景</strong>：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义。</p><p><strong>实现思路</strong>：将该RDD的每条数据都打上一个n以内的随机前缀。同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。最后将两个处理后的RDD进行join即可。和上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。</p><p><strong>优点</strong>：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。</p><p><strong>缺点</strong>：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。</p><p><strong>实践经验</strong>：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。</p><p>注意：将倾斜Key添加1-N的随机前缀，并将被Join的数据集相应的扩大N倍（需要将1-N数字添加到每一条数据上作为前缀）</p><p><img src="https://pic4.zhimg.com/80/v2-fa2211e3a343d7b68e83bfe83d67f0cb_1440w.jpg" alt="img"></p><h4 id="5-2-5-数据集中少数几个key数据量很大，不重要，其他数据均匀"><a href="#5-2-5-数据集中少数几个key数据量很大，不重要，其他数据均匀" class="headerlink" title="5.2.5 数据集中少数几个key数据量很大，不重要，其他数据均匀"></a><strong>5.2.5</strong> 数据集中少数几个key数据量很大，不重要，其他数据均匀</h4><p><strong>解决方案</strong>：过滤少数倾斜Key</p><p><strong>适用场景</strong>：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</p><p><strong>优点</strong>：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</p><p><strong>缺点</strong>：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。</p><p><strong>实践经验</strong>：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;0-什么是数据倾斜&quot;&gt;&lt;a href=&quot;#0-什么是数据倾斜&quot; class=&quot;headerlink&quot; title=&quot;0. 什么是数据倾斜&quot;&gt;&lt;/a&gt;0. 什么是数据倾斜&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;​        对于集群系统，一般缓存是分布式的，即
      
    
    </summary>
    
    
      <category term="Data Question" scheme="https://dataquaner.github.io/categories/Data-Question/"/>
    
    
      <category term="数据倾斜" scheme="https://dataquaner.github.io/tags/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"/>
    
  </entry>
  
  <entry>
    <title>1.数据开发工程师面试题目必知必会</title>
    <link href="https://dataquaner.github.io/2020/04/21/1.shu-ju-kai-fa-gong-cheng-shi-mian-shi-ti-mu-bi-zhi-bi-hui/"/>
    <id>https://dataquaner.github.io/2020/04/21/1.shu-ju-kai-fa-gong-cheng-shi-mian-shi-ti-mu-bi-zhi-bi-hui/</id>
    <published>2020-04-21T10:59:38.680Z</published>
    <updated>2020-04-21T10:59:38.680Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题目梳理"><a href="#面试题目梳理" class="headerlink" title="面试题目梳理"></a>面试题目梳理</h2><h3 id="一-数据结构和算法-LeetCode"><a href="#一-数据结构和算法-LeetCode" class="headerlink" title="一. 数据结构和算法 LeetCode"></a>一. 数据结构和算法 <a href="https://leetcode-cn.com/problemset/all/" target="_blank" rel="noopener">LeetCode</a></h3><ol><li>合并数组</li><li>二元查找树转双向链表</li><li>二叉树层次遍历</li><li>堆 最小堆</li><li>排序算法</li><li>动态规划</li><li>青蛙跳台阶</li><li>贪心算法</li><li>字符串转换成整数</li><li>链表中倒数第K个结点</li><li><ol start="11"><li>二维数组中的查找</li></ol></li><li><ol start="12"><li>替换空格</li></ol></li><li><ol start="13"><li>从尾到头打印链表</li></ol></li><li><ol start="14"><li>重建二叉树</li></ol></li><li>用两个栈实现队列</li><li>斐波那契数列及变形题</li><li>二进制中1的个数</li><li>在O(1)时间删除链表结点</li><li>调整数组顺序使奇数位于偶数前面</li><li>反转链表</li><li>合并两个排序的链表</li><li>树的子结构</li><li>二叉树的镜像</li><li>顺时针打印矩阵</li><li>栈的压入、弹出序列</li><li>二叉搜索树的后序遍历序列</li><li>二叉树中和为某一值的路径</li><li>数组中出现次数超过一半的数字</li><li>最小的k个数</li><li>连续子数组的最大和</li><li>第一个只出现一次的字符</li><li>两个链表的第一个公共结点</li><li>链表中环的入口结点</li><li>二叉树的镜像</li><li>跳台阶</li><li>变态跳台阶</li><li>矩形覆盖</li><li>从上往下打印二叉树</li><li>二叉搜索树的第K个结点</li></ol><h3 id="二-计算平台"><a href="#二-计算平台" class="headerlink" title="二. 计算平台"></a>二. 计算平台</h3><h4 id="1-Hadoop"><a href="#1-Hadoop" class="headerlink" title="1. Hadoop"></a>1. Hadoop</h4><ol><li><p>数据倾斜问题</p></li><li><p>hive开窗函数</p></li><li><p>hive UDF UDAF<br>Mapreduce原理</p></li><li><p>MR的Shuffle过程</p></li><li><p>Yarn的工作机制，以及MR Job提交运行过程</p></li><li><p>MapReduce1的工作机制和过程</p></li><li><p>HDFS写入过程</p></li><li><p>Fsimage 与 EditLog定义及合并过程</p></li><li><p>HDFS读过程</p></li><li><p>HDFS简介</p></li><li><p>在向HDFS中写数据的时候，当写某一副本时出错怎么处理？</p></li><li><p>namenode的HA实现</p></li><li><p>简述联邦HDFS</p></li><li><p>HDFS源码解读–create()</p></li><li><p>NameNode高可用中editlog同步的过程</p></li><li><p>HDFS写入过程客户端奔溃怎么处理？（租约恢复）</p></li></ol><h4 id="2-Hive"><a href="#2-Hive" class="headerlink" title="2. Hive"></a>2. Hive</h4><ol><li>Hive内部表与外部表的区别</li><li>Hive与传统数据库的区别</li><li>Hiverc文件</li><li>Hive分区</li><li>Hive分区过多有何坏处以及分区时的注意事项</li><li>Hive中复杂数据类型的使用好处与坏处</li><li>hive分桶？</li><li>Hive元数据库是用来做什么的，存储哪些信息？</li><li>为何不使用Derby作为元数据库？</li><li>Hive什么情况下可以避免进行mapreduce？</li><li>Hive连接？</li><li>Hive MapJoin?</li><li>Hive的sort by, order by, distribute by, cluster by区别？</li><li>Hadoop计算框架特性</li><li>Hive优化常用手段</li><li>数据倾斜整理(转)</li><li>使用Hive如何进行抽样查询？</li></ol><h4 id="3-Spark"><a href="#3-Spark" class="headerlink" title="3. Spark"></a>3. Spark</h4><ol><li>Spark的运行模式</li><li>RDD是如何容错的？</li><li>Spark和MapReduce的区别</li><li>说一下Spark的RDD</li><li>自己实现一个RDD，需要实现哪些函数或者部分？</li><li>MapReduce和Spark的区别</li><li>Spark的Stage是怎么划分的？如何优化？</li><li>宽依赖与窄依赖区别</li><li>Spark性能调优</li><li>Flink、Storm与Spark Stream的区别（未）</li><li>说下spark中的transform和action</li><li>RDD、DataFrame和DataSet的区别</li><li>Spark执行任务流程（standalone、yarn）</li><li>Spark的数据容错机制</li><li>Spark技术栈有哪些组件，每个组件都有什么功能，适合什么应用场景？</li><li>Spark master使用zookeeper进行HA的，有哪些元数据保存在Zookeeper？以及要注意的地方</li><li>driver的功能是什么？</li><li>spark端口</li><li>RDD有哪几种创建方式</li><li>map和flatmap的区别</li><li>Spark的基本工作流程</li></ol><h4 id="4-Flink"><a href="#4-Flink" class="headerlink" title="4. Flink"></a>4. Flink</h4><h5 id="4-1-Flink核心概念和基础"><a href="#4-1-Flink核心概念和基础" class="headerlink" title="4.1 Flink核心概念和基础"></a>4.1 Flink核心概念和基础</h5><blockquote><p>第一部分：Flink 中的核心概念和基础篇，包含了 Flink 的整体介绍、核心概念、算子等考察点。</p></blockquote><p>第二部分：Flink 进阶篇，包含了 Flink 中的数据传输、容错机制、序列化、数据热点、反压等实际生产环境中遇到的问题等考察点。</p><p>第三部分：Flink 源码篇，包含了 Flink 的核心代码实现、Job 提交流程、数据交换、分布式快照机制、Flink SQL 的原理等考察点。</p><h4 id="5-Storm："><a href="#5-Storm：" class="headerlink" title="5. Storm："></a><strong>5. Storm：</strong></h4><p>Storm的可靠性如何实现？包括spout和bolt两部分</p><p>怎么提高Storm的并发度？</p><p>Storm如何处理反压机制？</p><p>Storm中的Stream grouping有哪几种方式？</p><p>Storm的组件介绍</p><p>Storm怎么完成对单词的计数？</p><p>简述Strom的计算结构</p><h4 id="6-kafka："><a href="#6-kafka：" class="headerlink" title="6. kafka："></a><strong>6. kafka：</strong></h4><p>kafka介绍</p><p>Kafka与传统消息队列的区别？</p><p>kafka的零拷贝</p><p>kafka消息持久化和顺序读写？</p><h4 id="7-Kylin"><a href="#7-Kylin" class="headerlink" title="7. Kylin"></a>7. Kylin</h4><p>简介Kylin</p><p>Kylin的工作原理</p><p>Kylin的技术框架</p><p>Cube、Cuboid 和 Cube Segment</p><p>Kylin 对维度表的的要求</p><p>Cube的构建过程</p><p>全量构建和增量构建的区别</p><p>流式构建原理</p><h3 id="三-数据库"><a href="#三-数据库" class="headerlink" title="三. 数据库"></a>三. 数据库</h3><pre><code>     1）两大引擎Innodb引擎和MyIASM引擎，      2）mysql索引原理和底层实现BTREE、B+ TREE</code></pre><h3 id="四-数据仓库"><a href="#四-数据仓库" class="headerlink" title="四. 数据仓库"></a>四. 数据仓库</h3><p>​    1）拉链表<br>​    2）星型模型和雪花模型<br>​    3）维度建模过程</p><h3 id="五-操作系统"><a href="#五-操作系统" class="headerlink" title="五. 操作系统"></a>五. 操作系统</h3><p>   1）线程和进程，进程间的通信方式<br>   2）死锁<br>   3）内存分页<br>   4）同步异步阻塞</p><h3 id="六-计算机网络"><a href="#六-计算机网络" class="headerlink" title="六. 计算机网络"></a>六. 计算机网络</h3><ol><li>简述TCP和UDP的区别</li><li>七层协议每一层的任务及作用</li><li>简述http状态码</li><li>简述http协议与https协议</li><li>简述SSL协议</li><li>解析DNS过程</li><li>三次握手，四次挥手的过程？？为什么三握？</li></ol><h3 id="七-Linux"><a href="#七-Linux" class="headerlink" title="七. Linux"></a>七. Linux</h3><h4 id="1-比较常用Linux指令"><a href="#1-比较常用Linux指令" class="headerlink" title="1. 比较常用Linux指令"></a>1. 比较常用Linux指令</h4><p>　　1.1、ls/ll、cd、mkdir、rm-rf、cp、mv、ps -ef | grep xxx、kill、free-m、tar -xvf file.tar、（说那么十几二十来个估计差不多了）</p><h4 id="2-进程相关"><a href="#2-进程相关" class="headerlink" title="2. 进程相关"></a>2. 进程相关</h4><h5 id="查看进程"><a href="#查看进程" class="headerlink" title="查看进程"></a>查看进程</h5><p>　　2.1、ps -ef | grep xxx</p><p>　　2.2、ps -aux | grep xxx（-aux显示所有状态）</p><h5 id="杀掉进程"><a href="#杀掉进程" class="headerlink" title="杀掉进程"></a>杀掉进程</h5><p>　　3.1、kill -9[PID]  —(PID用查看进程的方式查找)</p><p>4、启动/停止服务</p><p>　　4.1、cd到bin目录cd/</p><p>　　4.2、./startup.sh  –打开（先确保有足够的权限）</p><p>　　4.3、./shutdown.sh —关闭</p><p>5、查看日志</p><p>　　5.1、cd到服务器的logs目录（里面有xx.out文件）</p><p>　　5.2、tail -f xx.out –此时屏幕上实时更新日志。ctr+c停止</p><p>　　5.3、查看最后100行日志 tail -100 xx.out </p><p>　　5.4、查看关键字附件的日志。如：cat filename | grep -C 5 ‘关键字’（关键字前后五行。B表示前，A表示后，C表示前后） —-使用不多**<br>**</p><p>　　5.5、还有vi查询啥的。用的也不多。</p><p>6、查看端口：（如查看某个端口是否被占用）</p><p>　　6.1、netstat -anp | grep 端口号（状态为LISTEN表示被占用）</p><p>7、查找文件</p><p>　　7.1、查找大小超过xx的文件： find . -type f -size +xxk —–(find . -type f -mtime -1 -size +100k -size-400k)–查区间大小的文件</p><p>　　7.2、通过文件名：find / -name xxxx  —整个硬盘查找</p><p>　　其余的基本上不常用</p><p>8、vim（vi）编辑器　　</p><p>　　有命令模式、输入模式、末行模式三种模式。<br>　　命令模式：查找内容(/abc、跳转到指定行(20gg)、跳转到尾行(G)、跳转到首行(gg)、删除行(dd)、插入行(o)、复制粘贴(yy,p)<br>　　输入模式：编辑文件内容<br>　　末行模式：保存退出(wq)、强制退出(q!)、显示文件行号(set number)<br>　　在命令模式下，输入a或i即可切换到输入模式，输入冒号(:)即可切换到末行模式；在输入模式和末行模式下，按esc键切换到命令模式</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;面试题目梳理&quot;&gt;&lt;a href=&quot;#面试题目梳理&quot; class=&quot;headerlink&quot; title=&quot;面试题目梳理&quot;&gt;&lt;/a&gt;面试题目梳理&lt;/h2&gt;&lt;h3 id=&quot;一-数据结构和算法-LeetCode&quot;&gt;&lt;a href=&quot;#一-数据结构和算法-LeetCode&quot;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>IDEA环境下Git使用总结</title>
    <link href="https://dataquaner.github.io/2020/04/20/idea-xia-shi-yong-git-cao-zuo/"/>
    <id>https://dataquaner.github.io/2020/04/20/idea-xia-shi-yong-git-cao-zuo/</id>
    <published>2020-04-20T13:40:00.000Z</published>
    <updated>2020-04-20T04:13:12.538Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>工作中多人使用版本控制软件协作开发，常见的应用场景归纳如下：</p><p>假设小组中有两个人，组长小张，组员小袁</p><p>[TOC]</p><h2 id="场景一：小张创建项目并提交到远程Git仓库"><a href="#场景一：小张创建项目并提交到远程Git仓库" class="headerlink" title="场景一：小张创建项目并提交到远程Git仓库"></a>场景一：小张创建项目并提交到远程Git仓库</h2><p>创建好项目，选择VCS - &gt; Import into Version Control -&gt; Create Git Repository</p><p><img src="https://img-blog.csdn.net/20160912161234797" alt="img"></p><p>接下来指定本地仓库的位置，按个人习惯指定即可，例如这里选择了项目源代码同目录</p><p><img src="https://img-blog.csdn.net/20160912161334752" alt="img"></p><p>点击OK后创建完成本地仓库，注意，这里仅仅是本地的。下面把项目源码添加到本地仓库。</p><p>下图是Git与提交有关的三个命令对应的操作，Add命令是把文件从IDE的工作目录添加到本地仓库的stage区，Commit命令把stage区的暂存文件提交到当前分支的仓库，并清空stage区。Push命令把本地仓库的提交同步到远程仓库。</p><p><img src="https://img-blog.csdn.net/20160912164147415" alt="img"></p><p>IDEA中对操作做了一定的简化，Commit和Push可以在一步中完成。</p><p>具体操作，在项目上点击右键，选择Git菜单</p><p><img src="https://img-blog.csdn.net/20160912165901032" alt="img"></p><p><img src="https://img-blog.csdn.net/20160912165911954" alt="img"></p><p><img src="https://img-blog.csdn.net/20160912165921938" alt="img"></p><p>因为是第一次提交，Push前需要指定远程仓库的地址。如下图，点击Define remote后，在弹出的窗口中输入远程仓库地址。</p><p><img src="https://img-blog.csdn.net/20160912165942829" alt="img"></p><h2 id="场景二：小袁从远程Git仓库上获取项目源码"><a href="#场景二：小袁从远程Git仓库上获取项目源码" class="headerlink" title="场景二：小袁从远程Git仓库上获取项目源码"></a>场景二：小袁从远程Git仓库上获取项目源码</h2><p>即克隆项目，操作如下：</p><p><img src="https://img-blog.csdn.net/20160912170148207" alt="img"></p><p>输入小张Push时填写的远程仓库地址</p><p><img src="https://img-blog.csdn.net/20160912170214880" alt="img"></p><p>接下来按向导操作，即可把项目从远程仓库克隆到本地仓库和IDE工作区。</p><h2 id="场景三：小袁修改了部分源码，提交到远程仓库"><a href="#场景三：小袁修改了部分源码，提交到远程仓库" class="headerlink" title="场景三：小袁修改了部分源码，提交到远程仓库"></a>场景三：小袁修改了部分源码，提交到远程仓库</h2><p>这个操作和首次提交的流程基本一致，分别是 Add -&gt; Commit -&gt; Push。请参考场景一</p><h2 id="场景四：小张从远程仓库获取小袁的提交"><a href="#场景四：小张从远程仓库获取小袁的提交" class="headerlink" title="场景四：小张从远程仓库获取小袁的提交"></a>场景四：小张从远程仓库获取小袁的提交</h2><p>获取更新有两个命令：Fetch和Pull，Fetch是从远程仓库下载文件到本地的origin/master，然后可以手动对比修改决定是否合并到本地的master库。Push则是直接下载并合并。如果各成员在工作中都执行修改前先更新的规范，则可以直接使用Pull方式以简化操作。</p><p><img src="https://img-blog.csdn.net/20160912170628933" alt="img"></p><h2 id="场景五：小袁接受了一个新功能的任务，创建了一个分支并在分支上开发"><a href="#场景五：小袁接受了一个新功能的任务，创建了一个分支并在分支上开发" class="headerlink" title="场景五：小袁接受了一个新功能的任务，创建了一个分支并在分支上开发"></a>场景五：小袁接受了一个新功能的任务，创建了一个分支并在分支上开发</h2><p>建分支也是一个常用的操作，例如临时修改bug、开发不确定是否加入的功能等，都可以创建一个分支，再等待合适的时机合并到主干。</p><p>创建流程如下：</p><p><img src="https://img-blog.csdn.net/20160912171844429" alt="img"></p><p>选择New Branch并输入一个分支的名称</p><p><img src="https://img-blog.csdn.net/20160912171858663" alt="img"></p><p>创建完成后注意IDEA的右下角，如下图，Git: wangpangzi_branch表示已经自动切换到wangpangzi_branch分支，当前工作在这个分支上。</p><p>点击后弹出一个小窗口，在Local Branches中有其他可用的本地分支选项，点击后选择Checkout即可切换当前工作的分支。</p><p><img src="https://img-blog.csdn.net/20160912173123122" alt="img"></p><p>如下图，点击Checkout</p><p><img src="https://img-blog.csdn.net/20160912173307202" alt="img"></p><p>注意，这里创建的分支仅仅在本地仓库，如果想让组长小张获取到这个分支，还需要提交到远程仓库。</p><h2 id="场景六：小袁把分支提交到远程Git仓库"><a href="#场景六：小袁把分支提交到远程Git仓库" class="headerlink" title="场景六：小袁把分支提交到远程Git仓库"></a>场景六：小袁把分支提交到远程Git仓库</h2><p>切换到新建的分支，使用Push功能</p><p><img src="https://img-blog.csdn.net/20160912173718844" alt="img"></p><p><img src="https://img-blog.csdn.net/20160912174243815" alt="img"></p><h2 id="场景七：小张获取小袁提交的分支"><a href="#场景七：小张获取小袁提交的分支" class="headerlink" title="场景七：小张获取小袁提交的分支"></a>场景七：小张获取小袁提交的分支</h2><p>使用Pull功能打开更新窗口，点击Remote栏后面的刷新按钮，会在Branches to merge栏中刷新出新的分支。这里并不想做合并，所以不要选中任何分支，直接点击Pull按钮完成操作。</p><p><img src="https://img-blog.csdn.net/20160912174329143" alt="img"></p><p>更新后，再点击右下角，可以看到在Remote Branches区已经有了新的分支，点击后在弹出的子菜单中选择Checkout as new local branch，在本地仓库中创建该分支。完成后在Local Branches区也会出现该分支的选项，可以按上面的方法，点击后选择Checkout切换。</p><p><img src="https://img-blog.csdn.net/20160912174729488" alt="img"></p><h2 id="场景八：小张把分支合并到主干"><a href="#场景八：小张把分支合并到主干" class="headerlink" title="场景八：小张把分支合并到主干"></a>场景八：小张把分支合并到主干</h2><p>新功能开发完成，体验很好，项目组决定把该功能合并到主干上。</p><p>切换到master分支，选择Merge Changes</p><p><img src="https://img-blog.csdn.net/20160912175201306" alt="img"></p><p>选择要合并的分支，点击Merge完成</p><p><img src="https://img-blog.csdn.net/20160912175359903" alt="img"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;p&gt;工作中多人使用版本控制软件协作开发，常见的应用场景归纳如下：&lt;/p&gt;
&lt;p&gt;假设小组中有两个人，组长小张，组员小袁&lt;/p&gt;
&lt;p&gt;[TOC]
      
    
    </summary>
    
    
      <category term="Git" scheme="https://dataquaner.github.io/categories/Git/"/>
    
    
      <category term="IDEA" scheme="https://dataquaner.github.io/tags/IDEA/"/>
    
      <category term="Git" scheme="https://dataquaner.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>Flink面试问题梳理(基础+进阶+源码)</title>
    <link href="https://dataquaner.github.io/2020/04/18/flink-mian-shi-wen-ti-shu-li-ji-chu-jin-jie-yuan-ma/"/>
    <id>https://dataquaner.github.io/2020/04/18/flink-mian-shi-wen-ti-shu-li-ji-chu-jin-jie-yuan-ma/</id>
    <published>2020-04-18T13:40:00.000Z</published>
    <updated>2020-04-18T14:39:18.053Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第一部分：Flink-面试基础篇"><a href="#第一部分：Flink-面试基础篇" class="headerlink" title="第一部分：Flink 面试基础篇"></a><strong>第一部分：Flink 面试基础篇</strong></h2><h3 id="1-简单介绍一下-Flink"><a href="#1-简单介绍一下-Flink" class="headerlink" title="1. 简单介绍一下 Flink"></a><strong>1. 简单介绍一下 Flink</strong></h3><p>​        Flink 是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。并且 Flink 提供了数据分布、容错机制以及资源管理等核心功能。</p><p>​        Flink提供了诸多高抽象层的API以便用户编写分布式任务：</p><ul><li><p>DataSet API， 对静态数据进行批处理操作，将静态数据抽象成分布式的数据集，用户可以方便地使用Flink提供的各种操作符对分布式数据集进行处理，支持Java、Scala和Python。</p></li><li><p>DataStream API，对数据流进行流处理操作，将流式的数据抽象成分布式的数据流，用户可以方便地对分布式数据流进行各种操作，支持Java和Scala。</p></li><li><p>Table API，对结构化数据进行查询操作，将结构化数据抽象成关系表，并通过类SQL的DSL对关系表进行各种查询操作，支持Java和Scala。</p></li></ul><p>​      此外，Flink 还针对特定的应用领域提供了领域库，例如：Flink ML，Flink 的机器学习库，提供了机器学习Pipelines API并实现了多种机器学习算法。Gelly，Flink 的图计算库，提供了图计算的相关API及多种图计算算法实现。</p><p>根据官网的介绍，Flink 的特性包含：</p><blockquote><p>支持高吞吐、低延迟、高性能的流处理<br>支持带有事件时间的窗口 （Window） 操作<br>支持有状态计算的 Exactly-once 语义<br>支持高度灵活的窗口 （Window） 操作，支持基于 time、count、session 以及 data-driven 的窗口操作<br>支持具有 Backpressure 功能的持续流模型<br>支持基于轻量级分布式快照（Snapshot）实现的容错<br>一个运行时同时支持 Batch on Streaming 处理和 Streaming 处理<br>Flink 在 JVM 内部实现了自己的内存管理<br>支持迭代计算<br>支持程序自动优化：避免特定情况下 Shuffle、排序等昂贵操作，中间结果有必要进行缓存</p></blockquote><h3 id="2-Flink-相比传统的-Spark-Streaming-有什么区别"><a href="#2-Flink-相比传统的-Spark-Streaming-有什么区别" class="headerlink" title="2. Flink 相比传统的 Spark Streaming 有什么区别?"></a><strong>2. Flink 相比传统的 Spark Streaming 有什么区别?</strong></h3><p>​       这个问题是一个非常宏观的问题，因为两个框架的不同点非常之多。但是在面试时有非常重要的一点一定要回答出来：</p><blockquote><p><strong>Flink 是标准的实时处理引擎，基于事件驱动。而 Spark Streaming 是微批（Micro-Batch）的模型。</strong></p></blockquote><p>下面我们就分几个方面介绍两个框架的主要区别：</p><h4 id="1-架构模型"><a href="#1-架构模型" class="headerlink" title="[1] 架构模型"></a><strong>[1] 架构模型</strong></h4><p>​      Spark Streaming 在运行时的主要角色包括：Master、Worker、Driver、Executor，Flink 在运行时主要包含：Jobmanager、Taskmanager和Slot。</p><h4 id="2-任务调度"><a href="#2-任务调度" class="headerlink" title="[2] 任务调度"></a><strong>[2] 任务调度</strong></h4><p>​       Spark Streaming 连续不断的生成微小的数据批次，构建有向无环图DAG，Spark Streaming 会依次创建 DStreamGraph、JobGenerator、JobScheduler。</p><p>​       Flink 根据用户提交的代码生成 StreamGraph，经过优化生成 JobGraph，然后提交给 JobManager进行处理，JobManager 会根据 JobGraph 生成 ExecutionGraph，ExecutionGraph 是 Flink 调度最核心的数据结构，JobManager 根据 ExecutionGraph 对 Job 进行调度。</p><h4 id="3-时间机制"><a href="#3-时间机制" class="headerlink" title="[3] 时间机制"></a><strong>[3] 时间机制</strong></h4><p>​        Spark Streaming 支持的时间机制有限，只支持<strong>处理时间</strong>。Flink 支持了流处理程序在时间上的三个定义：<strong>处理时间、事件时间、注入时间</strong>。同时也支持 <strong>watermark</strong> 机制来处理滞后数据。</p><h4 id="4-容错机制"><a href="#4-容错机制" class="headerlink" title="[4] 容错机制"></a><strong>[4] 容错机制</strong></h4><p>​        对于 Spark Streaming 任务，我们可以设置 checkpoint，然后假如发生故障并重启，我们可以从上次 checkpoint 之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到恰一次处理语义。</p><p>​         Flink 则使用两阶段提交协议来解决这个问题。</p><h3 id="3-Flink-的组件栈有哪些？"><a href="#3-Flink-的组件栈有哪些？" class="headerlink" title="3. Flink 的组件栈有哪些？"></a><strong>3. Flink 的组件栈有哪些？</strong></h3><p>​        根据 Flink 官网描述，Flink 是一个分层架构的系统，每一层所包含的组件都提供了特定的抽象，用来服务于上层组件。</p><p><img src="https://pic1.zhimg.com/80/v2-3d7d9b6e80a843212a4d168b500af1d8_1440w.jpg" alt="img"></p><p>图片来源于：<a href="https://link.zhihu.com/?target=https%3A//flink.apache.org">https://flink.apache.org</a></p><p>​         自下而上，每一层分别代表：</p><blockquote><ul><li>Deploy 层：该层主要涉及了Flink的部署模式，在上图中我们可以看出，Flink 支持包括local、Standalone、Cluster、Cloud等多种部署模式。</li><li>Runtime 层：Runtime层提供了支持 Flink 计算的核心实现，比如：支持分布式 Stream 处理、JobGraph到ExecutionGraph的映射、调度等等，为上层API层提供基础服务。</li><li>API层：API 层主要实现了面向流（Stream）处理和批（Batch）处理API，其中面向流处理对应DataStream API，面向批处理对应DataSet API，后续版本，Flink有计划将DataStream和DataSet API进行统一。</li><li>Libraries层：该层称为Flink应用框架层，根据API层的划分，在API层之上构建的满足特定应用的实现计算框架，也分别对应于面向流处理和面向批处理两类。面向流处理支持：CEP（复杂事件处理）、基于SQL-like的操作（基于Table的关系操作）；面向批处理支持：FlinkML（机器学习库）、Gelly（图处理）。</li></ul></blockquote><h3 id="4-Flink-的运行必须依赖-Hadoop组件吗？"><a href="#4-Flink-的运行必须依赖-Hadoop组件吗？" class="headerlink" title="4. Flink 的运行必须依赖 Hadoop组件吗？"></a><strong>4. Flink 的运行必须依赖 Hadoop组件吗？</strong></h3><p>​        Flink可以完全独立于Hadoop，在不依赖Hadoop组件下运行。但是做为大数据的基础设施，Hadoop体系是任何大数据框架都绕不过去的。Flink可以集成众多Hadoop 组件，例如Yarn、Hbase、HDFS等等。例如，Flink可以和Yarn集成做资源调度，也可以读写HDFS，或者利用HDFS做检查点。</p><h3 id="5-你们的Flink集群规模多大？"><a href="#5-你们的Flink集群规模多大？" class="headerlink" title="5. 你们的Flink集群规模多大？"></a><strong>5. 你们的Flink集群规模多大？</strong></h3><p>​      大家注意，这个问题看起来是问你实际应用中的Flink集群规模，其实还隐藏着另一个问题：Flink可以支持多少节点的集群规模？</p><p>​      在回答这个问题时候，可以将自己生产环节中的集群规模、节点、内存情况说明，同时说明部署模式（一般是Flink on Yarn），除此之外，用户也可以同时在小集群（少于5个节点）和拥有 TB 级别状态的上千个节点上运行 Flink 任务。</p><h3 id="6-Flink的基础编程模型了解吗？"><a href="#6-Flink的基础编程模型了解吗？" class="headerlink" title="6. Flink的基础编程模型了解吗？"></a><strong>6. Flink的基础编程模型了解吗？</strong></h3><p><img src="https://pic2.zhimg.com/80/v2-2e5a594aaa7dd3efdcbb2c3f9e5a8fa9_1440w.jpg" alt="img"></p><p>​        上图是来自Flink官网的运行流程图。通过上图我们可以得知，Flink 程序的基本构建是数据输入来自一个 Source，Source 代表数据的输入端，经过 Transformation 进行转换，然后在一个或者多个Sink接收器中结束。数据流（stream）就是一组永远不会停止的数据记录流，而转换（transformation）是将一个或多个流作为输入，并生成一个或多个输出流的操作。执行时，Flink程序映射到 streaming dataflows，由流（streams）和转换操作（transformation operators）组成。</p><h3 id="7-Flink集群有哪些角色？各自有什么作用？"><a href="#7-Flink集群有哪些角色？各自有什么作用？" class="headerlink" title="7. Flink集群有哪些角色？各自有什么作用？"></a><strong>7. Flink集群有哪些角色？各自有什么作用？</strong></h3><p><img src="https://pic3.zhimg.com/80/v2-a0c80153cec85fc9cd165d862b4d489e_1440w.jpg" alt="img"></p><p>​       Flink 程序在运行时主要有 TaskManager，JobManager，Client三种角色。其中JobManager扮演着集群中的管理者Master的角色，它是整个集群的协调者，负责接收Flink Job，协调检查点，Failover 故障恢复等，同时管理Flink集群中从节点TaskManager。</p><p>​      TaskManager是实际负责执行计算的Worker，在其上执行Flink Job的一组Task，每个TaskManager负责管理其所在节点上的资源信息，如内存、磁盘、网络，在启动的时候将资源的状态向JobManager汇报。</p><p>​      Client是Flink程序提交的客户端，当用户提交一个Flink程序时，会首先创建一个Client，该Client首先会对用户提交的Flink程序进行预处理，并提交到Flink集群中处理，所以Client需要从用户提交的Flink程序配置中获取JobManager的地址，并建立到JobManager的连接，将Flink Job提交给JobManager。</p><h3 id="8-说说-Flink-资源管理中-Task-Slot-的概念"><a href="#8-说说-Flink-资源管理中-Task-Slot-的概念" class="headerlink" title="8. 说说 Flink 资源管理中 Task Slot 的概念"></a><strong>8. 说说 Flink 资源管理中 Task Slot 的概念</strong></h3><p><img src="https://pic4.zhimg.com/80/v2-c692077d1cd718ad5671fa7d6128db93_1440w.jpg" alt="img"></p><p>​        在Flink架构角色中我们提到，TaskManager是实际负责执行计算的Worker，TaskManager 是一个 JVM 进程，并会以独立的线程来执行一个task或多个subtask。为了控制一个 TaskManager 能接受多少个 task，Flink 提出了 Task Slot 的概念。</p><p>​       简单的说，TaskManager会将自己节点上管理的资源分为不同的Slot：固定大小的资源子集。这样就避免了不同Job的Task互相竞争内存资源，但是需要主要的是，Slot只会做内存的隔离。没有做CPU的隔离。</p><h3 id="9-说说-Flink-的常用算子？"><a href="#9-说说-Flink-的常用算子？" class="headerlink" title="9. 说说 Flink 的常用算子？"></a><strong>9. 说说 Flink 的常用算子？</strong></h3><p>​        Flink 最常用的常用算子包括：Map：DataStream → DataStream，输入一个参数产生一个参数，map的功能是对输入的参数进行转换操作。Filter：过滤掉指定条件的数据。KeyBy：按照指定的key进行分组。Reduce：用来进行结果汇总合并。Window：窗口函数，根据某些特性将每个key的数据进行分组（例如：在5s内到达的数据）</p><h3 id="10-说说你知道的Flink分区策略？"><a href="#10-说说你知道的Flink分区策略？" class="headerlink" title="10. 说说你知道的Flink分区策略？"></a><strong>10. 说说你知道的Flink分区策略？</strong></h3><p>​       什么要搞懂什么是分区策略。分区策略是用来决定数据如何发送至下游。目前 Flink 支持了8中分区策略的实现。</p><p><img src="https://pic2.zhimg.com/80/v2-135f2ee43f63fd4275f5e437fb21dda9_1440w.jpg" alt="img"></p><p>上图是整个Flink实现的分区策略继承图：</p><blockquote><ul><li><strong>GlobalPartitioner</strong>数据会被分发到下游算子的第一个实例中进行处理。</li><li><strong>ShufflePartitioner</strong>数据会被随机分发到下游算子的每一个实例中进行处理。</li><li><strong>RebalancePartitioner</strong>数据会被循环发送到下游的每一个实例中进行处理。</li><li><strong>RescalePartitioner</strong>这种分区器会根据上下游算子的并行度，循环的方式输出到下游算子的每个实例。这里有点难以理解，假设上游并行度为2，编号为A和B。下游并行度为4，编号为1，2，3，4。那么A则把数据循环发送给1和2，B则把数据循环发送给3和4。假设上游并行度为4，编号为A，B，C，D。下游并行度为2，编号为1，2。那么A和B则把数据发送给1，C和D则把数据发送给2。</li><li><strong>BroadcastPartitioner</strong>广播分区会将上游数据输出到下游算子的每个实例中。适合于大数据集和小数据集做join的场景。</li><li><strong>ForwardPartitioner</strong> 用于将记录输出到下游本地的算子实例。它要求上下游算子并行度一样。简单的说，ForwardPartitioner用来做数据的控制台打印。</li><li><strong>KeyGroupStreamPartitioner</strong> Hash分区器。会将数据按 Key 的 Hash 值输出到下游算子实例中。</li><li><strong>CustomPartitionerWrapper</strong>用户自定义分区器。需要用户自己实现Partitioner接口，来定义自己的分区逻辑。</li></ul></blockquote><h3 id="11-Flink的并行度了解吗？Flink的并行度设置是怎样的？"><a href="#11-Flink的并行度了解吗？Flink的并行度设置是怎样的？" class="headerlink" title="11. Flink的并行度了解吗？Flink的并行度设置是怎样的？"></a><strong>11. Flink的并行度了解吗？Flink的并行度设置是怎样的？</strong></h3><p>​        Flink中的任务被分为多个并行任务来执行，其中每个并行的实例处理一部分数据。这些并行实例的数量被称为并行度。</p><p>​      我们在实际生产环境中可以从四个不同层面设置并行度：</p><ul><li><p>操作算子层面(Operator Level)</p></li><li><p>执行环境层面(Execution Environment Level)</p></li><li><p>客户端层面(Client Level)</p></li><li><p>系统层面(System Level)</p></li></ul><p>需要注意的优先级：算子层面&gt;环境层面&gt;客户端层面&gt;系统层面。</p><h3 id="12-Flink的Slot和parallelism有什么区别？"><a href="#12-Flink的Slot和parallelism有什么区别？" class="headerlink" title="12. Flink的Slot和parallelism有什么区别？"></a><strong>12. Flink的Slot和parallelism有什么区别？</strong></h3><p>官网上十分经典的图：</p><p><img src="https://pic2.zhimg.com/80/v2-d4ee22523e404ce88195bf5c4696f361_1440w.jpg" alt="img"></p><p>slot是指taskmanager的并发执行能力，假设我们将 taskmanager.numberOfTaskSlots 配置为3那么每一个 taskmanager 中分配3个 TaskSlot, 3个 taskmanager 一共有9个TaskSlot。</p><p><img src="https://pic4.zhimg.com/80/v2-855ff152aad46e75981864e13df3740b_1440w.jpg" alt="img"></p><p>parallelism是指taskmanager实际使用的并发能力。假设我们把 parallelism.default 设置为1，那么9个 TaskSlot 只能用1个，有8个空闲。</p><h3 id="13-Flink有没有重启策略？说说有哪几种？"><a href="#13-Flink有没有重启策略？说说有哪几种？" class="headerlink" title="13. Flink有没有重启策略？说说有哪几种？"></a><strong>13. Flink有没有重启策略？说说有哪几种？</strong></h3><p>Flink 实现了多种重启策略。</p><ul><li><p>固定延迟重启策略（Fixed Delay Restart Strategy）</p></li><li><p>故障率重启策略（Failure Rate Restart Strategy）</p></li><li><p>没有重启策略（No Restart Strategy）</p></li><li><p>Fallback重启策略（Fallback Restart Strategy）</p></li></ul><h3 id="14-用过Flink中的分布式缓存吗？如何使用？"><a href="#14-用过Flink中的分布式缓存吗？如何使用？" class="headerlink" title="14. 用过Flink中的分布式缓存吗？如何使用？"></a><strong>14. 用过Flink中的分布式缓存吗？如何使用？</strong></h3><p>​        Flink实现的分布式缓存和Hadoop有异曲同工之妙。目的是在本地读取文件，并把他放在 taskmanager 节点中，防止task重复拉取。</p><pre class="line-numbers language-text"><code class="language-text">val env = ExecutionEnvironment.getExecutionEnvironment// register a file from HDFSenv.registerCachedFile("hdfs:///path/to/your/file", "hdfsFile")// register a local executable file (script, executable, ...)env.registerCachedFile("file:///path/to/exec/file", "localExecFile", true)// define your program and execute...val input: DataSet[String] = ...val result: DataSet[Integer] = input.map(new MyMapper())...env.execute()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="15-说说Flink中的广播变量，使用时需要注意什么？"><a href="#15-说说Flink中的广播变量，使用时需要注意什么？" class="headerlink" title="15. 说说Flink中的广播变量，使用时需要注意什么？"></a><strong>15. 说说Flink中的广播变量，使用时需要注意什么？</strong></h3><p>​        我们知道Flink是并行的，计算过程可能不在一个 Slot 中进行，那么有一种情况即：当我们需要访问同一份数据。那么Flink中的广播变量就是为了解决这种情况。</p><p>​        我们可以把广播变量理解为是一个公共的共享变量，我们可以把一个dataset 数据集广播出去，然后不同的task在节点上都能够获取到，这个数据在每个节点上只会存在一份。</p><h3 id="16-说说Flink中的窗口？"><a href="#16-说说Flink中的窗口？" class="headerlink" title="16. 说说Flink中的窗口？"></a><strong>16. 说说Flink中的窗口？</strong></h3><p>​      来一张官网经典的图：</p><p><img src="https://pic3.zhimg.com/80/v2-c4faa8da0a50b8dbf8f07ed978890106_1440w.jpg" alt="img"></p><p>​        Flink 支持两种划分窗口的方式，按照time和count。如果根据时间划分窗口，那么它就是一个time-window 如果根据数据划分窗口，那么它就是一个count-window。</p><p>​        flink支持窗口的两个重要属性（size和interval）</p><p>​        如果size=interval,那么就会形成tumbling-window(无重叠数据)如果size&gt;interval,那么就会形成sliding-window(有重叠数据)如果size&lt; interval, 那么这种窗口将会丢失数据。比如每5秒钟，统计过去3秒的通过路口汽车的数据，将会漏掉2秒钟的数据。</p><p>​        通过组合可以得出四种基本窗口：</p><ul><li><p>time-tumbling-window 无重叠数据的时间窗口，设置方式举例：timeWindow(Time.seconds(5))</p></li><li><p>time-sliding-window 有重叠数据的时间窗口，设置方式举例：timeWindow(Time.seconds(5), Time.seconds(3))</p></li><li><p>count-tumbling-window无重叠数据的数量窗口，设置方式举例：countWindow(5)</p></li><li><p>count-sliding-window 有重叠数据的数量窗口，设置方式举例：countWindow(5,3)</p></li></ul><h3 id="17-说说Flink中的状态存储？"><a href="#17-说说Flink中的状态存储？" class="headerlink" title="17. 说说Flink中的状态存储？"></a><strong>17. 说说Flink中的状态存储？</strong></h3><p>​        Flink在做计算的过程中经常需要存储中间状态，来避免数据丢失和状态恢复。选择的状态存储策略不同，会影响状态持久化如何和 checkpoint 交互。</p><p>​        Flink提供了三种状态存储方式：MemoryStateBackend、FsStateBackend、RocksDBStateBackend。</p><h3 id="18-Flink-中的时间有哪几类"><a href="#18-Flink-中的时间有哪几类" class="headerlink" title="18. Flink 中的时间有哪几类"></a><strong>18. Flink 中的时间有哪几类</strong></h3><p>​        Flink 中的时间和其他流式计算系统的时间一样分为三类：事件时间，摄入时间，处理时间三种。</p><ul><li>如果以 EventTime 为基准来定义时间窗口将形成EventTimeWindow,要求消息本身就应该携带EventTime。</li><li>如果以 IngesingtTime 为基准来定义时间窗口将形成 IngestingTimeWindow,以 source 的systemTime为准。</li><li>如果以 ProcessingTime 基准来定义时间窗口将形成 ProcessingTimeWindow，以 operator 的systemTime 为准。</li></ul><h3 id="19-Flink-中水印是什么概念，起到什么作用？"><a href="#19-Flink-中水印是什么概念，起到什么作用？" class="headerlink" title="19. Flink 中水印是什么概念，起到什么作用？"></a><strong>19. Flink 中水印是什么概念，起到什么作用？</strong></h3><p>​       Watermark 是 Apache Flink 为了处理 EventTime 窗口计算提出的一种机制, 本质上是一种时间戳。一般来讲Watermark经常和Window一起被用来处理乱序事件。</p><h3 id="20-Flink-Table-amp-SQL-熟悉吗？TableEnvironment这个类有什么作用"><a href="#20-Flink-Table-amp-SQL-熟悉吗？TableEnvironment这个类有什么作用" class="headerlink" title="20. Flink Table &amp; SQL 熟悉吗？TableEnvironment这个类有什么作用"></a><strong>20. Flink Table &amp; SQL 熟悉吗？TableEnvironment这个类有什么作用</strong></h3><p>​       TableEnvironment是Table API和SQL集成的核心概念。</p><p>这个类主要用来：</p><ul><li><p>在内部catalog中注册表</p></li><li><p>注册外部catalog</p></li><li><p>执行SQL查询</p></li><li><p>注册用户定义（标量，表或聚合）函数</p></li><li><p>将DataStream或DataSet转换为表</p></li><li><p>持有对ExecutionEnvironment或StreamExecutionEnvironment的引用</p></li></ul><h3 id="21-Flink-SQL的实现原理是什么？-是如何实现-SQL-解析的呢？"><a href="#21-Flink-SQL的实现原理是什么？-是如何实现-SQL-解析的呢？" class="headerlink" title="21. Flink SQL的实现原理是什么？ 是如何实现 SQL 解析的呢？"></a><strong>21. Flink SQL的实现原理是什么？ 是如何实现 SQL 解析的呢？</strong></h3><p>​      首先大家要知道 Flink 的SQL解析是基于Apache Calcite这个开源框架。</p><p><img src="https://pic2.zhimg.com/80/v2-c3877f035a976a213eab756465c2ebfd_1440w.jpg" alt="img"></p><p>基于此，一次完整的SQL解析过程如下：</p><blockquote><ul><li><p>用户使用对外提供Stream SQL的语法开发业务应用</p></li><li><p>用calcite对StreamSQL进行语法检验，语法检验通过后，转换成calcite的逻辑树节点；最终形成calcite的逻辑计划</p></li><li><p>采用Flink自定义的优化规则和calcite火山模型、启发式模型共同对逻辑树进行优化，生成最优的Flink物理计划</p></li><li><p>对物理计划采用janino codegen生成代码，生成用低阶API DataStream 描述的流应用，提交到Flink平台执行</p></li></ul></blockquote><h2 id="第二部分：Flink-面试进阶篇"><a href="#第二部分：Flink-面试进阶篇" class="headerlink" title="第二部分：Flink 面试进阶篇"></a><strong>第二部分：Flink 面试进阶篇</strong></h2><h3 id="1-Flink是如何支持批流一体的？"><a href="#1-Flink是如何支持批流一体的？" class="headerlink" title="1. Flink是如何支持批流一体的？"></a><strong>1. Flink是如何支持批流一体的？</strong></h3><p><img src="https://pic2.zhimg.com/80/v2-36a937f492576709a89e8f25c1bed4a9_1440w.jpg" alt="img"></p><p>​       本道面试题考察的其实就是一句话：Flink的开发者认为批处理是流处理的一种特殊情况。批处理是有限的流处理。Flink 使用一个引擎支持了DataSet API 和 DataStream API。</p><h3 id="2-Flink是如何做到高效的数据交换的？"><a href="#2-Flink是如何做到高效的数据交换的？" class="headerlink" title="2. Flink是如何做到高效的数据交换的？"></a><strong>2. Flink是如何做到高效的数据交换的？</strong></h3><p>​         在一个Flink Job中，数据需要在不同的task中进行交换，整个数据交换是有 TaskManager 负责的，TaskManager 的网络组件首先从缓冲buffer中收集records，然后再发送。Records 并不是一个一个被发送的，二是积累一个批次再发送，batch 技术可以更加高效的利用网络资源。</p><h3 id="3-Flink是如何做容错的？"><a href="#3-Flink是如何做容错的？" class="headerlink" title="3. Flink是如何做容错的？"></a><strong>3. Flink是如何做容错的？</strong></h3><p>​        Flink 实现容错主要靠强大的CheckPoint机制和State机制。Checkpoint 负责定时制作分布式快照、对程序中的状态进行备份；State 用来存储计算过程中的中间状态。</p><h3 id="4-Flink-分布式快照的原理是什么？"><a href="#4-Flink-分布式快照的原理是什么？" class="headerlink" title="4. Flink 分布式快照的原理是什么？"></a><strong>4. Flink 分布式快照的原理是什么？</strong></h3><p>​        Flink的分布式快照是根据Chandy-Lamport算法量身定做的。简单来说就是持续创建分布式数据流及其状态的一致快照。</p><p><img src="https://pic2.zhimg.com/80/v2-4207ea26cfbf1c4d6528137a50b7add9_1440w.jpg" alt="img"></p><p>​       核心思想是在 input source 端插入 barrier，控制 barrier 的同步来实现 snapshot 的备份和 exactly-once 语义。</p><h3 id="5-Flink-是如何保证Exactly-once语义的？"><a href="#5-Flink-是如何保证Exactly-once语义的？" class="headerlink" title="5. Flink 是如何保证Exactly-once语义的？"></a><strong>5. Flink 是如何保证Exactly-once语义的？</strong></h3><p>​      Flink通过实现两阶段提交和状态保存来实现端到端的一致性语义。分为以下几个步骤：</p><ul><li><p>开始事务（beginTransaction）创建一个临时文件夹，来写把数据写入到这个文件夹里面</p></li><li><p>预提交（preCommit）将内存中缓存的数据写入文件并关闭</p></li><li><p>正式提交（commit）将之前写完的临时文件放入目标目录下。这代表着最终的数据会有一些延迟</p></li><li><p>丢弃（abort）丢弃临时文件</p></li></ul><p>​    若失败发生在预提交成功后，正式提交前。可以根据状态来提交预提交的数据，也可删除预提交的数据。</p><h3 id="6-Flink-的-kafka-连接器有什么特别的地方？"><a href="#6-Flink-的-kafka-连接器有什么特别的地方？" class="headerlink" title="6. Flink 的 kafka 连接器有什么特别的地方？"></a><strong>6. Flink 的 kafka 连接器有什么特别的地方？</strong></h3><p>​     Flink源码中有一个独立的connector模块，所有的其他connector都依赖于此模块，Flink 在1.9版本发布的全新kafka连接器，摒弃了之前连接不同版本的kafka集群需要依赖不同版本的connector这种做法，只需要依赖一个connector即可。</p><h3 id="7-说说-Flink的内存管理是如何做的"><a href="#7-说说-Flink的内存管理是如何做的" class="headerlink" title="7. 说说 Flink的内存管理是如何做的?"></a><strong>7. 说说 Flink的内存管理是如何做的?</strong></h3><p>​       Flink 并不是将大量对象存在堆上，而是将对象都序列化到一个预分配的内存块上。此外，Flink大量的使用了堆外内存。如果需要处理的数据超出了内存限制，则会将部分数据存储到硬盘上。Flink 为了直接操作二进制数据实现了自己的序列化框架。</p><p>理论上Flink的内存管理分为三部分：</p><ul><li><p>Network Buffers：这个是在TaskManager启动的时候分配的，这是一组用于缓存网络数据的内存，每个块是32K，默认分配2048个，可以通过“taskmanager.network.numberOfBuffers”修改</p></li><li><p>Memory Manage pool：大量的Memory Segment块，用于运行时的算法（Sort/Join/Shuffle等），这部分启动的时候就会分配。下面这段代码，根据配置文件中的各种参数来计算内存的分配方法。（heap or off-heap，这个放到下节谈），内存的分配支持预分配和lazy load，默认懒加载的方式。</p></li><li><p>User Code，这部分是除了Memory Manager之外的内存用于User code和TaskManager本身的数据结构。</p></li></ul><h3 id="8-说说-Flink的序列化如何做的"><a href="#8-说说-Flink的序列化如何做的" class="headerlink" title="8. 说说 Flink的序列化如何做的?"></a><strong>8. 说说 Flink的序列化如何做的?</strong></h3><p>​       Java本身自带的序列化和反序列化的功能，但是辅助信息占用空间比较大，在序列化对象时记录了过多的类信息。</p><p>​      Apache Flink摒弃了Java原生的序列化方法，以独特的方式处理数据类型和序列化，包含自己的类型描述符，泛型类型提取和类型序列化框架。</p><p>​     TypeInformation 是所有类型描述符的基类。它揭示了该类型的一些基本属性，并且可以生成序列化器。TypeInformation 支持以下几种类型：</p><ul><li><p>BasicTypeInfo: 任意Java 基本类型或 String 类型</p></li><li><p>BasicArrayTypeInfo: 任意Java基本类型数组或 String 数组</p></li><li><p>WritableTypeInfo: 任意 Hadoop Writable 接口的实现类</p></li><li><p>TupleTypeInfo: 任意的 Flink Tuple 类型(支持Tuple1 to Tuple25)。Flink tuples 是固定长度固定类型的Java Tuple实现</p></li><li><p>CaseClassTypeInfo: 任意的 Scala CaseClass(包括 Scala tuples)</p></li><li><p>PojoTypeInfo: 任意的 POJO (Java or Scala)，例如，Java对象的所有成员变量，要么是 public 修饰符定义，要么有 getter/setter 方法</p></li><li><p>GenericTypeInfo: 任意无法匹配之前几种类型的类</p></li></ul><p>​       针对前六种类型数据集，Flink皆可以自动生成对应的TypeSerializer，能非常高效地对数据集进行序列化和反序列化。</p><h3 id="9-Flink中的Window出现了数据倾斜，你有什么解决办法？"><a href="#9-Flink中的Window出现了数据倾斜，你有什么解决办法？" class="headerlink" title="9.  Flink中的Window出现了数据倾斜，你有什么解决办法？"></a><strong>9.  Flink中的Window出现了数据倾斜，你有什么解决办法？</strong></h3><p>​       window产生数据倾斜指的是数据在不同的窗口内堆积的数据量相差过多。本质上产生这种情况的原因是数据源头发送的数据量速度不同导致的。出现这种情况一般通过两种方式来解决：</p><ul><li><p>在数据进入窗口前做预聚合</p></li><li><p>重新设计窗口聚合的key</p></li></ul><h3 id="10-Flink中在使用聚合函数-GroupBy、Distinct、KeyBy-等函数时出现数据热点该如何解决？"><a href="#10-Flink中在使用聚合函数-GroupBy、Distinct、KeyBy-等函数时出现数据热点该如何解决？" class="headerlink" title="10.  Flink中在使用聚合函数 GroupBy、Distinct、KeyBy 等函数时出现数据热点该如何解决？"></a><strong>10.  Flink中在使用聚合函数 GroupBy、Distinct、KeyBy 等函数时出现数据热点该如何解决？</strong></h3><p>​      数据倾斜和数据热点是所有大数据框架绕不过去的问题。处理这类问题主要从3个方面入手：</p><ul><li>在业务上规避这类问题</li></ul><p>​      例如一个假设订单场景，北京和上海两个城市订单量增长几十倍，其余城市的数据量不变。这时候我们在进行聚合的时候，北京和上海就会出现数据堆积，我们可以单独数据北京和上海的数据。</p><ul><li>Key的设计上</li></ul><p>​     把热key进行拆分，比如上个例子中的北京和上海，可以把北京和上海按照地区进行拆分聚合。</p><ul><li>参数设置</li></ul><p>​     Flink 1.9.0 SQL(Blink Planner) 性能优化中一项重要的改进就是升级了微批模型，即 MiniBatch。原理是缓存一定的数据后再触发处理，以减少对State的访问，从而提升吞吐和减少数据的输出量。</p><h3 id="11-Flink任务延迟高，想解决这个问题，你会如何入手？"><a href="#11-Flink任务延迟高，想解决这个问题，你会如何入手？" class="headerlink" title="11. Flink任务延迟高，想解决这个问题，你会如何入手？"></a><strong>11. Flink任务延迟高，想解决这个问题，你会如何入手？</strong></h3><p>​     在Flink的后台任务管理中，我们可以看到Flink的哪个算子和task出现了反压。最主要的手段是资源调优和算子调优。资源调优即是对作业中的Operator的并发数（parallelism）、CPU（core）、堆内存（heap_memory）等参数进行调优。作业参数调优包括：并行度的设置，State的设置，checkpoint的设置。</p><h3 id="12-Flink是如何处理反压的？"><a href="#12-Flink是如何处理反压的？" class="headerlink" title="12. Flink是如何处理反压的？"></a><strong>12. Flink是如何处理反压的？</strong></h3><p>​       Flink 内部是基于 producer-consumer 模型来进行消息传递的，Flink的反压设计也是基于这个模型。Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。下游消费者消费变慢，上游就会受到阻塞。</p><h3 id="13-Flink的反压和Storm有哪些不同？"><a href="#13-Flink的反压和Storm有哪些不同？" class="headerlink" title="13. Flink的反压和Storm有哪些不同？"></a><strong>13. Flink的反压和Storm有哪些不同？</strong></h3><p>​      Storm 是通过监控 Bolt 中的接收队列负载情况，如果超过高水位值就会将反压信息写到 Zookeeper ，Zookeeper 上的 watch 会通知该拓扑的所有 Worker 都进入反压状态，最后 Spout 停止发送 tuple。</p><p>​      Flink中的反压使用了高效有界的分布式阻塞队列，下游消费变慢会导致发送端阻塞。</p><p>​      二者最大的区别是Flink是逐级反压，而Storm是直接从源头降速。</p><h3 id="14-Operator-Chains（算子链）这个概念你了解吗？"><a href="#14-Operator-Chains（算子链）这个概念你了解吗？" class="headerlink" title="14. Operator Chains（算子链）这个概念你了解吗？"></a><strong>14. Operator Chains（算子链）这个概念你了解吗？</strong></h3><p>​      为了更高效地分布式执行，Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。将operators链接成task是非常有效的优化：它能减少线程之间的切换，减少消息的序列化/反序列化，减少数据在缓冲区的交换，减少了延迟的同时提高整体的吞吐量。这就是我们所说的算子链。</p><h3 id="15-Flink什么情况下才会把Operator-chain在一起形成算子链？"><a href="#15-Flink什么情况下才会把Operator-chain在一起形成算子链？" class="headerlink" title="15. Flink什么情况下才会把Operator chain在一起形成算子链？"></a><strong>15. Flink什么情况下才会把Operator chain在一起形成算子链？</strong></h3><p>​    两个operator chain在一起的的条件：</p><ul><li><p>上下游的并行度一致</p></li><li><p>下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）</p></li><li><p>上下游节点都在同一个 slot group 中（下面会解释 slot group）</p></li><li><p>下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）</p></li><li><p>上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）</p></li><li><p>两个节点间数据分区方式是 forward（参考理解数据流的分区）</p></li><li><p>用户没有禁用 chain</p></li></ul><h3 id="16-说说Flink1-9的新特性？"><a href="#16-说说Flink1-9的新特性？" class="headerlink" title="16. 说说Flink1.9的新特性？"></a><strong>16. 说说Flink1.9的新特性？</strong></h3><ul><li><p>支持hive读写，支持UDF</p></li><li><p>Flink SQL TopN和GroupBy等优化</p></li><li><p>Checkpoint跟savepoint针对实际业务场景做了优化</p></li><li><p>Flink state查询</p></li></ul><h3 id="17-消费kafka数据的时候，如何处理脏数据？"><a href="#17-消费kafka数据的时候，如何处理脏数据？" class="headerlink" title="17. 消费kafka数据的时候，如何处理脏数据？"></a><strong>17. 消费kafka数据的时候，如何处理脏数据？</strong></h3><p>   可以在处理前加一个fliter算子，将不符合规则的数据过滤出去。</p><h2 id="第三部分：Flink-面试源码篇"><a href="#第三部分：Flink-面试源码篇" class="headerlink" title="第三部分：Flink 面试源码篇"></a><strong>第三部分：Flink 面试源码篇</strong></h2><h3 id="1-Flink-Job的提交流程"><a href="#1-Flink-Job的提交流程" class="headerlink" title="1. Flink Job的提交流程"></a><strong>1. Flink Job的提交流程</strong></h3><p>​       用户提交的Flink Job会被转化成一个DAG任务运行，分别是：StreamGraph、JobGraph、ExecutionGraph，Flink中JobManager与TaskManager，JobManager与Client的交互是基于Akka工具包的，是通过消息驱动。整个Flink Job的提交还包含着ActorSystem的创建，JobManager的启动，TaskManager的启动和注册。</p><h3 id="2-Flink所谓”三层图”结构是哪几个”图”？"><a href="#2-Flink所谓”三层图”结构是哪几个”图”？" class="headerlink" title="2. Flink所谓”三层图”结构是哪几个”图”？"></a><strong>2. Flink所谓”三层图”结构是哪几个”图”？</strong></h3><blockquote><p>一个Flink任务的DAG生成计算图大致经历以下三个过程：</p><ul><li><p>StreamGraph<br>最接近代码所表达的逻辑层面的计算拓扑结构，按照用户代码的执行顺序向StreamExecutionEnvironment添加StreamTransformation构成流式图。</p></li><li><p>JobGraph<br>从StreamGraph生成，将可以串联合并的节点进行合并，设置节点之间的边，安排资源共享slot槽位和放置相关联的节点，上传任务所需的文件，设置检查点配置等。相当于经过部分初始化和优化处理的任务图。</p></li><li><p>ExecutionGraph<br>由JobGraph转换而来，包含了任务具体执行所需的内容，是最贴近底层实现的执行图。</p></li></ul></blockquote><h3 id="3-JobManger在集群中扮演了什么角色？"><a href="#3-JobManger在集群中扮演了什么角色？" class="headerlink" title="3. JobManger在集群中扮演了什么角色？"></a><strong>3. JobManger在集群中扮演了什么角色？</strong></h3><p>​      JobManager 负责整个 Flink 集群任务的调度以及资源的管理，从客户端中获取提交的应用，然后根据集群中 TaskManager 上 TaskSlot 的使用情况，为提交的应用分配相应的 TaskSlot 资源并命令 TaskManager 启动从客户端中获取的应用。</p><p>​     JobManager 相当于整个集群的 Master 节点，且整个集群有且只有一个活跃的 JobManager ，负责整个集群的任务管理和资源管理。</p><p>​     JobManager 和 TaskManager 之间通过 Actor System 进行通信，获取任务执行的情况并通过 Actor System 将应用的任务执行情况发送给客户端。</p><p>​    同时在任务执行的过程中，Flink JobManager 会触发 Checkpoint 操作，每个 TaskManager 节点 收到 Checkpoint 触发指令后，完成 Checkpoint 操作，所有的 Checkpoint 协调过程都是在 Fink JobManager 中完成。</p><p>​     当任务完成后，Flink 会将任务执行的信息反馈给客户端，并且释放掉 TaskManager 中的资源以供下一次提交任务使用。</p><h3 id="4-JobManger在集群启动过程中起到什么作用？"><a href="#4-JobManger在集群启动过程中起到什么作用？" class="headerlink" title="4. JobManger在集群启动过程中起到什么作用？"></a><strong>4. JobManger在集群启动过程中起到什么作用？</strong></h3><p>​     JobManager的职责主要是接收Flink作业，调度Task，收集作业状态和管理TaskManager。它包含一个Actor，并且做如下操作：</p><ul><li><p>RegisterTaskManager: 它由想要注册到JobManager的TaskManager发送。注册成功会通过AcknowledgeRegistration消息进行Ack。</p></li><li><p>SubmitJob: 由提交作业到系统的Client发送。提交的信息是JobGraph形式的作业描述信息。</p></li><li><p>CancelJob: 请求取消指定id的作业。成功会返回CancellationSuccess，否则返回CancellationFailure。</p></li><li><p>UpdateTaskExecutionState: 由TaskManager发送，用来更新执行节点(ExecutionVertex)的状态。成功则返回true，否则返回false。</p></li><li><p>RequestNextInputSplit: TaskManager上的Task请求下一个输入split，成功则返回NextInputSplit，否则返回null。</p></li><li><p>JobStatusChanged： 它意味着作业的状态(RUNNING, CANCELING, FINISHED,等)发生变化。这个消息由ExecutionGraph发送。</p></li></ul><h3 id="5-TaskManager在集群中扮演了什么角色？"><a href="#5-TaskManager在集群中扮演了什么角色？" class="headerlink" title="5. TaskManager在集群中扮演了什么角色？"></a><strong>5. TaskManager在集群中扮演了什么角色？</strong></h3><p>​     TaskManager 相当于整个集群的 Slave 节点，负责具体的任务执行和对应任务在每个节点上的资源申请和管理。</p><p>​    客户端通过将编写好的 Flink 应用编译打包，提交到 JobManager，然后 JobManager 会根据已注册在 JobManager 中 TaskManager 的资源情况，将任务分配给有资源的 TaskManager节点，然后启动并运行任务。</p><p>​     TaskManager 从 JobManager 接收需要部署的任务，然后使用 Slot 资源启动 Task，建立数据接入的网络连接，接收数据并开始数据处理。同时 TaskManager 之间的数据交互都是通过数据流的方式进行的。</p><p>​      可以看出，Flink 的任务运行其实是采用多线程的方式，这和 MapReduce 多 JVM 进行的方式有很大的区别，Flink 能够极大提高 CPU 使用效率，在多个任务和 Task 之间通过 TaskSlot 方式共享系统资源，每个 TaskManager 中通过管理多个 TaskSlot 资源池进行对资源进行有效管理。</p><h3 id="6-TaskManager在集群启动过程中起到什么作用？"><a href="#6-TaskManager在集群启动过程中起到什么作用？" class="headerlink" title="6. TaskManager在集群启动过程中起到什么作用？"></a><strong>6. TaskManager在集群启动过程中起到什么作用？</strong></h3><p>​     TaskManager的启动流程较为简单：启动类：org.apache.flink.runtime.taskmanager.TaskManager核心启动方法 ： selectNetworkInterfaceAndRunTaskManager启动后直接向JobManager注册自己，注册完成后，进行部分模块的初始化。</p><h3 id="7-Flink-计算资源的调度是如何实现的？"><a href="#7-Flink-计算资源的调度是如何实现的？" class="headerlink" title="7. Flink 计算资源的调度是如何实现的？"></a><strong>7. Flink 计算资源的调度是如何实现的？</strong></h3><p>​     TaskManager中最细粒度的资源是Task slot，代表了一个固定大小的资源子集，每个TaskManager会将其所占有的资源平分给它的slot。</p><p>​     通过调整 task slot 的数量，用户可以定义task之间是如何相互隔离的。每个 TaskManager 有一个slot，也就意味着每个task运行在独立的 JVM 中。每个 TaskManager 有多个slot的话，也就是说多个task运行在同一个JVM中。</p><p>​      而在同一个JVM进程中的task，可以共享TCP连接（基于多路复用）和心跳消息，可以减少数据的网络传输，也能共享一些数据结构，一定程度上减少了每个task的消耗。每个slot可以接受单个task，也可以接受多个连续task组成的pipeline，如下图所示，FlatMap函数占用一个taskslot，而key Agg函数和sink函数共用一个taskslot：</p><p><img src="https://pic2.zhimg.com/80/v2-00e4b6d488ca209d7b02580ece13a905_1440w.jpg" alt="img"></p><h3 id="8-简述Flink的数据抽象及数据交换过程？"><a href="#8-简述Flink的数据抽象及数据交换过程？" class="headerlink" title="8. 简述Flink的数据抽象及数据交换过程？"></a><strong>8. 简述Flink的数据抽象及数据交换过程？</strong></h3><p>​        Flink 为了避免JVM的固有缺陷例如java对象存储密度低，FGC影响吞吐和响应等，实现了自主管理内存。MemorySegment就是Flink的内存抽象。默认情况下，一个MemorySegment可以被看做是一个32kb大的内存块的抽象。这块内存既可以是JVM里的一个byte[]，也可以是堆外内存（DirectByteBuffer）。</p><p>​        在MemorySegment这个抽象之上，Flink在数据从operator内的数据对象在向TaskManager上转移，预备被发给下个节点的过程中，使用的抽象或者说内存对象是Buffer。</p><p>​        对接从Java对象转为Buffer的中间对象是另一个抽象StreamRecord。</p><h3 id="9-Flink-中的分布式快照机制是如何实现的？"><a href="#9-Flink-中的分布式快照机制是如何实现的？" class="headerlink" title="9. Flink 中的分布式快照机制是如何实现的？"></a><strong>9. Flink 中的分布式快照机制是如何实现的？</strong></h3><p>​        Flink的容错机制的核心部分是制作分布式数据流和操作算子状态的一致性快照。 这些快照充当一致性checkpoint，系统可以在发生故障时回滚。 Flink用于制作这些快照的机制在“分布式数据流的轻量级异步快照”中进行了描述。 它受到分布式快照的标准Chandy-Lamport算法的启发，专门针对Flink的执行模型而定制。</p><p><img src="https://pic3.zhimg.com/80/v2-897c8116fc9c17b50068810949311d52_1440w.jpg" alt="img"></p><p>​       barriers在数据流源处被注入并行数据流中。快照n的barriers被插入的位置（我们称之为Sn）是快照所包含的数据在数据源中最大位置。例如，在Apache Kafka中，此位置将是分区中最后一条记录的偏移量。 将该位置Sn报告给checkpoint协调器（Flink的JobManager）。</p><p>​       然后barriers向下游流动。当一个中间操作算子从其所有输入流中收到快照n的barriers时，它会为快照n发出barriers进入其所有输出流中。 一旦sink操作算子（流式DAG的末端）从其所有输入流接收到barriers n，它就向checkpoint协调器确认快照n完成。在所有sink确认快照后，意味快照着已完成。</p><p>​        一旦完成快照n，job将永远不再向数据源请求Sn之前的记录，因为此时这些记录（及其后续记录）将已经通过整个数据流拓扑，也即是已经被处理结束。</p><h3 id="10-简单说说FlinkSQL的是如何实现的？"><a href="#10-简单说说FlinkSQL的是如何实现的？" class="headerlink" title="10. 简单说说FlinkSQL的是如何实现的？"></a><strong>10. 简单说说FlinkSQL的是如何实现的？</strong></h3><p>​        Flink 将 SQL 校验、SQL 解析以及 SQL 优化交给了Apache Calcite。Calcite 在其他很多开源项目里也都应用到了，譬如 Apache Hive, Apache Drill, Apache Kylin, Cascading。Calcite 在新的架构中处于核心的地位，如下图所示。</p><p><img src="https://pic2.zhimg.com/80/v2-6f52103fd8b0bbd77e3c35f9cdbf4df9_1440w.jpg" alt="img"></p><p>构建抽象语法树的事情交给了 Calcite 去做。SQL query 会经过 Calcite 解析器转变成 SQL 节点树，通过验证后构建成 Calcite 的抽象语法树（也就是图中的 Logical Plan）。另一边，Table API 上的调用会构建成 Table API 的抽象语法树，并通过 Calcite 提供的 RelBuilder 转变成 Calcite 的抽象语法树。然后依次被转换成逻辑执行计划和物理执行计划。</p><p>在提交任务后会分发到各个 TaskManager 中运行，在运行时会使用 Janino 编译器编译代码后运行。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;第一部分：Flink-面试基础篇&quot;&gt;&lt;a href=&quot;#第一部分：Flink-面试基础篇&quot; class=&quot;headerlink&quot; title=&quot;第一部分：Flink 面试基础篇&quot;&gt;&lt;/a&gt;&lt;strong&gt;第一部分：Flink 面试基础篇&lt;/strong&gt;&lt;/h2&gt;
      
    
    </summary>
    
    
      <category term="Flink" scheme="https://dataquaner.github.io/categories/Flink/"/>
    
    
      <category term="Flink" scheme="https://dataquaner.github.io/tags/Flink/"/>
    
      <category term="面试必备" scheme="https://dataquaner.github.io/tags/%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87/"/>
    
  </entry>
  
  <entry>
    <title>机器学习系列之决策树算法（03）：决策树的剪枝</title>
    <link href="https://dataquaner.github.io/2020/04/11/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-03-jue-ce-shu-de-jian-zhi/"/>
    <id>https://dataquaner.github.io/2020/04/11/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-03-jue-ce-shu-de-jian-zhi/</id>
    <published>2020-04-11T11:32:09.079Z</published>
    <updated>2020-04-11T11:32:09.079Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><p>上一篇文章介绍了决策树的生成详细过程，由于决策树生成算法过多地考虑如何提高对训练数据的正确分类，从而构建过于复杂的决策树，这样产生的决策树往往对训练数据的分类很准确，却对未知的测试数据的分类没有那么准确，即出现<strong>过拟合现象</strong>。我们需要对已生成的决策树进行简化，这个简化的过程我们称之为<strong>剪枝(pruning)。</strong></p><p>具体就是剪掉一些不重要的子树或叶结点，并将其根结点或父结点作为新的叶结点，从而简化分类树模型，得到最优的决策树模型。保证模型对预测数据的泛化能力。</p><blockquote><p>决策树的剪枝往往通过<strong>极小化</strong>决策树整体的<strong>损失函数(loss funtion)</strong>或<strong>代价函数(cost funtion)</strong>来实现。</p></blockquote><h1 id="2-剪枝算法"><a href="#2-剪枝算法" class="headerlink" title="2.剪枝算法"></a>2.剪枝算法</h1><h2 id="2-1-为什么要剪枝"><a href="#2-1-为什么要剪枝" class="headerlink" title="2.1 为什么要剪枝"></a>2.1 为什么要剪枝</h2><p><strong>现象</strong></p><p>接上一次讲的生成决策树，下面给出一张图。</p><img src="https://pic2.zhimg.com/80/v2-d6588457cc144c1bad2f87ec77081af1_hd.jpg" alt="决策树学习中的过渡拟合" style="zoom:50%;"><ul><li>横轴表示在决策树创建过程中树的结点总数，纵轴表示决策树的预测精度。</li><li>实线显示的是决策树在训练集上的精度，虚线显示的则是在一个独立的测试集上测量出来的精度。</li></ul><p><strong>可以看出随着树的增长， 在训练样集上的精度是单调上升的， 然而在独立的测试样例上测出的精度先上升后下降。</strong></p><p><strong>原因</strong></p><p><img src="https://pic2.zhimg.com/80/v2-677a5e08d5b55b3b4cb14f7ad6f8eb31_hd.jpg" alt="原因"></p><ul><li>原因1：噪声、样本冲突，即错误的样本数据。</li><li>原因2：特征即属性不能完全作为分类标准。</li><li>原因3：巧合的规律性，数据量不够大。</li></ul><p>这个时候，就需要对生成树进行修剪，也就是<strong>剪枝</strong>。</p><h2 id="2-2-如何进行剪枝"><a href="#2-2-如何进行剪枝" class="headerlink" title="2.2 如何进行剪枝"></a>2.2 如何进行剪枝</h2><h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a><strong>预剪枝</strong></h3><p>预剪枝就是在完全正确分类训练集之前，较早地停止树的生长。 具体在什么时候停止决策树的生长有多种不同的方法:<br>        (1) 一种最为简单的方法就是在决策树到达一定高度的情况下就停止树的生长。<br>        (2) 到达此结点的实例具有相同的特征向量，而不必一定属于同一类， 也可停止生长。<br>        (3) 到达此结点的实例个数小于某一个阈值也可停止树的生长。</p><p>(4) 还有一种更为普遍的做法是计算每次扩张对系统性能的增益，如果这个增益值小于某个阈值则不进行扩展。</p><p><strong>优点&amp;缺点</strong></p><ul><li><p>由于预剪枝不必生成整棵决策树，且算法相对简单， 效率很高， 适合解决大规模问题。但是尽管这一方法看起来很直接， 但是【<strong>怎样精确地估计何时停止树的增长是相当困难的</strong>】。</p></li><li><p>预剪枝有一个缺点， 即视野效果问题 。 也就是说在相同的标准下，也许当前的扩展会造成过度拟合训练数据，但是更进一步的扩展能够满足要求，也有可能准确地拟合训练数据。这将使得算法过早地停止决策树的构造。</p></li></ul><h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a><strong>后剪枝</strong></h3><p>后剪枝，在已生成过拟合决策树上进行剪枝，可以得到简化版的剪枝决策树。</p><p>这里主要介绍四种：</p><ul><li>REP-错误率降低剪枝</li><li>PEP-悲观剪枝</li><li>CCP-代价复杂度剪枝</li><li>MEP-最小错误剪枝</li></ul><h4 id="REP-Reduced-Error-Pruning-方法"><a href="#REP-Reduced-Error-Pruning-方法" class="headerlink" title="REP(Reduced Error Pruning)方法"></a><strong>REP(Reduced Error Pruning)方法</strong></h4><blockquote><p>对于决策树T 的每棵非叶子树S , 用叶子替代这棵子树. 如果 S 被叶子替代后形成的新树关于D 的误差等于或小于S 关于 D 所产生的误差, 则用叶子替代子树S</p></blockquote><p><img src="https://pic2.zhimg.com/80/v2-ff11945f2e5a8319d82ab53c363ef441_hd.jpg" alt="img"></p><p><strong>优点：</strong></p><ul><li>REP 是当前最简单的事后剪枝方法之一。</li><li>它的计算复杂性是线性的。</li><li>和原始决策树相比，修剪后的决策树对未来新事例的预测偏差较小。</li></ul><p><strong>缺点：</strong></p><ul><li>但在数据量较少的情况下很少应用. REP方法趋于过拟合( overfitting) , 这是因为训练数据集中存在的特性在剪枝过程中都被忽略了, 当剪枝数据集比训练数据集小得多时 , 这个问题特别值得注意.</li></ul><h4 id="PEP-Pessimistic-Error-Pruning-方法"><a href="#PEP-Pessimistic-Error-Pruning-方法" class="headerlink" title="PEP(Pessimistic Error Pruning)方法"></a><strong>PEP(Pessimistic Error Pruning)方法</strong></h4><blockquote><p>为了克服 R EP 方法需要独立剪枝数据集的缺点而提出的, 它不需要分离的剪枝数据集，为了提高对未来事例的预测可靠性, <strong>PEP 方法对误差估计增加了连续性校正(continuity correction)</strong>。关于PEP方法的数据解释待后续开专题梳理。</p></blockquote><p><strong>优点：</strong></p><ul><li>PEP方法被认为是当前决策树事后剪枝方法中精度较高的算法之一</li><li>PEP 方法不需要分离的剪枝数据集, 这对于事例较少的问题非常有利</li><li>它的计算时间复杂性也只和未剪枝树的非叶节点数目成线性关系 .</li></ul><p><strong>缺点：</strong></p><p>PEP是唯一使用自顶向下剪枝策略的事后剪枝方法, 这种策略会带来与事前剪枝方法出现的同样问题, 那就是树的某个节点会在该节点的子孙根据同样准则不需要剪裁时也会被剪裁。</p><p><strong>TIPS：</strong></p><p>个人认为，其实以时间复杂度和空间复杂度为代价，PEP是可以自下而上的，这并不是必然的。</p><h4 id="MEP-Minimum-Error-Pruning-方法"><a href="#MEP-Minimum-Error-Pruning-方法" class="headerlink" title="MEP(Minimum Error Pruning)方法"></a><strong>MEP(Minimum Error Pruning)方法</strong></h4><blockquote><p>MEP 方法的基本思路是采用自底向上的方式, 对于树中每个非叶节点, 首先计算该节点的误差 Er(t) . 然后, 计算该节点每个分枝的误差Er(Tt) , 并且加权相加, 权为每个分枝拥有的训练样本比例. 如果 Er(t) 大于 Er(Tt) , 则保留该子树; 否则, 剪裁它。</p></blockquote><p><strong>优点：</strong></p><ul><li>MEP方法不需要独立的剪枝数据集, 无论是初始版本, 还是改进版本, 在剪枝过程中, 使用的信息都来自于训练样本集.</li><li>它的计算时间复杂性也只和未剪枝树的非叶节点数目成线性关系 .</li></ul><p><strong>缺点：</strong></p><p>类别平均分配的前提假设现实几率不大&amp;对K太过敏感</p><p><img src="https://pic3.zhimg.com/80/v2-5e7deee0ee978be2eec60328192affc6_hd.jpg" alt="img"></p><p>对此，也有改进算法，我没有深入研究。</p><p><img src="https://pic1.zhimg.com/80/v2-3ffc529242dbb52dcb4946e37fed92f0_hd.jpg" alt="img"></p><h4 id="CCP-Cost-Complexity-Pruning-方法"><a href="#CCP-Cost-Complexity-Pruning-方法" class="headerlink" title="CCP(Cost-Complexity Pruning)方法"></a><strong>CCP(Cost-Complexity Pruning)方法</strong></h4><blockquote><p>CCP 方法就是著名的CART(Classificationand Regression Trees)剪枝算法，它包含两个步骤:<br>                (1) 自底向上，通过对原始决策树中的修剪得到一系列的树 {T0,T1,T2,…,Tt}， 其中Tia 是由Ti中的一个或多个子树被替换所得到的，T0为未经任何修剪的原始树，几为只有一个结点的树。</p><p>​        (2) 评价这些树，根据真实误差率来选择一个最优秀的树作为最后被剪枝的树。</p></blockquote><p><strong>缺点：</strong></p><p>生成子树序列 T ( α) 所需要的时间和原决策树非叶节点的关系是二次的, 这就意味着如果非叶节点的数目随着训练例子记录数目线性增加, 则CCP方法的运行时间和训练数据记录数的关系也是二次的 . 这就比本文中将要介绍的其它剪枝方法所需要的时间长得多, 因为其它剪枝方法的运行时间和非叶节点的关系是线性的.</p><p><strong>对比四种方法</strong></p><table><thead><tr><th><strong>剪枝名称</strong></th><th><strong>剪枝方式</strong></th><th><strong>计算复杂度</strong></th><th><strong>误差估计</strong></th></tr></thead><tbody><tr><td>REP</td><td>自底向上</td><td>0(n)</td><td>剪枝集上误差估计</td></tr><tr><td>PEP</td><td>自顶向下</td><td>o(n)</td><td>使用连续纠正</td></tr><tr><td>CCP</td><td>自底向上</td><td>o(n2)</td><td>标准误差</td></tr><tr><td>MEP</td><td>自底向上</td><td>o(n)</td><td>使用连续纠正</td></tr></tbody></table><p>① MEP比PEP不准确，且树大。两者都不需要额外数据集，故当数据集小的时候可以用。对比公式，如果类（Label）多，则用MEP；PEP在数据集uncertain时错误多，不使用。</p><p>② REP最简单且精度高，但需要额外数据集；CCP精度和REP差不多，但树小。</p><p>③ 如果数据集多（REP&amp;CCP←复杂但树小）</p><p>④ 如果数据集小（MEP←不准确树大&amp;PEP←不稳定）</p><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h1><p>决策树是机器学习算法中比较容易受影响的，从而导致过拟合，有效的剪枝能够减少过拟合发生的概率。</p><p>剪枝主要分为两种：预剪枝(early stopping)，后剪枝，一般说剪枝都是指后剪枝，预剪枝一般叫做early stopping，后剪枝决策树在数学上更加严谨，得到的树至少是和early stopping得到的一样好。</p><p><strong>预剪枝：</strong></p><p>预剪枝的核心思想是在对每一个节点划分之前先进行计算，如果当前节点的划分并不能够带来模型泛化能力的提升就不再进行划分，对于未能够区分的样本种类（此时可能存在不同的样本类别同时存在于节点中），按照投票（少数服从多数）的原则进行判断。</p><p>简单一点的方法可以通过测试集判断划分过后的测试集准确度能否得到提升进行确定，如果准确率不提升变不再进行节点划分。</p><p>这样做的好处是在降低过拟合风险的同时减少了训练时间的开销，但是可能会出现欠拟合的风险：虽然一次划分可能会导致准确率的降低，但是再进行几次划分后，可能会使得准确率显著提升。</p><p><strong>后剪枝：</strong></p><p>后剪枝的核心思想是让算法生成一个完全决策树，然后从最低层向上计算决定是否剪枝。</p><p>同样的，方法可以通过在测试集上的准确率进行判断，如果剪枝后准确率有所提升，则进行剪枝。</p><p>后剪枝的泛化能力往往高于预剪枝，但是时间花销相对较大。</p><p><strong>剪枝方法的选择</strong></p><p>如果不在乎计算量的问题，后剪枝策略一般更加常用，更加有效。</p><p>后剪枝中REP和CCP通常需要训练集和额外的验证集，计算量更大。</p><p>有研究表明，通常reduced error pruning是效果最好的，但是也不会比其他的好太多。</p><p>经验表明，限制节点的最小样本个数对防止过拟合很重要，输的最大depth的设置往往要依赖于问题的复杂度，另外树的叶节点总个数和最大depth是相关的，所以有些设置只会要求指定其中一个参数。</p><p>无论是预剪枝还是后剪枝都是为了减少决策树过拟合的情况，在实际运用中，我使用了python中的sklearn库中的函数。</p><p>函数中的max_depth参数可以控制树的最大深度，即最多产生几层节点</p><p>函数中的min_samples_split参数可以控制最小划分样本，即当节点样本数大于阈值时才进行下一步划分。</p><p>函数中min_samples_leaf参数可以控制最后的叶子中最小的样本数量，即最后的分类中的样本需要高于阈值</p><p>上述几个参数的设置均可以从控制过拟合的方面进行理解，通过控制树的层数、节点划分样本数量以及每一个分类的样本数可以在一定程度上减少对于样本个性的关注。具体设置需要根据实际情况进行设置</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      决策树
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="Decision Tree" scheme="https://dataquaner.github.io/tags/Decision-Tree/"/>
    
  </entry>
  
  <entry>
    <title>机器学习系列之决策树算法（02）：决策树的生成</title>
    <link href="https://dataquaner.github.io/2020/04/11/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-02-jue-ce-shu-de-sheng-cheng/"/>
    <id>https://dataquaner.github.io/2020/04/11/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-02-jue-ce-shu-de-sheng-cheng/</id>
    <published>2020-04-11T11:31:53.052Z</published>
    <updated>2020-04-11T11:31:53.052Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p>上文讲到决策树的特征选择会根据不同的算法选择不同的分裂参考指标，例如信息增益、信息增益比和基尼指数，本文完整分析记录决策树的详细生成过程和剪枝处理。</p><h2 id="2-决策树的生成"><a href="#2-决策树的生成" class="headerlink" title="2. 决策树的生成"></a>2. 决策树的生成</h2><p> <strong>示例数据表格</strong></p><p>    文章所使用的数据集如下，来源于《数据分析实战45讲》17讲中</p><p><img src="https://pic3.zhimg.com/80/v2-393024075528471f43f52891d29320be_hd.jpg" alt="img"></p><h3 id="2-1-相关概念阐述"><a href="#2-1-相关概念阐述" class="headerlink" title="2.1 相关概念阐述"></a><strong>2.1 相关概念阐述</strong></h3><h4 id="2-1-1-决策树"><a href="#2-1-1-决策树" class="headerlink" title="2.1.1 决策树"></a><strong>2.1.1 决策树</strong></h4><p> 以上面的表格数据为例，比如我们考虑要不要去打篮球，先看天气是不是阴天，是阴天的话，外面刮风没，没刮风我们就去，刮风就不去。决策树就是把上面我们判断背后的逻辑整理成一个结构图，也就是一个树状结构。</p><h4 id="2-1-2-ID3、C4-5、CART"><a href="#2-1-2-ID3、C4-5、CART" class="headerlink" title="2.1.2 ID3、C4.5、CART"></a><strong>2.1.2 ID3、C4.5、CART</strong></h4><p>在决策树构造中有三个著名算法：ID3、C4.5、CART，ID3算法计算的是信息增益，C4.5计算使用的是增益率、CART计算使用的是基尼系数，关于这部分内容可以参考上文【<a href="https://dataquaner.github.io/2019/12/17/机器学习系列之决策树算法（01）：决策树特征选择/">机器学习系列之决策树算法（01）：决策树特征选择</a>】下面简单介绍下其算法，这里也不要求完全看懂，扫一眼有个印象就行，在后面的例子中有计算示例，回过头结合看应该就懂了。</p><h5 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a><strong>信息熵</strong></h5><p> 在信息论中，随机离散事件的出现的概率存在不确定性，为了衡量这种信息的不确定性，信息学之父香农引入了信息熵的概念，并给出了计算信息熵的数学公式。</p><p>​                                                            Entopy(t)=-Σp(i|t)log2p(i|t)</p><h5 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a><strong>信息增益</strong></h5><p>信息增益指的是划分可以带来纯度的提高，信息熵的下降。特征的信息熵越大代表特征的不确定性越大，代表得知了该特征后，数据集的信息熵会下降更多，即信息增益越大。它的计算公式是父亲节点的信息熵减去所有子节点的信息熵。信息增益的公式可以表示为：</p><p>​                                        Gain(D,a)=Entropy(D)- Σ|Di|/|D|Entropy(Di)</p><h5 id="信息增益率"><a href="#信息增益率" class="headerlink" title="信息增益率"></a><strong>信息增益率</strong></h5><p> 信息增益率 = 信息增益 / 属性熵。属性熵，就是每种属性的信息熵，比如天气的属性熵的计算如下,天气有晴阴雨,各占3/7,2/7,2/7：</p><p>​                H(天气)= -(3/7 * log2(3/7) + 2/7 * log2(2/7) + 2/7 * log2(2/7))</p><h5 id="基尼系数"><a href="#基尼系数" class="headerlink" title="基尼系数"></a><strong>基尼系数</strong></h5><p> 基尼系数在经济学中用来衡量一个国家收入差距的常用指标.当基尼指数大于0.4的时候,说明财富差异悬殊.基尼系数在0.2-0.4之间说明分配合理,财富差距不大.扩展阅读下<a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0">基尼系数</a></p><p> 基尼系数本身反应了样本的不确定度.当基尼系数越小的时候,说明样本之间的差异性小,不确定程度低.</p><p> CART算法在构造分类树的时候,会选择基尼系数最小的属性作为属性的划分.</p><p> 基尼系数的计算公式如下:</p><p>​                            Gini = 1 – Σ (Pi)2 for i=1 to number of classes</p><h3 id="2-2-完整生成过程"><a href="#2-2-完整生成过程" class="headerlink" title="2.2 完整生成过程"></a><strong>2.2 完整生成过程</strong></h3><p> 下面是一个完整的决策树的构造生成过程，已完整开头所给的数据为例</p><h4 id="2-2-1-根节点的选择"><a href="#2-2-1-根节点的选择" class="headerlink" title="2.2.1 根节点的选择"></a><strong>2.2.1 根节点的选择</strong></h4><p> 在上面的列表中有四个属性:天气,温度,湿度,刮风.需要先计算出这四个属性的信息增益、信息增益率、基尼系数</p><p> 数据集中有7条数据，3个打篮球，4个不打篮球，不打篮球的概率为4/7,打篮球的概率为3/7,则根据信息熵的计算公式可以得到根节点的信息熵为：</p><p>​                        Ent(D)=-(4/7 * log2(4/7) + 3/7 * log2(3/7))=0.985</p><h5 id="天气"><a href="#天气" class="headerlink" title="天气"></a><strong>天气</strong></h5><p>    其数据表格如下:</p><p><img src="https://pic2.zhimg.com/80/v2-4977ea2a875ea67cb75588eb04b6aee5_hd.jpg" alt="img"></p><h6 id="信息增益计算"><a href="#信息增益计算" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>如果将天气作为属性划分，分别会有三个叶节点：晴天、阴天、小雨，其中晴天2个不打篮球，1个打篮球；阴天1个打篮球，1个不打篮球；小雨1个打篮球，1个不打篮球，其对应相应的信息熵如下：</p><p>D(晴天)=-(1/3 * log2(1/3) + 2/3 * log2(2/3)) = 0.981</p><p>D(阴天)=-(1/2 * log2(1/2) + 1/2 * log2(1/2)) = 1.0</p><p>D(雨天)=-(1/2 * log2(1/2) + 1/2 * log2(1/2)) = 1.0</p><p>在数据集中晴天有3条数据，阴天有2条数据，雨天有2条数据，对应的概率为3/7、2/7、2/7，那么作为子节点的归一化信息熵为：</p><p>3/7 * 0.918 + 2/7 * 1.0 * 2/7 * 1.0 = 0.965</p><p>其信息增益为：</p><p>Gain(天气)=0.985 - 0.965 = 0.020</p><h6 id="信息增益率计算"><a href="#信息增益率计算" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p> 天气有三个选择，晴天有3条数据，阴天有2条数据，雨天有2条数据，对应的概率为3/7、2/7、2/7，其对应的属性熵为：</p><p>H(天气)=-(3/7 * log2(3/7) + 2/7 * log2(2/7) + 2/7 * log2(2/7)) = 1.556</p><p> 则其信息增益率为：</p><p>Gain_ratio(天气)=0.020/1.556=0.012</p><h6 id="基尼系数计算"><a href="#基尼系数计算" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(天气=晴)=1 - (1/3)^2 - (2/3)^2 = 1 - 1/9 - 4/9 = 4/9</li><li>Gini(天气=阴)=1 - (1/2)^2 - (1/2)^2 = 1 - 1/4 - 1/4 = 0.5</li><li>Gini(天气=小雨)=1 - (1/2)^2 - (1/2)^2 = 1 - 1/4 - 1/4 = 0.5</li><li>Gini(天气)=(3/7) * 4/9 + (2/7) * 0.5 + (2/7) * 0.5 = 4/21 + 1/7 + 1/7 = 10/21</li></ul><h5 id="温度"><a href="#温度" class="headerlink" title="温度"></a><strong>温度</strong></h5><p>  其数据表格如下:</p><p><img src="https://pic3.zhimg.com/80/v2-74ad946b56a27f3bc480ba07f31552de_hd.jpg" alt="img"></p><h6 id="信息增益计算-1"><a href="#信息增益计算-1" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    各情况的信息熵如下：</p><p>D(高)=-(2/4 * log2(2/4) + 2/4 * log2(2/4)) = 1.0</p><p>D(中)=-(1/2 * log2(1/2) + 1/2 * log2(1/2)) = 1.0</p><p>D(低)=-(0/1 * log2(0/1) + 1/1 * log2(1/1)) = 0.0</p><p>    作为子节点的归一化信息熵为：</p><p>4/7 * 1.0 + 2/7 * 1.0 * 1/7 * 0.0 = 0.857</p><p>    其信息增益为：</p><p>Gain(温度)=0.985 - 0.857 = 0.128</p><h6 id="信息增益率计算-1"><a href="#信息增益率计算-1" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    属性熵为：</p><p>H(温度)=-(4/7 * log2(4/7) + 2/7 * log2(2/7) + 1/7 * log2(1/7)) = 1.378</p><p>    则其信息增益率为：</p><p>Gain_ratio(温度)=0.128/1.378=0.0928</p><h6 id="基尼系数计算-1"><a href="#基尼系数计算-1" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(温度=高)=1 - (2/4)^2 - (2/4)^2 = 1 - 1/4 - 1/4 = 0.5</li><li>Gini(温度=中)=1 - (1/2)^2 - (1/2)^2 = 1 - 1/4 - 1/4 = 0.5</li><li>Gini(温度=低)=1 - (0/1)^2 - (1/1)^2 = 1 - 0 - 1 = 0</li><li>Gini(温度)=4/7 * 0.5 + 2/7 * 0.5 + 1/7 * 0 = 3/7</li></ul><h5 id="湿度"><a href="#湿度" class="headerlink" title="湿度"></a><strong>湿度</strong></h5><p>    其数据表格如下:</p><p><img src="https://pic1.zhimg.com/80/v2-423f80f054a8d86eed652afff6a6c914_hd.jpg" alt="img"></p><h6 id="信息增益计算-2"><a href="#信息增益计算-2" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    各情况的信息熵如下：</p><p>D(高)=-(2/4 * log2(2/4) + 2/4 * log2(2/4)) = 1.0</p><p>D(中)=-(2/3 * log2(2/3) + 1/3 * log2(1/3)) = 0.918</p><p>    作为子节点的归一化信息熵为：</p><p>4/7 * 1.0 + 3/7 * 0.918 = 0.964</p><p>    其信息增益为：</p><p>Gain(湿度)=0.985 - 0.964 = 0.021</p><h6 id="信息增益率计算-2"><a href="#信息增益率计算-2" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    属性熵为：</p><p>H(湿度)=-(4/7 * log2(4/7) + 3/7 * log2(3/7) = 0.985</p><p>    则其信息增益率为：</p><p>Gain_ratio(湿度)=0.021/0.985=0.021</p><h6 id="基尼系数计算-2"><a href="#基尼系数计算-2" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(湿度=高)=1 - (2/4)^2 - (2/4)^2 = 1 - 1/4 - 1/4 = 0.5</li><li>Gini(湿度=中)=1 - (2/3)^2 - (1/3)^2 = 1 - 4/9 - 1/9 = 4/9</li><li>Gini(湿度)=(4/7) * 0.5 + (3/7) * 4/9 = 2/7 + 4/21 = 10/21 ~ 0.47619</li></ul><h6 id="刮风"><a href="#刮风" class="headerlink" title="刮风"></a><strong>刮风</strong></h6><p>    其数据表格如下:</p><p><img src="https://pic2.zhimg.com/80/v2-edb75f5790519fcee2dd6317f4d5557d_hd.jpg" alt="img"></p><h6 id="信息增益计算-3"><a href="#信息增益计算-3" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    各情况的信息熵如下：</p><p>D(是)=-(2/3 * log2(2/3) + 1/3 * log2(1/3)) = 0.918</p><p>D(否)=-(2/4 * log2(2/4) + 2/4 * log2(2/4)) = 1.0</p><p>    作为子节点的归一化信息熵为：</p><p>3/7 * 1.0 + 4/7 * 0.918 = 0.964</p><p>    其信息增益为：</p><p>Gain(刮风)=0.985 - 0.964 = 0.021</p><h6 id="信息增益率计算-3"><a href="#信息增益率计算-3" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    属性熵为：</p><p>H(刮风)=-(4/7 * log2(4/7) + 3/7 * log2(3/7) = 0.985</p><p>    则其信息增益率为：</p><p>Gain_ratio(刮风)=0.021/0.985=0.021</p><h6 id="基尼系数计算-3"><a href="#基尼系数计算-3" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(刮风=是)=1 - (2/3)^2 - (1/3)^2 = 1 - 4/9 - 1/9 = 4/9</li><li>Gini(刮风=否)=1 - (2/4)^2 - (2/4)^2 = 1 - 1/4 - 1/4 = 0.5</li><li>Gini(刮风)=(4/7) * 0.5 + (3/7) * 4/9 = 2/7 + 4/21 = 10/21 ~ 0.47619</li></ul><h5 id="根节点的选择"><a href="#根节点的选择" class="headerlink" title="根节点的选择"></a><strong>根节点的选择</strong></h5><p>  如下汇总所有接口,第一个为信息增益的，第二个为信息增益率的，第三个为基尼系数的。其中信息增益和信息增益率选择最大的，基尼系数选择最小的。从下面的结果可以得到选择为：温度</p><p><strong>信息增益</strong></p><ul><li><p>Gain(天气)=0.985 - 0.965 = 0.020</p></li><li><p>Gain(温度)=0.985 - 0.857 = 0.128</p></li><li><p>Gain(湿度)=0.985 - 0.964 = 0.021</p></li><li><p>Gain(刮风)=0.985 - 0.964 = 0.021</p></li></ul><p><strong>信息增益率</strong></p><ul><li>Gain_ratio(天气)=0.020/1.556=0.012</li><li>Gain_ratio(温度)=0.128/1.378=0.0928</li><li>Gain_ratio(湿度)=0.021/0.985=0.021</li><li>Gain_ratio(刮风)=0.021/0.985=0.021</li></ul><p><strong>基尼系数</strong></p><ul><li>Gini(天气)=(3/7) * 4/9 + (2/7) * 0.5 + (2/7) * 0.5 = 0.47619</li><li>Gini(温度)=4/7 * 0.5 + 2/7 * 0.5 + 1/7 * 0 = 0.42857</li><li>Gini(湿度)=(4/7) * 0.5 + (3/7) * 4/9 = 2/7 + 4/21 = 10/21 ~ 0.47619</li><li>Gini(刮风)=(4/7) * 0.5 + (3/7) * 4/9 = 2/7 + 4/21 = 10/21 ~ 0.47619</li></ul><p>确定根节点以后,大致的树结构如下，温度低能确定结果，高和中需要进一步的进行分裂，从剩下的数据中再次进行属性选择:</p><ul><li>根节点<ul><li>子节点温度高:(待进一步进行选择)</li><li>子节点温度中:(待进一步进行选择)</li><li>叶节点温度低:不打篮球(能直接确定为不打篮球)</li></ul></li></ul><h4 id="2-2-2-子节点温度高的选择"><a href="#2-2-2-子节点温度高的选择" class="headerlink" title="2.2.2 子节点温度高的选择"></a><strong>2.2.2 子节点温度高的选择</strong></h4><p>    其剩下的数据集如下,温度不再进行下面的节点选择参与:</p><p><img src="https://pic1.zhimg.com/80/v2-86c2e574fc2309e9dff98e8205c0dff4_hd.jpg" alt="img"></p><p>    根据信息熵的计算公式可以得到子节点温度高的信息熵为：</p><p>​                                                Ent(D)=-(2/4 * log2(2/4) + 2/4 * log2(2/4)) = 1.0</p><h5 id="天气-1"><a href="#天气-1" class="headerlink" title="天气"></a><strong>天气</strong></h5><p>    其数据表格如下:</p><p><img src="https://pic2.zhimg.com/80/v2-72771013ffea869ed0ce76c7f8998f79_hd.jpg" alt="img"></p><h6 id="信息增益计算-4"><a href="#信息增益计算-4" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    相应的信息熵如下：</p><p>D(晴天)=-(1/2 * log2(1/2) + 1/2 * log2(1/2)) = 1.0</p><p>D(阴天)=-(1/1 * log2(1/1) + 0/1 * log2(0/1)) = 0.0</p><p>D(雨天)=-(1/1 * log2(1/1) + 0/1 * log2(0/1)) = 0.0</p><p>    归一化信息熵为：</p><p>2/4 * 1.0 + 1/4 * 0.0 * 1/4 * 0.0 = 0.5</p><p>    其信息增益为：</p><p>Gain(天气)=1.0 - 0.5 = 0.5</p><h6 id="信息增益率计算-4"><a href="#信息增益率计算-4" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    对应的属性熵为：</p><p>H(天气)=-(2/4 * log2(2/4) + 1/4 * log2(1/4) + 1/4 * log2(1/4)) = 1.5</p><p>    则其信息增益率为：</p><p>Gain_ratio(天气)=0.5/1.5=0.33333</p><h6 id="基尼系数计算-4"><a href="#基尼系数计算-4" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(天气=晴)=1 - (1/2)^2 - (1/2)^2 = 1 - 1/4 - 1/4 = 0.5</li><li>Gini(天气=阴)=1 - (1/1)^2 - (0/1)^2 = 0</li><li>Gini(天气=小雨)=1 - (1/1)^2 - (0/1)^2 = 0</li><li>Gini(天气)=2/4 * 0.5 + 1/4 * 0 + 1/4 * 0 = 0.25</li></ul><h5 id="湿度-1"><a href="#湿度-1" class="headerlink" title="湿度"></a><strong>湿度</strong></h5><p>    其数据表格如下:</p><p><img src="https://pic3.zhimg.com/80/v2-ea98c22052cf1246618f266c52be998e_hd.jpg" alt="img"></p><h6 id="信息增益计算-5"><a href="#信息增益计算-5" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    各情况的信息熵如下：</p><p>D(高)=-(2/2 * log2(2/2) + 0/2 * log2(0/2)) = 0.0</p><p>D(中)=-(0/2 * log2(0/2) + 2/2 * log2(2/2)) = 0.0</p><p>    作为子节点的归一化信息熵为：</p><p>2/4 * 0.0 + 2/4 * 0.0 = 0.0</p><p>    其信息增益为：</p><p>Gain(湿度)=1.0 - 0.0 = 1.0</p><h6 id="信息增益率计算-5"><a href="#信息增益率计算-5" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    属性熵为：</p><p>H(湿度)=-(2/4 * log2(2/4) + 2/4 * log2(2/4) = 1.0</p><p>    则其信息增益率为：</p><p>Gain_ratio(湿度)=1.0/1.0=1.0</p><h6 id="基尼系数计算-5"><a href="#基尼系数计算-5" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(湿度=高)=1 - (2/2)^2 - (0/2)^2 = 0</li><li>Gini(湿度=中)=1 - (0/2)^2 - (2/2)^2 = 0</li><li>Gini(湿度)=(2/4) * 0 + (2/4) * 0 = 0</li></ul><h5 id="刮风-1"><a href="#刮风-1" class="headerlink" title="刮风"></a><strong>刮风</strong></h5><p>    其数据表格如下:</p><p><img src="https://pic3.zhimg.com/80/v2-ba94b90f801904bae450796e8a5db0be_hd.jpg" alt="img"></p><h6 id="信息增益计算-6"><a href="#信息增益计算-6" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    各情况的信息熵如下：</p><p>D(是)=-(0/1 * log2(0/1) + 1/1 * log2(1/1)) = 0</p><p>D(否)=-(2/3 * log2(2/3) + 1/3 * log2(1/3)) = 0.918</p><p>    作为子节点的归一化信息熵为：</p><p>1/4 * 0.0 + 3/4 * 0.918 = 0.688</p><p>    其信息增益为：</p><p>Gain(刮风)=1.0 - 0.688 = 0.312</p><h6 id="信息增益率计算-6"><a href="#信息增益率计算-6" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    属性熵为：</p><p>H(刮风)=-(1/3 * log2(1/3) + 2/3 * log2(2/3) = 0.918</p><p>    则其信息增益率为：</p><p>Gain_ratio(刮风)=0.312/0.918=0.349</p><h6 id="基尼系数计算-6"><a href="#基尼系数计算-6" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li><p>Gini(刮风=是)=1 - (0/1)^2 - (1/1)^2 = 0</p></li><li><p>Gini(刮风=否)=1 - (2/3)^2 - (1/3)^2 = 1 - 4/9 - 1/9 = 4/9</p></li><li><p>Gini(刮风)=(1/4) * 0 + (3/4) * 4/9 = 1/3 = 0.333333</p></li></ul><p><strong>子节点温度高的选择</strong></p><p>    如下汇总所有接口,第一个为信息增益的，第二个为信息增益率的，第三个为基尼系数的。其中信息增益和信息增益率选择最大的，基尼系数选择最小的。从下面的结果可以得到选择为：湿度</p><ul><li>Gain(天气)=1.0 - 0.5 = 0.5</li><li>Gain(湿度)=1.0 - 0.0 = 1.0</li><li>Gain(刮风)=1.0 - 0.688 = 0.312</li><li>Gain_ratio(天气)=0.5/1.5=0.33333</li><li>Gain_ratio(湿度)=1.0/1.0=1.0</li><li>Gain_ratio(刮风)=0.312/0.918=0.349</li><li>Gini(天气)=2/4 * 0.5 + 1/4 * 0 + 1/4 * 0 = 0.25</li><li>Gini(湿度)=(2/4) * 0 + (2/4) * 0 = 0</li><li>Gini(刮风)=(1/4) * 0 + (3/4) * 4/9 = 1/3 = 0.333333</li></ul><p>    确定跟节点以后,大致的树结构如下，选择湿度作为分裂属性后能直接确定结果:</p><ul><li>根节点<ul><li>子节点温度高<ul><li>叶节点湿度高：打篮球</li><li>叶节点湿度中：不打篮球</li></ul></li><li>子节点温度中:(待进一步进行选择)<ul><li>叶节点温度低:不打篮球(能直接确定为不打篮球)</li></ul></li></ul></li></ul><h4 id="2-2-3-子节点温度中的选择"><a href="#2-2-3-子节点温度中的选择" class="headerlink" title="2.2.3 子节点温度中的选择"></a><strong>2.2.3 子节点温度中的选择</strong></h4><p>    其剩下的数据集如下,温度不再进行下面的节点选择参与:</p><p><img src="https://pic1.zhimg.com/80/v2-3f1b0c5e060288599f90c428441aaabc_hd.jpg" alt="img"></p><p>    根据信息熵的计算公式可以得到子节点温度高的信息熵为：</p><p>Ent(D)=-(1/2 * log2(1/2) + 1/2 * log2(1/2)) = 1.0</p><h5 id="天气-2"><a href="#天气-2" class="headerlink" title="天气"></a><strong>天气</strong></h5><p>    其数据表格如下:</p><p><img src="https://pic4.zhimg.com/80/v2-7ac9cd99fc8388c6c3f34fdb2e132b57_hd.jpg" alt="img"></p><h6 id="信息增益计算-7"><a href="#信息增益计算-7" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    相应的信息熵如下：</p><p>D(晴天)=-(1/1 * log2(1/1) + 0/1 * log2(0/1)) = 0.0 D</p><p>(阴天)=-(0/1 * log2(0/1) + 1/1 * log2(1/1)) = 0.0</p><p>    归一化信息熵为：</p><p>1/2 * 0.0 + 1/2 * 0.0 = 0</p><p>    其信息增益为：</p><p>Gain(天气)=1.0 - 0 = 1.0</p><h6 id="信息增益率计算-7"><a href="#信息增益率计算-7" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    对应的属性熵为：</p><p>H(天气)=-(1/2 * log2(1/2) + 1/2 * log2(1/2)) = 1.0</p><p>    则其信息增益率为：</p><p>Gain_ratio(天气)=1.0/1.0=1.0</p><h6 id="基尼系数计算-7"><a href="#基尼系数计算-7" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(天气=晴)=1 - (1/1)^2 - (0/1)^2 = 0</li><li>Gini(天气=阴)=1 - (0/1)^2 - (1/1)^2 = 0</li><li>Gini(天气)=1/2 * 0.0 + 1/2 * 0.0 = 0</li></ul><h5 id="湿度-2"><a href="#湿度-2" class="headerlink" title="湿度"></a><strong>湿度</strong></h5><p>    其数据表格如下:</p><p><img src="https://pic3.zhimg.com/80/v2-a27cfcdbbde0c07ab39cbdac34b8e6da_hd.jpg" alt="img"></p><h6 id="信息增益计算-8"><a href="#信息增益计算-8" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    各情况的信息熵如下：</p><p>D(高)=-(0/1 * log2(0/1) + 1/1 * log2(1/1)) = 0.0</p><p>D(中)=-(1/1 * log2(1/1) + 0/1 * log2(0/1)) = 0.0</p><p>    作为子节点的归一化信息熵为：</p><p>1/2 * 0.0 + 1/2 * 0.0 = 0</p><p>    其信息增益为：</p><p>Gain(湿度)=1.0 - 0.0 = 1.0</p><h6 id="信息增益率计算-8"><a href="#信息增益率计算-8" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    属性熵为：</p><p>H(湿度)=-(1/2 * log2(1/2) + 1/2 * log2(1/2)) = 1.0</p><p>    则其信息增益率为：</p><p>Gain_ratio(湿度)=1.0/1.0=1.0</p><h6 id="基尼系数计算-8"><a href="#基尼系数计算-8" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(湿度=高)=1 - (0/1)^2 - (1/1)^2 = 0</li><li>Gini(湿度=中)=1 - (1/1)^2 - (0/1)^2 = 0</li><li>Gini(湿度)=1/2 * 0.0 + 1/2 * 0.0 = 0</li></ul><h5 id="刮风-2"><a href="#刮风-2" class="headerlink" title="刮风"></a><strong>刮风</strong></h5><p>    其数据表格如下:</p><p><img src="https://pic2.zhimg.com/80/v2-887ebcf7eecd07ee13ca02d024a3b321_hd.jpg" alt="img"></p><h6 id="信息增益计算-9"><a href="#信息增益计算-9" class="headerlink" title="信息增益计算"></a><strong>信息增益计算</strong></h6><p>    各情况的信息熵如下：</p><p>D(是)=-(1/2 * log2(1/2) + 1/2 * log2(1/2)) = 1.0</p><p>    作为子节点的归一化信息熵为：</p><p>1/1 * 1.0 = 1.0</p><p>    其信息增益为：</p><p>Gain(刮风)=1.0 - 1.0 = 0</p><h6 id="信息增益率计算-9"><a href="#信息增益率计算-9" class="headerlink" title="信息增益率计算"></a><strong>信息增益率计算</strong></h6><p>    属性熵为：</p><p>H(刮风)=-(2/2 * log2(2/2) = 0.0</p><p>    则其信息增益率为：</p><p>Gain_ratio(刮风)=0/0 = 0</p><h6 id="基尼系数计算-9"><a href="#基尼系数计算-9" class="headerlink" title="基尼系数计算"></a><strong>基尼系数计算</strong></h6><ul><li>Gini(刮风=是)=1 - (1/2)^2 - (1/2)^2 = 0.5</li><li>Gini(刮风)=2/2 * 0.5 = 0.5</li></ul><p><strong>子节点温度中的选择</strong></p><p>如下汇总所有接口,第一个为信息增益的，第二个为信息增益率的，第三个为基尼系数的。其中信息增益和信息增益率选择最大的，基尼系数选择最小的。从下面的结果可以得到天气和湿度是一样好的，我们随机选天气吧</p><ul><li>Gain(天气)=1.0 - 0 = 1.0</li><li>Gain(湿度)=1.0 - 0.0 = 1.0</li><li>Gain(刮风)=1.0 - 1.0 = 0</li><li>Gain_ratio(天气)=1.0/1.0=1.0</li><li>Gain_ratio(湿度)=1.0/1.0=1.0</li><li>Gain_ratio(刮风)=0/0 = 0</li><li>Gini(天气)=1/2 * 0.0 + 1/2 * 0.0 = 0</li><li>Gini(湿度)=1/2 * 0.0 + 1/2 * 0.0 = 0</li><li>Gini(刮风)=2/2 * 0.5 = 0.5</li></ul><p>    确定跟节点以后,大致的树结构如下，选择天气作为分裂属性后能直接确定结果:</p><ul><li>根节点<ul><li>子节点温度高<ul><li>叶节点湿度高：打篮球</li><li>叶节点湿度中：不打篮球</li></ul></li><li>子节点温度中<ul><li>叶节点天气晴：打篮球</li><li>叶节点天气阴：不打篮球</li><li>叶节点温度低:不打篮球(能直接确定为不打篮球)</li></ul></li></ul></li></ul><h4 id="2-2-4-最终的决策树"><a href="#2-2-4-最终的决策树" class="headerlink" title="2.2.4 最终的决策树"></a><strong>2.2.4 最终的决策树</strong></h4><p>    在上面的步骤已经进行完整的演示，得到当前数据一个完整的决策树：</p><ul><li>根节点<ul><li>子节点温度高<ul><li>叶节点湿度高：打篮球</li><li>叶节点湿度中：不打篮球</li></ul></li><li>子节点温度中<ul><li>叶节点天气晴：打篮球</li><li>叶节点天气阴：不打篮球</li><li>叶节点温度低:不打篮球(能直接确定为不打篮球)</li></ul></li></ul></li></ul><h2 id="3-思考"><a href="#3-思考" class="headerlink" title="3. 思考"></a><strong>3. 思考</strong></h2><p> 在构造的过程中我们可以发现，有可能同一个属性在同一级会被选中两次，比如上面的决策树中子节点温度高中都能选中温度作为分裂属性，这样是否合理？</p><p> 完整的构造整个决策树后，发现整个决策树的高度大于等于属性数量，感觉决策树应该是构造时间较长，但用于决策的时候很快，时间复杂度也就是O(n)</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      决策树
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="Decision Tree" scheme="https://dataquaner.github.io/tags/Decision-Tree/"/>
    
  </entry>
  
  <entry>
    <title>数据存储之MySQL系列（01）：MySQL体系结构</title>
    <link href="https://dataquaner.github.io/2020/04/11/shu-ju-cun-chu-zhi-mysql-xi-lie-01-mysql-ti-xi-jie-gou/"/>
    <id>https://dataquaner.github.io/2020/04/11/shu-ju-cun-chu-zhi-mysql-xi-lie-01-mysql-ti-xi-jie-gou/</id>
    <published>2020-04-11T11:31:10.255Z</published>
    <updated>2020-04-11T11:31:10.255Z</updated>
    
    <content type="html"><![CDATA[<script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      MySQL
    
    </summary>
    
    
      <category term="DataBase" scheme="https://dataquaner.github.io/categories/DataBase/"/>
    
    
      <category term="MySQL" scheme="https://dataquaner.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>xgboost算法模型输出的解释</title>
    <link href="https://dataquaner.github.io/2020/04/11/xgboost-suan-mo-xing-shu-chu-de-jie-shi/"/>
    <id>https://dataquaner.github.io/2020/04/11/xgboost-suan-mo-xing-shu-chu-de-jie-shi/</id>
    <published>2020-04-11T11:30:52.923Z</published>
    <updated>2020-04-11T11:30:52.923Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h2><p> 近来, 在python环境下使用xgboost算法作若干的机器学习任务, 在这个过程中也使用了其内置的函数来可视化树的结果, 但对leaf value的值一知半解; 同时, 也遇到过使用xgboost 内置的predict 对测试集进行打分预测, 发现若干样本集的输出分值是一样的. 这个问题该怎么解释呢? 通过翻阅Stack Overflow 上的相关问题, 以及搜索到的github上的issue回答, 应该算初步对这个问题有了一定的理解。</p><h2 id="2-数据集"><a href="#2-数据集" class="headerlink" title="2. 数据集"></a>2. 数据集</h2><p> 在这里, 使用经典的鸢尾花的数据来说明. 使用二分类的问题来说明, 故在这里只取前100行的数据.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasetsiris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>data <span class="token operator">=</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token keyword">print</span> data<span class="token punctuation">.</span>shape<span class="token comment" spellcheck="true">#(100L, 4L)</span><span class="token comment" spellcheck="true">#一共有100个样本数据, 维度为4维</span>label <span class="token operator">=</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token keyword">print</span> label<span class="token comment" spellcheck="true">#正好选取label为0和1的数据</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-训练集与测试集"><a href="#3-训练集与测试集" class="headerlink" title="3. 训练集与测试集"></a>3. 训练集与测试集</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cross_validation <span class="token keyword">import</span> train_test_splittrain_x<span class="token punctuation">,</span> test_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="4-Xgboost建模"><a href="#4-Xgboost建模" class="headerlink" title="4. Xgboost建模"></a>4. Xgboost建模</h2><h3 id="4-1-模型初始化设置"><a href="#4-1-模型初始化设置" class="headerlink" title="4.1 模型初始化设置"></a>4.1 模型初始化设置</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgbdtrain<span class="token operator">=</span>xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span>label<span class="token operator">=</span>train_y<span class="token punctuation">)</span>dtest<span class="token operator">=</span>xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>params<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'booster'</span><span class="token punctuation">:</span><span class="token string">'gbtree'</span><span class="token punctuation">,</span>    <span class="token string">'objective'</span><span class="token punctuation">:</span> <span class="token string">'binary:logistic'</span><span class="token punctuation">,</span>    <span class="token string">'eval_metric'</span><span class="token punctuation">:</span> <span class="token string">'auc'</span><span class="token punctuation">,</span>    <span class="token string">'max_depth'</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span>    <span class="token string">'lambda'</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">,</span>    <span class="token string">'subsample'</span><span class="token punctuation">:</span><span class="token number">0.75</span><span class="token punctuation">,</span>    <span class="token string">'colsample_bytree'</span><span class="token punctuation">:</span><span class="token number">0.75</span><span class="token punctuation">,</span>    <span class="token string">'min_child_weight'</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span>    <span class="token string">'eta'</span><span class="token punctuation">:</span> <span class="token number">0.025</span><span class="token punctuation">,</span>    <span class="token string">'seed'</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span>    <span class="token string">'nthread'</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">,</span>     <span class="token string">'silent'</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">}</span>watchlist <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>dtrain<span class="token punctuation">,</span><span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-建模与预测"><a href="#4-2-建模与预测" class="headerlink" title="4.2 建模与预测"></a>4.2 建模与预测</h3><pre class="line-numbers language-python"><code class="language-python">bst<span class="token operator">=</span>xgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>params<span class="token punctuation">,</span>dtrain<span class="token punctuation">,</span>num_boost_round<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>evals<span class="token operator">=</span>watchlist<span class="token punctuation">)</span>ypred<span class="token operator">=</span>bst<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>dtest<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 设置阈值, 输出一些评价指标</span>y_pred <span class="token operator">=</span> <span class="token punctuation">(</span>ypred <span class="token operator">>=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">1</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics<span class="token keyword">print</span> <span class="token string">'AUC: %.4f'</span> <span class="token operator">%</span> metrics<span class="token punctuation">.</span>roc_auc_score<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span>ypred<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token string">'ACC: %.4f'</span> <span class="token operator">%</span> metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token string">'Recall: %.4f'</span> <span class="token operator">%</span> metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token string">'F1-score: %.4f'</span> <span class="token operator">%</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token string">'Precesion: %.4f'</span> <span class="token operator">%</span>metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span>metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Out[23]:</p><pre class="line-numbers language-python"><code class="language-python">AUC<span class="token punctuation">:</span> <span class="token number">1.0000</span>ACC<span class="token punctuation">:</span> <span class="token number">1.0000</span>Recall<span class="token punctuation">:</span> <span class="token number">1.0000</span>F1<span class="token operator">-</span>score<span class="token punctuation">:</span> <span class="token number">1.0000</span>Precesion<span class="token punctuation">:</span> <span class="token number">1.0000</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int64<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Yeah, 完美的模型, 完美的预测!</p><h3 id="4-3-可视化输出"><a href="#4-3-可视化输出" class="headerlink" title="4.3 可视化输出"></a>4.3 可视化输出</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#对于预测的输出有三种方式</span>?bst<span class="token punctuation">.</span>predictSignature<span class="token punctuation">:</span> bst<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">,</span> output_margin<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ntree_limit<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> pred_leaf<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> pred_contribs<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> approx_contribs<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>pred_leaf <span class="token punctuation">:</span> bool    When this option <span class="token keyword">is</span> on<span class="token punctuation">,</span> the output will be a matrix of <span class="token punctuation">(</span>nsample<span class="token punctuation">,</span> ntrees<span class="token punctuation">)</span>    <span class="token keyword">with</span> each record indicating the predicted leaf index of each sample <span class="token keyword">in</span> each tree<span class="token punctuation">.</span>    Note that the leaf index of a tree <span class="token keyword">is</span> unique per tree<span class="token punctuation">,</span> so you may find leaf <span class="token number">1</span>    <span class="token keyword">in</span> both tree <span class="token number">1</span> <span class="token operator">and</span> tree <span class="token number">0</span><span class="token punctuation">.</span>pred_contribs <span class="token punctuation">:</span> bool    When this option <span class="token keyword">is</span> on<span class="token punctuation">,</span> the output will be a matrix of <span class="token punctuation">(</span>nsample<span class="token punctuation">,</span> nfeats<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> each record indicating the feature contributions <span class="token punctuation">(</span>SHAP values<span class="token punctuation">)</span> <span class="token keyword">for</span> that    prediction<span class="token punctuation">.</span> The sum of all feature contributions <span class="token keyword">is</span> equal to the prediction<span class="token punctuation">.</span>    Note that the bias <span class="token keyword">is</span> added <span class="token keyword">as</span> the final column<span class="token punctuation">,</span> on top of the regular features<span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-3-1-得分"><a href="#4-3-1-得分" class="headerlink" title="4.3.1 得分"></a>4.3.1 得分</h4><p>默认的输出就是得分, 这没什么好说的, 直接上code.</p><pre class="line-numbers language-python"><code class="language-python">ypred <span class="token operator">=</span> bst<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>dtest<span class="token punctuation">)</span>ypred<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Out[32]:</p><pre class="line-numbers language-python"><code class="language-python">array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>        <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>        <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>        <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>        <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">,</span>  <span class="token number">0.80391562</span><span class="token punctuation">,</span>  <span class="token number">0.20081411</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这里, 就可以观察到文章最开始遇到的问题: 为什么得分几乎都是一样的值? 先不急, 看看另外两种输出.</p><h4 id="4-3-2-所属的叶子节点"><a href="#4-3-2-所属的叶子节点" class="headerlink" title="4.3.2 所属的叶子节点"></a>4.3.2 所属的叶子节点</h4><p>当设置<code>pred_leaf=True</code>的时候, 这时就会输出每个样本在所有树中的叶子节点</p><pre class="line-numbers language-python"><code class="language-python">ypred_leaf <span class="token operator">=</span> bst<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>dtest<span class="token punctuation">,</span> pred_leaf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>ypred_leaf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Out[33]:</p><pre class="line-numbers language-python"><code class="language-python">array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出的维度为[样本数, 树的数量], 树的数量默认是100, 所以<code>ypred_leaf</code>的维度为<code>[100*100]</code>.</p><p>对于第一行数据的解释就是, 在xgboost所有的100棵树里, 预测的叶子节点都是1(相对于每颗树).</p><p>那怎么看每颗树以及相应的叶子节点的分值呢?这里有两种方法, 可视化树或者直接输出模型.</p><pre class="line-numbers language-python"><code class="language-python">xgb<span class="token punctuation">.</span>to_graphviz<span class="token punctuation">(</span>bst<span class="token punctuation">,</span> num_trees<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#可视化第一棵树的生成情况</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://images2017.cnblogs.com/blog/957413/201710/957413-20171017204407818-1932629185.png" alt="img"></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#直接输出模型的迭代工程</span>bst<span class="token punctuation">.</span>dump_model<span class="token punctuation">(</span><span class="token string">"model.txt"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">booster<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">[</span>f3<span class="token operator">&lt;</span><span class="token number">0.75</span><span class="token punctuation">]</span> yes<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>no<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>missing<span class="token operator">=</span><span class="token number">1</span>    <span class="token number">1</span><span class="token punctuation">:</span>leaf<span class="token operator">=</span><span class="token operator">-</span><span class="token number">0.019697</span>    <span class="token number">2</span><span class="token punctuation">:</span>leaf<span class="token operator">=</span><span class="token number">0.0214286</span>booster<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">[</span>f2<span class="token operator">&lt;</span><span class="token number">2.35</span><span class="token punctuation">]</span> yes<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>no<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>missing<span class="token operator">=</span><span class="token number">1</span>    <span class="token number">1</span><span class="token punctuation">:</span>leaf<span class="token operator">=</span><span class="token operator">-</span><span class="token number">0.0212184</span>    <span class="token number">2</span><span class="token punctuation">:</span>leaf<span class="token operator">=</span><span class="token number">0.0212</span>booster<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">[</span>f2<span class="token operator">&lt;</span><span class="token number">2.35</span><span class="token punctuation">]</span> yes<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>no<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>missing<span class="token operator">=</span><span class="token number">1</span>    <span class="token number">1</span><span class="token punctuation">:</span>leaf<span class="token operator">=</span><span class="token operator">-</span><span class="token number">0.0197404</span>    <span class="token number">2</span><span class="token punctuation">:</span>leaf<span class="token operator">=</span><span class="token number">0.0197235</span>booster<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ……<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过上述命令就可以输出模型的迭代过程, 可以看到每颗树都有两个叶子节点(树比较简单). 然后我们对每颗树中的叶子节点1的value进行累加求和, 同时进行相应的函数转换, 就是第一个样本的预测值.</p><p>在这里, 以第一个样本为例, 可以看到, 该样本在所有树中都属于第一个叶子, 所以累加值, 得到以下值.</p><p>同样, 以第二个样本为例, 可以看到, 该样本在所有树中都属于第二个叶子, 所以累加值, 得到以下值.</p><pre class="line-numbers language-python"><code class="language-python">leaf1   <span class="token operator">-</span><span class="token number">1.381214</span>leaf2    <span class="token number">1.410950</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在使用xgboost模型最开始, 模型初始化的时候, 我们就设置了<code>'objective': 'binary:logistic'</code>, 因此使用函数将累加的值转换为实际的打分:</p><p>f(x)=1/(1+exp(−x))</p><pre class="line-numbers language-python"><code class="language-python"><span class="token number">1</span><span class="token operator">/</span>float<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token number">1.38121416</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Out<span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">0.20081407112186503</span><span class="token number">1</span><span class="token operator">/</span>float<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1.410950</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Out<span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">0.8039157403338895</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这就与<code>ypred = bst.predict(dtest)</code> 的分值相对应上了.</p><h4 id="4-3-2-特征重要性"><a href="#4-3-2-特征重要性" class="headerlink" title="4.3.2 特征重要性"></a>4.3.2 特征重要性</h4><p>接着, 我们看另一种输出方式, 输出的是特征相对于得分的重要性.</p><pre class="line-numbers language-python"><code class="language-python">ypred_contribs <span class="token operator">=</span> bst<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>dtest<span class="token punctuation">,</span> pred_contribs<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>ypred_contribs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Out[37]:</p><pre class="line-numbers language-python"><code class="language-python">array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0.96967536</span><span class="token punctuation">,</span>  <span class="token number">0.39522746</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.01448286</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.41277751</span><span class="token punctuation">,</span>  <span class="token number">0.04604663</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出的<code>ypred_contribs</code>的维度为<code>[100,5]</code>, 通过阅读前面的文档注释就可以知道, 最后一列是<code>bias</code>, 前面的四列分别是每个特征对最后打分的影响因子, 可以看出, 前面两个特征是不起作用的.</p><p>通过这个输出, 怎么和最后的打分进行关联呢? 原理也是一样的, 还是以前两列为例.</p><pre class="line-numbers language-python"><code class="language-python">score_a <span class="token operator">=</span> sum<span class="token punctuation">(</span>ypred_contribs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span> score_a<span class="token comment" spellcheck="true"># -1.38121373579</span>score_b <span class="token operator">=</span> sum<span class="token punctuation">(</span>ypred_contribs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span> score_b<span class="token comment" spellcheck="true"># 1.41094945744</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>相同的分值, 相同的处理情况.</p><p>到此, 这期关于在python上关于xgboost算法的简单实现, 以及在实现的过程中: 得分的输出、样本对应到树的节点、每个样本中单独特征对得分的影响, 以及上述三者之间的联系, 均已介绍完毕。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      xgboost算法模型输出的解释
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="XGBoost" scheme="https://dataquaner.github.io/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM算法基础系列之基础理论篇（1）</title>
    <link href="https://dataquaner.github.io/2020/04/11/lightgbm-suan-fa-ji-chu-xi-lie-zhi-ji-chu-li-lun-pian-1/"/>
    <id>https://dataquaner.github.io/2020/04/11/lightgbm-suan-fa-ji-chu-xi-lie-zhi-ji-chu-li-lun-pian-1/</id>
    <published>2020-04-11T11:30:37.965Z</published>
    <updated>2020-04-11T11:30:37.965Z</updated>
    
    <content type="html"><![CDATA[<p>这是lightgbm算法基础系列的第一篇，讲述lightgbm基础理论。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      LightGBM分类算法
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="LightGBM" scheme="https://dataquaner.github.io/tags/LightGBM/"/>
    
  </entry>
  
  <entry>
    <title>零基础自学人工智能路径规划，附资源，亲身经验</title>
    <link href="https://dataquaner.github.io/2020/04/11/ling-ji-chu-zi-xue-ren-gong-zhi-neng-lu-jing-gui-hua-fu-zi-yuan-qin-shen-jing-yan/"/>
    <id>https://dataquaner.github.io/2020/04/11/ling-ji-chu-zi-xue-ren-gong-zhi-neng-lu-jing-gui-hua-fu-zi-yuan-qin-shen-jing-yan/</id>
    <published>2020-04-11T01:25:00.000Z</published>
    <updated>2020-04-11T12:08:44.555Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h1><p>下面的每个资源都是我亲身学过的，且是网上公开公认最优质的资源。</p><p>下面的每个学习步骤也是我一步步走过来的。希望大家以我为参考，少走弯路。</p><p>请大家不要浪费时间找非常多的资料，只看最精华的！</p><p>综述，机器学习的自学简单来说分为三个步骤</p><p><strong>前期</strong>：知识储备包括数学知识，机器学习经典算法知识，编程技术（python）的掌握</p><p><strong>中期</strong>：算法的代码实现</p><p><strong>后期</strong>：实战水平提升</p><p><strong>机器学习路径规划图</strong></p><p><img src="https://pic2.zhimg.com/80/v2-513e28c795a43b69a0ae88d49d722205_hd.jpg" alt="img"></p><h1 id="1-数学基础"><a href="#1-数学基础" class="headerlink" title="1. 数学基础"></a><strong>1. 数学基础</strong></h1><p>很多人看到数学知识的时候就望而却步，数学是需要的，但是作为入门水平，对数学的要求没有那么的高。<strong><em>假设你上过大学的数学课（忘了也没事），需要的数学知识啃一啃还是基本能理解下来的。</em></strong></p><h2 id="1-1-数学内容"><a href="#1-1-数学内容" class="headerlink" title="1.1 数学内容"></a>1.1 数学内容</h2><p><strong>线性代数</strong>：矩阵/张量乘法、求逆，奇异值分解/特征值分解，行列式，范数等</p><p><strong>统计与概率</strong>：概率分布，独立性与贝叶斯，最大似然(MLE)和最大后验估计(MAP)等</p><p><strong>优化</strong>：线性优化，非线性优化(凸优化/非凸优化)以及其衍生的如梯度下降、牛顿法等</p><p><strong>微积分</strong>：偏微分，链式法则，矩阵求导等</p><p><strong>信息论</strong>、<strong>数值理论</strong>等</p><p>上面的看不太懂没事，不是特别难，学习一下就能理解了。</p><h2 id="1-2-数学资源"><a href="#1-2-数学资源" class="headerlink" title="1.2 数学资源"></a>1.2 数学资源</h2><p>网上有很多人会列举大量大量的课程资源，这是非常不负责任的事，学完那些我头发都得白了。<strong><em>实际上，我们只需要学习其中的一部分就够了。</em></strong></p><h3 id="1-2-1-吴恩达的斯坦福大学机器学习王牌课程CS229"><a href="#1-2-1-吴恩达的斯坦福大学机器学习王牌课程CS229" class="headerlink" title="1.2.1 吴恩达的斯坦福大学机器学习王牌课程CS229"></a>1.2.1 吴恩达的斯坦福大学机器学习王牌课程CS229</h3><p>课后就有对学生数学知识的要求和补充，这些数学知识是完全符合机器学习要求的，不多也不少。墙裂推荐要看，不过只有英文版的。</p><p>链接：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1NrCAW38C9lXFqPwqTlrVRA">https://pan.baidu.com/s/1NrCAW38C9lXFqPwqTlrVRA</a><br>密码：3k3m</p><h3 id="1-2-2-深度学习的三大开山鼻祖之一Yoshua-Bengio写的深度学习（包含了机器学习）领域的教科书"><a href="#1-2-2-深度学习的三大开山鼻祖之一Yoshua-Bengio写的深度学习（包含了机器学习）领域的教科书" class="headerlink" title="1.2.2 深度学习的三大开山鼻祖之一Yoshua Bengio写的深度学习（包含了机器学习）领域的教科书"></a>1.2.2 深度学习的三大开山鼻祖之一Yoshua Bengio写的深度学习（包含了机器学习）领域的教科书</h3><p>现在以开源的形式在网上公开。这部书被誉为深度学习的圣经。在这里我们只看这本书的第一部分，也就是数学基础。囊括了机器学习所需的所有必备数学基础，而且是从最基础的说起，也不多，必读的。</p><p>链接：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1GmmbqFewyCuEA7blXNC-7g">https://pan.baidu.com/s/1GmmbqFewyCuEA7blXNC-7g</a><br>密码：6qqm</p><h3 id="1-2-3-跟机器学习算法相结合的数学知识。上面两部分是理论层面的数学，机器学习算法中会对这些数学进行应用。"><a href="#1-2-3-跟机器学习算法相结合的数学知识。上面两部分是理论层面的数学，机器学习算法中会对这些数学进行应用。" class="headerlink" title="1.2.3 跟机器学习算法相结合的数学知识。上面两部分是理论层面的数学，机器学习算法中会对这些数学进行应用。"></a>1.2.3 跟机器学习算法相结合的数学知识。上面两部分是理论层面的数学，机器学习算法中会对这些数学进行应用。</h3><p>链接：<a href="https://zhuanlan.zhihu.com/p/25197792，知乎专栏上的一篇好文章，囊括了所有的应用知识点。" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25197792，知乎专栏上的一篇好文章，囊括了所有的应用知识点。</a></p><p>好了，数学方面我只推荐上面三个资源，三个都是必看的。里面很多可能你现在看不太懂，没关系。先大概过一遍，知道自己的数学水平在哪。在看到算法知识的时候，不懂的再回来补就好。后期需要更多的数学资料我会再更新的。</p><h1 id="2-编程技术"><a href="#2-编程技术" class="headerlink" title="2 编程技术"></a><strong>2 编程技术</strong></h1><p>编程语言：python3.5及以上，python易学，这个这期先不细讲。</p><h1 id="3-经典算法知识"><a href="#3-经典算法知识" class="headerlink" title="3 经典算法知识"></a><strong>3 经典算法知识</strong></h1><p>算法包括机器学习和深度学习，机器学习是深度学习的基础。所以务必先学机器学习的经典算法，再学深度学习的算法。</p><h2 id="3-1-机器学习"><a href="#3-1-机器学习" class="headerlink" title="3.1 机器学习"></a>3.1 机器学习</h2><h3 id="3-1-1-课程资料"><a href="#3-1-1-课程资料" class="headerlink" title="3.1.1 课程资料"></a>3.1.1 课程资料</h3><p>首推吴恩达的CS229，经典中的经典，在网易公开课里有视频，翻译，课程讲义，笔记是非常非常完备的。墙裂推荐。<strong><em>这个课程对数学有一定的要求</em></strong>，但我觉得只要你上过大学的数学，然后补一下上面的数学，完全可以直接来看这个CS229。</p><p>假设你的数学真的很差的话，怎么办？吴恩达在coursera上也开了一门跟CS229完全匹配的课程，coursera机器学习课。这门课是CS229的翻版，唯一不同的是它对数学基本是没有要求了，如果你对数学真的不懂的话，那就先看这个的教程吧。它跟CS229的关系就是同样的广度，但是深度浅很多，不过你学完coursera还是要回过头来看CS229的。这个也是免费的。</p><p>CS229课程视频：<a href="https://link.zhihu.com/?target=http%3A//open.163.com/special/opencourse/machinelearning.html">http://open.163.com/special/opencourse/machinelearning.html</a></p><p>课程讲义和中文笔记：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1MC_yWjcz_m5YoZFNBcsRSQ">https://pan.baidu.com/s/1MC_yWjcz_m5YoZFNBcsRSQ</a><br>密码：6rw6</p><h3 id="3-1-2-配套书籍："><a href="#3-1-2-配套书籍：" class="headerlink" title="3.1.2 配套书籍："></a>3.1.2 配套书籍：</h3><p>机器学习实战，必看。用代码实现了一遍各大经典机器学习算法，必须看，对你理解算法有很大帮助，同时里面也有应用。<strong><em>如果大家看上面纯理论的部分太枯燥了，就可以来看看这本书来知道在现实中机器学习算法是怎么应用的，会很大程度提升你的学习兴趣</em></strong>，当初我可是看了好几遍。</p><p>书籍及课后代码：链接：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/15XtFOH18si316076GLKYfg">https://pan.baidu.com/s/15XtFOH18si316076GLKYfg</a><br>密码：sawb</p><p>李航《统计学习方法》，配合着看</p><p>链接：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1Mk_O71k-H8GHeaivWbzM-Q">https://pan.baidu.com/s/1Mk_O71k-H8GHeaivWbzM-Q</a><br>密码：adep，配合着看</p><p>周志华《机器学习》，机器学习的百科全书，配合着看。</p><p>链接：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1lJoQnWToonvBU6cYwjrRKg">https://pan.baidu.com/s/1lJoQnWToonvBU6cYwjrRKg</a><br>密码：7rzl</p><h2 id="3-2-深度学习"><a href="#3-2-深度学习" class="headerlink" title="3.2 深度学习"></a>3.2 深度学习</h2><p>说到深度学习，我们不得不提斯坦福的另一门王牌课程CS231，李飞飞教授的。这门课的课程，课后习题，堪称完美。必须必须看。整个系列下来，特别是课后的习题要做，做完之后你会发现，哇哦！它的课后习题就是写代码来实现算法的。这个在网易云课堂上有。</p><p>视频地址：<a href="https://link.zhihu.com/?target=http%3A//study.163.com/course/introduction.htm%3FcourseId%3D1004697005">http://study.163.com/course/introduction.htm?courseId=1004697005</a></p><p>课程笔记翻译，知乎专栏：<a href="https://zhuanlan.zhihu.com/p/21930884" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21930884</a></p><p>墙裂建议要阅读这个知乎专栏，关于怎么学这门课，这个专栏写的很清楚。</p><p>课后作业配套答案：<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/bigdatadigest/article/category/7425092">https://blog.csdn.net/bigdatadigest/article/category/7425092</a></p><h2 id="3-3-学习时间"><a href="#3-3-学习时间" class="headerlink" title="3.3 学习时间"></a>3.3 学习时间</h2><p>到这里了，你的机器学习和深度学习算是入门了。学完上面这些，按一天6小时，一周六天的话，起码也得三个月吧。上面是基本功一定要认真学。但是，还找不了工作。因为你还没把这些知识应用到实际当中。</p><h2 id="3-4-实战部分"><a href="#3-4-实战部分" class="headerlink" title="3.4 实战部分"></a>3.4 实战部分</h2><h3 id="3-4-1-实战基础"><a href="#3-4-1-实战基础" class="headerlink" title="3.4.1 实战基础"></a>3.4.1 实战基础</h3><p>这一个阶段，你要开始用tensorflow（谷歌的深度学习框架）、scikit-learn（python的机器学习框架），这两个框架极大程度地集成了各大算法。其实上面在学习cs231n的时候你就会用到一部分。</p><p>scikit-learn的学习：<a href="https://link.zhihu.com/?target=http%3A//sklearn.apachecn.org/cn/0.19.0/">http://sklearn.apachecn.org/cn/0.19.0/</a></p><p>这是scikit-learn的官方文档中文版翻译，有理论有实战，最好的库学习资源，没有之一。认真看，传统的机器学习就是用这个库来实现的。</p><p>Tensorflow的学习：<a href="https://link.zhihu.com/?target=https%3A//tensorflow.google.cn/api_docs/python/%3Fhl%3Dzh-cn">https://tensorflow.google.cn/api_docs/python/?hl=zh-cn</a></p><p>官方文档很详尽，还有实战例子，学习tensorflow的不二之选</p><h3 id="3-4-2-实战进阶"><a href="#3-4-2-实战进阶" class="headerlink" title="3.4.2 实战进阶"></a>3.4.2 实战进阶</h3><p>仅仅看这两个教程是不够的，你需要更多地去应用这两个库。</p><p>接下来推荐一部神书，机器学习和深度学习的实战教学，非常非常的棒，网上有很多号称实战的书或者例子，我看了基本就是照搬官网的，只有这一本书，是完全按照工业界的流程解决方案进行实战，你不仅能学习到库的应用，还能深入了解工业界的流程解决方案，最好的实战教学书，没有之一。书名是hands-on-ml-with-sklearn-and-tf</p><p>链接：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1x318qTHGt9oZKQwHkoUvKA">https://pan.baidu.com/s/1x318qTHGt9oZKQwHkoUvKA</a><br>密码：xssj</p><h3 id="3-4-3-实战最终阶段"><a href="#3-4-3-实战最终阶段" class="headerlink" title="3.4.3 实战最终阶段"></a>3.4.3 实战最终阶段</h3><p>kaggle数据竞赛，如果你已经学到了这一步，恭喜你离梦想越来越近了：对于我们初学者来说，没有机会接触到机器学习真正的应用项目，所以一些比赛平台是我们不错的选择。参加kaggle竞赛可以给你的简历增分不少，里面有入门级别到专家级别的实战案例，满足你的各方面需求。如果你能学到这一步了，我相信也不需要再看这个了。</p><p><strong><em>上述所有资料的合集：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1tPqsSmSMZa6qLyD0ng87IQ">https://pan.baidu.com/s/1tPqsSmSMZa6qLyD0ng87IQ</a></em></strong><br><strong><em>密码：ve75</em></strong></p><p>补充：</p><p>学到这个水平，应该是能够实习的水平了，还有很多后面再说吧。比如深度学习和机器学习的就业方向，深度学习得看论文，找工作还得对你得编程基础进行加强，具体就是数据结构与算法，我当年在这个上面可是吃了很大的亏。</p><p>这里面关于深度学习和机器学习的就业其实是两个方向，上面的其实也没有说全。一般来说，你得选择一个方向专攻。我建议的是，自学的最好在后期侧重机器学习方向，而不是深度学习。深度学习的岗位实在是太少，要求太高。机器学习还算稍微好点。</p><p><strong>重点：上面的学习路径是主要框架，但是不意味着仅仅学习这些就够了。根据每个人基础的不同，你有可能需要另外的学习资料补充。但是，我希望大家可以按照上面的主框架走，先按上面我推荐的资源学，有需要的再去看别的（我之后也会推荐），上面的我能列出来的都是最经典的，最有效率，而且我亲身学过的。</strong></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0-前言&quot;&gt;&lt;a href=&quot;#0-前言&quot; class=&quot;headerlink&quot; title=&quot;0. 前言&quot;&gt;&lt;/a&gt;0. 前言&lt;/h1&gt;&lt;p&gt;下面的每个资源都是我亲身学过的，且是网上公开公认最优质的资源。&lt;/p&gt;
&lt;p&gt;下面的每个学习步骤也是我一步步走过来的。希
      
    
    </summary>
    
    
      <category term="LearnPath" scheme="https://dataquaner.github.io/categories/LearnPath/"/>
    
    
      <category term="LearnPath" scheme="https://dataquaner.github.io/tags/LearnPath/"/>
    
      <category term="AI" scheme="https://dataquaner.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>机器学习系列之决策树算法（10）：决策树模型，XGBoost，LightGBM和CatBoost模型可视化</title>
    <link href="https://dataquaner.github.io/2020/01/16/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-10-jue-ce-shu-mo-xing-xgboost-lightgbm-he-catboost-mo-xing-ke-shi-hua/"/>
    <id>https://dataquaner.github.io/2020/01/16/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-10-jue-ce-shu-mo-xing-xgboost-lightgbm-he-catboost-mo-xing-ke-shi-hua/</id>
    <published>2020-01-16T06:08:00.000Z</published>
    <updated>2020-04-11T11:34:10.409Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装-graphviz"><a href="#安装-graphviz" class="headerlink" title="安装 graphviz"></a>安装 graphviz</h2><ol><li><p>参考文档 <a href="http://graphviz.readthedocs.io/en/stable/manual.html#installation" target="_blank" rel="noopener">http://graphviz.readthedocs.io/en/stable/manual.html#installation</a></p></li><li><p>graphviz安装包下载地址 <a href="https://www.graphviz.org/download/" target="_blank" rel="noopener">https://www.graphviz.org/download/</a></p></li><li><p>将graphviz的安装位置添加到系统环境变量</p></li><li><p>使用pip install graphviz安装graphviz python包</p></li><li><p>使用pip install pydotplus安装pydotplus python包</p></li></ol><h2 id="决策树模型可视化"><a href="#决策树模型可视化" class="headerlink" title="决策树模型可视化"></a>决策树模型可视化</h2><p>   以iris数据为例。训练一个分类决策树，调用export_graphviz函数导出DOT格式的文件。并用pydotplus包绘制图片。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#在环境变量中加入安装的Graphviz路径</span><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"PATH"</span><span class="token punctuation">]</span> <span class="token operator">+=</span> os<span class="token punctuation">.</span>pathsep <span class="token operator">+</span> <span class="token string">'E:/Program Files (x86)/Graphviz2.38/bin'</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_irisiris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>clf <span class="token operator">=</span> tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>clf <span class="token operator">=</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span><span class="token keyword">import</span> pydotplus<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Imagedot_data <span class="token operator">=</span> tree<span class="token punctuation">.</span>export_graphviz<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> out_file<span class="token operator">=</span>None<span class="token punctuation">,</span>                          feature_names<span class="token operator">=</span>iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">,</span>                           class_names<span class="token operator">=</span>iris<span class="token punctuation">.</span>target_names<span class="token punctuation">,</span>                           filled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> rounded<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> special_characters<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  graph <span class="token operator">=</span> pydotplus<span class="token punctuation">.</span>graph_from_dot_data<span class="token punctuation">(</span>dot_data<span class="token punctuation">)</span>Image<span class="token punctuation">(</span>graph<span class="token punctuation">.</span>create_png<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdn.net/20180808124429851?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xfeHpt/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p><h2 id="XGBoost模型可视化"><a href="#XGBoost模型可视化" class="headerlink" title="XGBoost模型可视化"></a>XGBoost模型可视化</h2><p>参考文档 <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html" target="_blank" rel="noopener">https://xgboost.readthedocs.io/en/latest/python/python_api.html</a><br>xgboost中，对应的可视化函数是xgboost.to_graphviz。以iris数据为例，训练一个xgb分类模型并可视化</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 在环境变量中加入安装的Graphviz路径</span><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"PATH"</span><span class="token punctuation">]</span> <span class="token operator">+=</span> os<span class="token punctuation">.</span>pathsep <span class="token operator">+</span> <span class="token string">'E:/Program Files (x86)/Graphviz2.38/bin'</span><span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_irisiris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>xgb_clf <span class="token operator">=</span> xgb<span class="token punctuation">.</span>XGBClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>xgb_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span>xgb<span class="token punctuation">.</span>to_graphviz<span class="token punctuation">(</span>xgb_clf<span class="token punctuation">,</span> num_trees<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdn.net/20180808130159227?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xfeHpt/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p><p>也可以通过Digraph对象可以将保存文件并查看</p><pre class="line-numbers language-python"><code class="language-python">digraph <span class="token operator">=</span> xgb<span class="token punctuation">.</span>to_graphviz<span class="token punctuation">(</span>xgb_clf<span class="token punctuation">,</span> num_trees<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>digraph<span class="token punctuation">.</span>format <span class="token operator">=</span> <span class="token string">'png'</span>digraph<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token string">'./iris_xgb'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>xgboost中提供了另一个api plot_tree，使用matplotlib可视化树模型。效果上没有graphviz清楚。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltfig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>xgb<span class="token punctuation">.</span>plot_tree<span class="token punctuation">(</span>xgb_clf<span class="token punctuation">,</span> num_trees<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdn.net/20180808131546220?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xfeHpt/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p><h2 id="LightGBM模型可视化"><a href="#LightGBM模型可视化" class="headerlink" title="LightGBM模型可视化"></a>LightGBM模型可视化</h2><p>参考文档 <a href="https://lightgbm.readthedocs.io/en/latest/Python-API.html#plotting" target="_blank" rel="noopener">https://lightgbm.readthedocs.io/en/latest/Python-API.html#plotting</a><br>lgb中，对应的可视化函数是lightgbm.create_tree_digraph。以iris数据为例，训练一个lgb分类模型并可视化</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 在环境变量中加入安装的Graphviz路径</span><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"PATH"</span><span class="token punctuation">]</span> <span class="token operator">+=</span> os<span class="token punctuation">.</span>pathsep <span class="token operator">+</span> <span class="token string">'E:/Program Files (x86)/Graphviz2.38/bin'</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris<span class="token keyword">import</span> lightgbm <span class="token keyword">as</span> lgbiris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>lgb_clf <span class="token operator">=</span> lgb<span class="token punctuation">.</span>LGBMClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>lgb_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span>lgb<span class="token punctuation">.</span>create_tree_digraph<span class="token punctuation">(</span>lgb_clf<span class="token punctuation">,</span> tree_index<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>lgb中提供了另一个api plot_tree，使用matplotlib可视化树模型。效果上没有graphviz清楚。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltfig2 <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax <span class="token operator">=</span> fig2<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>lgb<span class="token punctuation">.</span>plot_tree<span class="token punctuation">(</span>lgb_clf<span class="token punctuation">,</span> tree_index<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="CatBoost模型可视化"><a href="#CatBoost模型可视化" class="headerlink" title="CatBoost模型可视化"></a>CatBoost模型可视化</h2><p><a href="https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboostclassifier-docpage/" target="_blank" rel="noopener">参考文档</a><br>        catboost并没有提供模型可视化的api。唯一可以导出模型结构的api是save_model(fname, format=”cbm”, export_parameters=None)<br>以iris数据为例，训练一个catboost模型。</p><p>参考文档 <a href="https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboostclassifier-docpage/" target="_blank" rel="noopener">https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboostclassifier-docpage/</a><br>catboost并没有提供模型可视化的api。唯一可以导出模型结构的api是save_model(fname, format=”cbm”, export_parameters=None)<br>以iris数据为例，训练一个catboost模型。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris<span class="token keyword">from</span> catboost <span class="token keyword">import</span> CatBoostClassifieriris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>cat_clf <span class="token operator">=</span> CatBoostClassifier<span class="token punctuation">(</span>iterations<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>cat_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以python代码格式保存模型文件</p><pre class="line-numbers language-python"><code class="language-python">cat_clf<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span><span class="token string">'catboost_model_file.py'</span><span class="token punctuation">,</span> format<span class="token operator">=</span><span class="token string">"python"</span><span class="token punctuation">,</span> export_parameters<span class="token operator">=</span>None<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也可以保存以C++代码格式保存模型文件</p><pre class="line-numbers language-python"><code class="language-python">cat_clf<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span><span class="token string">'catboost_model_file.cpp'</span><span class="token punctuation">,</span> format<span class="token operator">=</span><span class="token string">"cpp"</span><span class="token punctuation">,</span> export_parameters<span class="token operator">=</span>None<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看保存到的python代码，部分信息如下 </p><p><img src="https://img-blog.csdn.net/20180808143016336?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xfeHpt/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p><p><img src="https://img-blog.csdn.net/20180808142319424?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xfeHpt/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p><p>需要自己解析出文件了树的结构，再用 graphviz 绘制图像</p><h3 id="导出的Python文件"><a href="#导出的Python文件" class="headerlink" title="导出的Python文件"></a>导出的Python文件</h3><p>首先第一个for循环部分</p><pre class="line-numbers language-python"><code class="language-python">binary_feature_index <span class="token operator">=</span> <span class="token number">0</span>binary_features <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> model<span class="token punctuation">.</span>binary_feature_count<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>model<span class="token punctuation">.</span>float_feature_count<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>model<span class="token punctuation">.</span>border_counts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        binary_features<span class="token punctuation">[</span>binary_feature_index<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>float_features<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">></span> model<span class="token punctuation">.</span>borders<span class="token punctuation">[</span>binary_feature_index<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token number">0</span>        binary_feature_index <span class="token operator">+=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输入的参数float_features存储输入的数值型特征值。model.binary_feature_count表示booster中所有树的节点总数。model.border_counts存储每个feature对应的节点数量，model.borders存储所有节点的判断边界。显然，CatBoost并没有按照二叉树结构从左到右，从上到下的存储结构。此段代码的功能，生成所有节点的判断结果。如果特征值大于判断边界，表示为1，否则为0。存储在binary_features中。</p><p>第二个for循环部分</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Extract and sum values from trees</span>result <span class="token operator">=</span> <span class="token number">0.0</span>tree_splits_index <span class="token operator">=</span> <span class="token number">0</span>current_tree_leaf_values_index <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> tree_id <span class="token keyword">in</span> range<span class="token punctuation">(</span>model<span class="token punctuation">.</span>tree_count<span class="token punctuation">)</span><span class="token punctuation">:</span>    current_tree_depth <span class="token operator">=</span> model<span class="token punctuation">.</span>tree_depth<span class="token punctuation">[</span>tree_id<span class="token punctuation">]</span>    index <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> depth <span class="token keyword">in</span> range<span class="token punctuation">(</span>current_tree_depth<span class="token punctuation">)</span><span class="token punctuation">:</span>        index <span class="token operator">|</span><span class="token operator">=</span> <span class="token punctuation">(</span>binary_features<span class="token punctuation">[</span>model<span class="token punctuation">.</span>tree_splits<span class="token punctuation">[</span>tree_splits_index <span class="token operator">+</span> depth<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> depth<span class="token punctuation">)</span>    result <span class="token operator">+=</span> model<span class="token punctuation">.</span>leaf_values<span class="token punctuation">[</span>current_tree_leaf_values_index <span class="token operator">+</span> index<span class="token punctuation">]</span>    tree_splits_index <span class="token operator">+=</span> current_tree_depth    current_tree_leaf_values_index <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> current_tree_depth<span class="token punctuation">)</span><span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这段点代码功能是生成模型的预测结果result。model.tree_count表示决策树的数量，遍历每棵决策树。model.tree_depth存储每棵决策树的深度，取当前树的深度，存储在current_tree_depth。model.tree_splits存储决策树当前深度的节点在binary_features中的索引，每棵树有current_tree_depth个节点。看似CatBoost模型存储了都是完全二叉树，而且每一层的节点以及该节点的判断边界一致。如一棵6层的决策，可以从binary_features中得到一个长度为6，值为0和1组成的list。model.leaf_values存储所有叶子节点的值，每棵树的叶子节点有(1 &lt;&lt; current_tree_depth)个。将之前得到的list，倒序之后，看出一个2进制表示的数index，加上current_tree_leaf_values_index后，即是值在model.leaf_values的索引。将所有树得到的值相加，得到CatBoost模型的结果。</p><h3 id="还原CatBoost模型树"><a href="#还原CatBoost模型树" class="headerlink" title="还原CatBoost模型树"></a>还原CatBoost模型树</h3><p>先从第二个for循环开始，打印每棵树序号，树的深度，当前树节点索引在tree_splits的便宜了，已经每个节点对应在tree_splits中的值。这个值对应的是在第一个for循环中生成的binary_features的索引。</p><pre class="line-numbers language-python"><code class="language-python">tree_splits_index <span class="token operator">=</span> <span class="token number">0</span>current_tree_leaf_values_index <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> tree_id <span class="token keyword">in</span> range<span class="token punctuation">(</span>tree_count<span class="token punctuation">)</span><span class="token punctuation">:</span>    current_tree_depth <span class="token operator">=</span> tree_depth<span class="token punctuation">[</span>tree_id<span class="token punctuation">]</span>    tree_splits_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> depth <span class="token keyword">in</span> range<span class="token punctuation">(</span>current_tree_depth<span class="token punctuation">)</span><span class="token punctuation">:</span>        tree_splits_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tree_splits<span class="token punctuation">[</span>tree_splits_index <span class="token operator">+</span> depth<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span> tree_id<span class="token punctuation">,</span> current_tree_depth<span class="token punctuation">,</span> tree_splits_index<span class="token punctuation">,</span> tree_splits_list    tree_splits_index <span class="token operator">+=</span> current_tree_depth    current_tree_leaf_values_index <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> current_tree_depth<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token number">0</span> <span class="token number">6</span> <span class="token number">0</span> <span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">104</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">]</span><span class="token number">1</span> <span class="token number">6</span> <span class="token number">6</span> <span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">106</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token number">2</span> <span class="token number">6</span> <span class="token number">12</span> <span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">]</span><span class="token number">3</span> <span class="token number">6</span> <span class="token number">18</span> <span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">105</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">106</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">111</span><span class="token punctuation">]</span><span class="token number">4</span> <span class="token number">6</span> <span class="token number">24</span> <span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">75</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">]</span><span class="token number">5</span> <span class="token number">6</span> <span class="token number">30</span> <span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">103</span><span class="token punctuation">,</span> <span class="token number">104</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">]</span><span class="token number">6</span> <span class="token number">6</span> <span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">]</span><span class="token number">7</span> <span class="token number">6</span> <span class="token number">42</span> <span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">111</span><span class="token punctuation">]</span><span class="token number">8</span> <span class="token number">6</span> <span class="token number">48</span> <span class="token punctuation">[</span><span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">71</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token number">9</span> <span class="token number">4</span> <span class="token number">54</span> <span class="token punctuation">[</span><span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">37</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从第一个for循环可以看出，每个feature对应的节点都在一起，且每个feature的数量保存在model.border_counts。即可生成每个feature在binary_features的索引区间。</p><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>从第一个for循环可以看出，每个feature对应的节点都在一起，且每个feature的数量保存在model.border_counts。即可生成每个feature在binary_features的索引区间。</p><pre class="line-numbers language-python"><code class="language-python">split_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>border_counts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    split_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>split_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> border_counts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span> border_counts<span class="token keyword">print</span> zip<span class="token punctuation">(</span>split_list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> split_list<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">92</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">92</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在拿到一个binary_features的索引后即可知道该索引对应的节点使用的特征序号（float_features的索引）。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">find_feature</span><span class="token punctuation">(</span>tree_splits_index<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>split_list<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> split_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> tree_splits_index <span class="token operator">&lt;</span> split_list<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> i<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>有了节点在binary_features中的索引，该索引也对应特征的判断边界数值索引，也知道了如何根据索引获取特征序号。决策树索引信息都的得到了，现在可以绘制树了。</p><h2 id="绘制单棵决策树"><a href="#绘制单棵决策树" class="headerlink" title="绘制单棵决策树"></a>绘制单棵决策树</h2><p>首先修改一下代码，便于获取单棵树的节点</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">CatBoostTree</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> CatboostModel<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> CatboostModel        self<span class="token punctuation">.</span>split_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>float_feature_count<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>split_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>split_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>border_counts<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">find_feature</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> splits_index<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 可优化成二分查找</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>float_feature_count<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>split_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> splits_index <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>split_list<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> i<span class="token keyword">def</span> <span class="token function">get_split_index</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tree_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    tree_splits_index <span class="token operator">=</span> <span class="token number">0</span>    current_tree_leaf_values_index <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> index <span class="token keyword">in</span> range<span class="token punctuation">(</span>tree_id<span class="token punctuation">)</span><span class="token punctuation">:</span>        current_tree_depth <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>tree_depth<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        tree_splits_index <span class="token operator">+=</span> current_tree_depth        current_tree_leaf_values_index <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> current_tree_depth<span class="token punctuation">)</span>    <span class="token keyword">return</span> tree_splits_index<span class="token punctuation">,</span> current_tree_leaf_values_index<span class="token keyword">def</span> <span class="token function">get_tree_info</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tree_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    tree_splits_index<span class="token punctuation">,</span> current_tree_leaf_values_index <span class="token operator">=</span> self<span class="token punctuation">.</span>get_split_index<span class="token punctuation">(</span>tree_id<span class="token punctuation">)</span>    current_tree_depth <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>tree_depth<span class="token punctuation">[</span>tree_id<span class="token punctuation">]</span>    tree_splits_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> depth <span class="token keyword">in</span> range<span class="token punctuation">(</span>current_tree_depth<span class="token punctuation">)</span><span class="token punctuation">:</span>        tree_splits_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>tree_splits<span class="token punctuation">[</span>tree_splits_index <span class="token operator">+</span> depth<span class="token punctuation">]</span><span class="token punctuation">)</span>    node_feature_list <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>find_feature<span class="token punctuation">(</span>index<span class="token punctuation">)</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> tree_splits_list<span class="token punctuation">]</span>    node_feature_borders <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>borders<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> tree_splits_list<span class="token punctuation">]</span>    end_tree_leaf_values_index <span class="token operator">=</span> current_tree_leaf_values_index <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> current_tree_depth<span class="token punctuation">)</span>    tree_leaf_values <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>leaf_values<span class="token punctuation">[</span>current_tree_leaf_values_index<span class="token punctuation">:</span> end_tree_leaf_values_index<span class="token punctuation">]</span>    <span class="token keyword">return</span> current_tree_depth<span class="token punctuation">,</span> node_feature_list<span class="token punctuation">,</span> node_feature_borders<span class="token punctuation">,</span> tree_leaf_values<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面是绘制一棵决策树的函数，CatBoost导出的python代码文件通过model_file参数传入。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> imp<span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"PATH"</span><span class="token punctuation">]</span> <span class="token operator">+=</span> os<span class="token punctuation">.</span>pathsep <span class="token operator">+</span> <span class="token string">'E:/Program Files (x86)/Graphviz2.38/bin'</span><span class="token keyword">from</span> graphviz <span class="token keyword">import</span> Digraph<span class="token keyword">def</span> <span class="token function">draw_tree</span><span class="token punctuation">(</span>model_file<span class="token punctuation">,</span> tree_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    fp<span class="token punctuation">,</span> pathname<span class="token punctuation">,</span> description <span class="token operator">=</span> imp<span class="token punctuation">.</span>find_module<span class="token punctuation">(</span>model_file<span class="token punctuation">)</span>    CatboostModel <span class="token operator">=</span> imp<span class="token punctuation">.</span>load_module<span class="token punctuation">(</span><span class="token string">'CatboostModel'</span><span class="token punctuation">,</span> fp<span class="token punctuation">,</span> pathname<span class="token punctuation">,</span> description<span class="token punctuation">)</span>    catboost_tree <span class="token operator">=</span> CatBoostTree<span class="token punctuation">(</span>CatboostModel<span class="token punctuation">.</span>CatboostModel<span class="token punctuation">)</span>    current_tree_depth<span class="token punctuation">,</span> node_feature_list<span class="token punctuation">,</span> node_feature_borders<span class="token punctuation">,</span> tree_leaf_values <span class="token operator">=</span> catboost_tree<span class="token punctuation">.</span>get_tree_info<span class="token punctuation">(</span>tree_id<span class="token punctuation">)</span>    dot <span class="token operator">=</span> Digraph<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'tree_'</span><span class="token operator">+</span>str<span class="token punctuation">(</span>tree_id<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> depth <span class="token keyword">in</span> range<span class="token punctuation">(</span>current_tree_depth<span class="token punctuation">)</span><span class="token punctuation">:</span>    node_name <span class="token operator">=</span> str<span class="token punctuation">(</span>node_feature_list<span class="token punctuation">[</span>current_tree_depth <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> depth<span class="token punctuation">]</span><span class="token punctuation">)</span>    node_border <span class="token operator">=</span> str<span class="token punctuation">(</span>node_feature_borders<span class="token punctuation">[</span>current_tree_depth <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> depth<span class="token punctuation">]</span><span class="token punctuation">)</span>    label <span class="token operator">=</span> <span class="token string">'column_'</span> <span class="token operator">+</span> node_name <span class="token operator">+</span> <span class="token string">'>'</span> <span class="token operator">+</span> node_border    <span class="token keyword">if</span> depth <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        dot<span class="token punctuation">.</span>node<span class="token punctuation">(</span>str<span class="token punctuation">(</span>depth<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_0'</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> depth<span class="token punctuation">)</span><span class="token punctuation">:</span>            dot<span class="token punctuation">.</span>node<span class="token punctuation">(</span>str<span class="token punctuation">(</span>depth<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>            dot<span class="token punctuation">.</span>edge<span class="token punctuation">(</span>str<span class="token punctuation">(</span>depth<span class="token number">-1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>j<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> str<span class="token punctuation">(</span>depth<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'No'</span> <span class="token keyword">if</span> j<span class="token operator">%</span><span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'Yes'</span><span class="token punctuation">)</span>depth <span class="token operator">=</span> current_tree_depth<span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> depth<span class="token punctuation">)</span><span class="token punctuation">:</span>    dot<span class="token punctuation">.</span>node<span class="token punctuation">(</span>str<span class="token punctuation">(</span>depth<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">,</span> str<span class="token punctuation">(</span>tree_leaf_values<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    dot<span class="token punctuation">.</span>edge<span class="token punctuation">(</span>str<span class="token punctuation">(</span>depth<span class="token number">-1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>j<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> str<span class="token punctuation">(</span>depth<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'No'</span> <span class="token keyword">if</span> j<span class="token operator">%</span><span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'Yes'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># dot.format = 'png'</span>path <span class="token operator">=</span> dot<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token string">'./'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>tree_id<span class="token punctuation">)</span><span class="token punctuation">,</span> cleanup<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span> path<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>例如绘制第11棵树（序数从0开始）。draw_tree(‘catboost_model_file’, 11)。 </p><p><img src="https://img-blog.csdn.net/20180809104012816?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xfeHpt/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p><p>为了验证这个对不对，需要对一个测试特征生成每棵树的路径和结果，抽查一两个测试用例以及其中的一两颗树，观察结果是否相同。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test_tree</span><span class="token punctuation">(</span>model_file<span class="token punctuation">,</span> float_features<span class="token punctuation">)</span><span class="token punctuation">:</span>    fp<span class="token punctuation">,</span> pathname<span class="token punctuation">,</span> description <span class="token operator">=</span> imp<span class="token punctuation">.</span>find_module<span class="token punctuation">(</span>model_file<span class="token punctuation">)</span>    CatboostModel <span class="token operator">=</span> imp<span class="token punctuation">.</span>load_module<span class="token punctuation">(</span><span class="token string">'CatboostModel'</span><span class="token punctuation">,</span> fp<span class="token punctuation">,</span> pathname<span class="token punctuation">,</span> description<span class="token punctuation">)</span>    model <span class="token operator">=</span> CatboostModel<span class="token punctuation">.</span>CatboostModel    catboost_tree <span class="token operator">=</span> CatBoostTree<span class="token punctuation">(</span>CatboostModel<span class="token punctuation">.</span>CatboostModel<span class="token punctuation">)</span>    result <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> tree_id <span class="token keyword">in</span> range<span class="token punctuation">(</span>model<span class="token punctuation">.</span>tree_count<span class="token punctuation">)</span><span class="token punctuation">:</span>        current_tree_depth<span class="token punctuation">,</span> node_feature_list<span class="token punctuation">,</span> node_feature_borders<span class="token punctuation">,</span> tree_leaf_values <span class="token operator">=</span> catboost_tree<span class="token punctuation">.</span>get_tree_info<span class="token punctuation">(</span>tree_id<span class="token punctuation">)</span>        route <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> depth <span class="token keyword">in</span> range<span class="token punctuation">(</span>current_tree_depth<span class="token punctuation">)</span><span class="token punctuation">:</span>            route<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> float_features<span class="token punctuation">[</span>node_feature_list<span class="token punctuation">[</span>depth<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">></span> node_feature_borders<span class="token punctuation">[</span>depth<span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>        index <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> depth <span class="token keyword">in</span> range<span class="token punctuation">(</span>current_tree_depth<span class="token punctuation">)</span><span class="token punctuation">:</span>            index <span class="token operator">|</span><span class="token operator">=</span> route<span class="token punctuation">[</span>depth<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> depth        tree_value <span class="token operator">=</span> tree_leaf_values<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        <span class="token keyword">print</span> route<span class="token punctuation">,</span> index<span class="token punctuation">,</span> tree_value        result <span class="token operator">+=</span> tree_value    <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如我们生成了第11棵树的图像，根据测试测试特征，手动在图像上查找可以得到一个值A。test_tree函数会打印一系列值，其中第11行对应的结果为值B。值A与值B相同，则测试为问题。<br>其次还需要测试所有树的结果和导出文件中apply_catboost_model函数得到的结果相同。这个可以写个脚本，拿训练数据集跑一边。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> catboost_model_file <span class="token keyword">import</span> apply_catboost_model<span class="token keyword">from</span> CatBoostModelInfo <span class="token keyword">import</span> test_tree<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># print iris.data</span>    <span class="token comment" spellcheck="true"># print iris.target</span>    <span class="token keyword">for</span> feature <span class="token keyword">in</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">:</span>    <span class="token keyword">if</span> apply_catboost_model<span class="token punctuation">(</span>feature<span class="token punctuation">)</span> <span class="token operator">!=</span> test_tree<span class="token punctuation">(</span><span class="token string">'catboost_model_file'</span><span class="token punctuation">,</span> feature<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span> <span class="token boolean">False</span> <span class="token keyword">print</span> <span class="token string">'End.'</span><span class="token keyword">if</span> name <span class="token operator">==</span> <span class="token string">'main'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>至此，CatBoost模型的可视化完成了。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      模型可视化
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="LightGBM" scheme="https://dataquaner.github.io/tags/LightGBM/"/>
    
      <category term="XGBoost" scheme="https://dataquaner.github.io/tags/XGBoost/"/>
    
      <category term="GBDT" scheme="https://dataquaner.github.io/tags/GBDT/"/>
    
      <category term="CatBoost" scheme="https://dataquaner.github.io/tags/CatBoost/"/>
    
  </entry>
  
  <entry>
    <title>DBSCAN算法python实现（附完整数据集和代码）</title>
    <link href="https://dataquaner.github.io/2020/01/07/dbscan-suan-fa-python-shi-xian-fu-wan-zheng-shu-ju-ji-he-dai-ma/"/>
    <id>https://dataquaner.github.io/2020/01/07/dbscan-suan-fa-python-shi-xian-fu-wan-zheng-shu-ju-ji-he-dai-ma/</id>
    <published>2020-01-07T08:05:00.000Z</published>
    <updated>2020-04-11T11:30:29.639Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p>[TOC]</p><h1 id="1-算法思路"><a href="#1-算法思路" class="headerlink" title="1. 算法思路"></a>1. 算法思路</h1><p>DBSCAN算法的核心是“延伸”。先找到一个未访问的点p，若该点是核心点，则创建一个新的簇C，将其邻域中的点放入该簇，并遍历其邻域中的点，若其邻域中有点q为核心点，则将q的邻域内的点也划入簇C，直到C不再扩展。直到最后所有的点都标记为已访问。</p><p>点p通过密度可达来扩大自己的“地盘”，实际上就是簇在“延伸”。 </p><p>图示网站：<a href="https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/" target="_blank" rel="noopener">https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/</a> 可以看一下簇是如何延伸的。</p><h1 id="2-算法实现"><a href="#2-算法实现" class="headerlink" title="2. 算法实现"></a>2. 算法实现</h1><h2 id="2-1-计算两点之间的距离"><a href="#2-1-计算两点之间的距离" class="headerlink" title="2.1 计算两点之间的距离"></a>2.1 计算两点之间的距离</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 计算两个点之间的欧式距离，参数为两个元组</span><span class="token keyword">def</span> <span class="token function">dist</span><span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span><span class="token punctuation">:</span>    dis <span class="token operator">=</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token punctuation">(</span>t1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span>t2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token punctuation">(</span>t1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">-</span>t2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># print("两点之间的距离为："+str(dis))</span>    <span class="token keyword">return</span> dis<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-2-读取文件，加载数据集"><a href="#2-2-读取文件，加载数据集" class="headerlink" title="2.2 读取文件，加载数据集"></a><strong>2.2 读取文件，加载数据集</strong></h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loadDataSet</span><span class="token punctuation">(</span>fileName<span class="token punctuation">,</span> splitChar<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    dataSet <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>fileName<span class="token punctuation">)</span> <span class="token keyword">as</span> fr<span class="token punctuation">:</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> fr<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            curline <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span>splitChar<span class="token punctuation">)</span>            fltline <span class="token operator">=</span> list<span class="token punctuation">(</span>map<span class="token punctuation">(</span>float<span class="token punctuation">,</span> curline<span class="token punctuation">)</span><span class="token punctuation">)</span>            dataSet<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fltline<span class="token punctuation">)</span>    <span class="token keyword">return</span> dataSet<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-3-DBSCAN算法实现"><a href="#2-3-DBSCAN算法实现" class="headerlink" title="2.3 DBSCAN算法实现"></a>2.3 DBSCAN算法实现</h2><p>1、标记点是否被访问：我设置了两个列表，一个存放未访问的点unvisited，一个存放已访问的点visited。每次访问一个点，unvisited列表remove该点，visited列表append该点，以此来实现点的标记改变。</p><p>2、C作为输出结果，初始时是一个长度为所有点的个数的值全为-1的列表。之后修改点对应的索引的值来设置点属于哪个簇</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># DBSCAN算法，参数为数据集，Eps为指定半径参数，MinPts为制定邻域密度阈值</span><span class="token keyword">def</span> <span class="token function">dbscan</span><span class="token punctuation">(</span>Data<span class="token punctuation">,</span> Eps<span class="token punctuation">,</span> MinPts<span class="token punctuation">)</span><span class="token punctuation">:</span>    num <span class="token operator">=</span> len<span class="token punctuation">(</span>Data<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 点的个数</span>    <span class="token comment" spellcheck="true"># print("点的个数："+str(num))</span>    unvisited <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 没有访问到的点的列表</span>    <span class="token comment" spellcheck="true"># print(unvisited)</span>    visited <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 已经访问的点的列表</span>    C <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># C为输出结果，默认是一个长度为num的值全为-1的列表</span>    <span class="token comment" spellcheck="true"># 用k来标记不同的簇，k = -1表示噪声点</span>    k <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token comment" spellcheck="true"># 如果还有没访问的点</span>    <span class="token keyword">while</span> len<span class="token punctuation">(</span>unvisited<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 随机选择一个unvisited对象</span>        p <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>unvisited<span class="token punctuation">)</span>        unvisited<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        visited<span class="token punctuation">.</span>append<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># N为p的epsilon邻域中的对象的集合</span>        N <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>dist<span class="token punctuation">(</span>Data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> Data<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> Eps<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># and (i!=p):</span>                N<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 如果p的epsilon邻域中的对象数大于指定阈值，说明p是一个核心对象</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>N<span class="token punctuation">)</span> <span class="token operator">>=</span> MinPts<span class="token punctuation">:</span>            k <span class="token operator">=</span> k<span class="token operator">+</span><span class="token number">1</span>            <span class="token comment" spellcheck="true"># print(k)</span>            C<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> k            <span class="token comment" spellcheck="true"># 对于p的epsilon邻域中的每个对象pi</span>            <span class="token keyword">for</span> pi <span class="token keyword">in</span> N<span class="token punctuation">:</span>                <span class="token keyword">if</span> pi <span class="token keyword">in</span> unvisited<span class="token punctuation">:</span>                    unvisited<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>pi<span class="token punctuation">)</span>                    visited<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pi<span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true"># 找到pi的邻域中的核心对象，将这些对象放入N中</span>                    <span class="token comment" spellcheck="true"># M是位于pi的邻域中的点的列表</span>                    M <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>                        <span class="token keyword">if</span> <span class="token punctuation">(</span>dist<span class="token punctuation">(</span>Data<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> Data<span class="token punctuation">[</span>pi<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&lt;=</span>Eps<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#and (j!=pi):</span>                            M<span class="token punctuation">.</span>append<span class="token punctuation">(</span>j<span class="token punctuation">)</span>                    <span class="token keyword">if</span> len<span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token operator">>=</span>MinPts<span class="token punctuation">:</span>                        <span class="token keyword">for</span> t <span class="token keyword">in</span> M<span class="token punctuation">:</span>                            <span class="token keyword">if</span> t <span class="token operator">not</span> <span class="token keyword">in</span> N<span class="token punctuation">:</span>                                N<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># 若pi不属于任何簇，C[pi] == -1说明C中第pi个值没有改动</span>                <span class="token keyword">if</span> C<span class="token punctuation">[</span>pi<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>                    C<span class="token punctuation">[</span>pi<span class="token punctuation">]</span> <span class="token operator">=</span> k        <span class="token comment" spellcheck="true"># 如果p的epsilon邻域中的对象数小于指定阈值，说明p是一个噪声点</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            C<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">return</span> C<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-问题记录"><a href="#3-问题记录" class="headerlink" title="3. 问题记录"></a>3. 问题记录</h1><p>代码思路非常简单，让我以为实现起来也很简单。结果拖拖拉拉半个多月才终于将算法改好。</p><p>算法实现过程中遇到的问题其实是小问题，但是导致的结果非常严重。因为不起眼所以才难以察觉。</p><p>这是刚开始我运行算法得到的结果（Eps为10，MinPts为10）：</p><p><img src="https://img-blog.csdnimg.cn/20190614104513322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pveWNlX0Zm,size_16,color_FFFFFF,t_70" alt="img"></p><p>Eps为2，MinPts为10（我改了点的大小）：</p><p><img src="https://img-blog.csdnimg.cn/20190614104535578.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pveWNlX0Zm,size_16,color_FFFFFF,t_70" alt="img"></p><p>可以看出图中颜色特别多，实际上就是聚成的簇太多，可实际上目测应该只有七八个簇。这是为什么呢？</p><p>原来是变量k的重复使用问题。</p><p>前面我用k来标识不同的簇，后面（如下图）我又将k变成了循环变量，注意M列表中都是整数，代表点在数据集中的索引，所以实际上是k在整数列表中遍历，覆盖掉了前面用来标识不同簇的k值，导致每次运行出来k取值特别多（如下下图）。</p><p><img src="https://img-blog.csdnimg.cn/20190614104625815.png" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/2019061410463417.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pveWNlX0Zm,size_16,color_FFFFFF,t_70" alt="img"></p><h1 id="4-运行结果"><a href="#4-运行结果" class="headerlink" title="4. 运行结果"></a>4. 运行结果</h1><p><img src="https://img-blog.csdnimg.cn/20190614104713963.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pveWNlX0Zm,size_16,color_FFFFFF,t_70" alt="img"></p><h1 id="5-完整代码"><a href="#5-完整代码" class="headerlink" title="5. 完整代码"></a>5. 完整代码</h1><h2 id="5-1-源数据"><a href="#5-1-源数据" class="headerlink" title="5.1 源数据"></a>5.1 源数据</h2><p>附数据集</p><p>链接：<a href="https://pan.baidu.com/s/1dI1Eu7etWvx8IZX-ikqBig" target="_blank" rel="noopener">数据集788个点</a><br>        提取码：rv06</p><h2 id="5-2-源代码"><a href="#5-2-源代码" class="headerlink" title="5.2 源代码"></a>5.2 源代码</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># encoding:utf-8</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> random<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> math<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasetslist_1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>list_2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 数据集一：随机生成散点图,参数为点的个数</span><span class="token comment" spellcheck="true"># def scatter(num):</span><span class="token comment" spellcheck="true">#     for i in range(num):</span><span class="token comment" spellcheck="true">#         x = random.randint(0, 100)</span><span class="token comment" spellcheck="true">#         list_1.append(x)</span><span class="token comment" spellcheck="true">#         y = random.randint(0, 100)</span><span class="token comment" spellcheck="true">#         list_2.append(y)</span><span class="token comment" spellcheck="true">#     print(list_1)</span><span class="token comment" spellcheck="true">#     print(list_2)</span><span class="token comment" spellcheck="true">#     data = list(zip(list_1, list_2))</span><span class="token comment" spellcheck="true">#     print(data)</span><span class="token comment" spellcheck="true">#     #plt.scatter(list_1, list_2)</span><span class="token comment" spellcheck="true">#     #plt.show()</span><span class="token comment" spellcheck="true">#     return data</span><span class="token comment" spellcheck="true">#scatter(50)</span><span class="token keyword">def</span> <span class="token function">loadDataSet</span><span class="token punctuation">(</span>fileName<span class="token punctuation">,</span> splitChar<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    dataSet <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>fileName<span class="token punctuation">)</span> <span class="token keyword">as</span> fr<span class="token punctuation">:</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> fr<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            curline <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span>splitChar<span class="token punctuation">)</span>            fltline <span class="token operator">=</span> list<span class="token punctuation">(</span>map<span class="token punctuation">(</span>float<span class="token punctuation">,</span> curline<span class="token punctuation">)</span><span class="token punctuation">)</span>            dataSet<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fltline<span class="token punctuation">)</span>    <span class="token keyword">return</span> dataSet<span class="token comment" spellcheck="true"># 计算两个点之间的欧式距离，参数为两个元组</span><span class="token keyword">def</span> <span class="token function">dist</span><span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span><span class="token punctuation">:</span>    dis <span class="token operator">=</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token punctuation">(</span>t1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span>t2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token punctuation">(</span>t1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">-</span>t2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># print("两点之间的距离为："+str(dis))</span>    <span class="token keyword">return</span> dis<span class="token comment" spellcheck="true"># dis = dist((1,1),(3,4))</span><span class="token comment" spellcheck="true"># print(dis)</span><span class="token comment" spellcheck="true"># DBSCAN算法，参数为数据集，Eps为指定半径参数，MinPts为制定邻域密度阈值</span><span class="token keyword">def</span> <span class="token function">dbscan</span><span class="token punctuation">(</span>Data<span class="token punctuation">,</span> Eps<span class="token punctuation">,</span> MinPts<span class="token punctuation">)</span><span class="token punctuation">:</span>    num <span class="token operator">=</span> len<span class="token punctuation">(</span>Data<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 点的个数</span>    <span class="token comment" spellcheck="true"># print("点的个数："+str(num))</span>    unvisited <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 没有访问到的点的列表</span>    <span class="token comment" spellcheck="true"># print(unvisited)</span>    visited <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 已经访问的点的列表</span>    C <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># C为输出结果，默认是一个长度为num的值全为-1的列表</span>    <span class="token comment" spellcheck="true"># 用k来标记不同的簇，k = -1表示噪声点</span>    k <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token comment" spellcheck="true"># 如果还有没访问的点</span>    <span class="token keyword">while</span> len<span class="token punctuation">(</span>unvisited<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 随机选择一个unvisited对象</span>        p <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>unvisited<span class="token punctuation">)</span>        unvisited<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        visited<span class="token punctuation">.</span>append<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># N为p的epsilon邻域中的对象的集合</span>        N <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>dist<span class="token punctuation">(</span>Data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> Data<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> Eps<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># and (i!=p):</span>                N<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 如果p的epsilon邻域中的对象数大于指定阈值，说明p是一个核心对象</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>N<span class="token punctuation">)</span> <span class="token operator">>=</span> MinPts<span class="token punctuation">:</span>            k <span class="token operator">=</span> k<span class="token operator">+</span><span class="token number">1</span>            <span class="token comment" spellcheck="true"># print(k)</span>            C<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> k            <span class="token comment" spellcheck="true"># 对于p的epsilon邻域中的每个对象pi</span>            <span class="token keyword">for</span> pi <span class="token keyword">in</span> N<span class="token punctuation">:</span>                <span class="token keyword">if</span> pi <span class="token keyword">in</span> unvisited<span class="token punctuation">:</span>                    unvisited<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>pi<span class="token punctuation">)</span>                    visited<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pi<span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true"># 找到pi的邻域中的核心对象，将这些对象放入N中</span>                    <span class="token comment" spellcheck="true"># M是位于pi的邻域中的点的列表</span>                    M <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>                        <span class="token keyword">if</span> <span class="token punctuation">(</span>dist<span class="token punctuation">(</span>Data<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> Data<span class="token punctuation">[</span>pi<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&lt;=</span>Eps<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#and (j!=pi):</span>                            M<span class="token punctuation">.</span>append<span class="token punctuation">(</span>j<span class="token punctuation">)</span>                    <span class="token keyword">if</span> len<span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token operator">>=</span>MinPts<span class="token punctuation">:</span>                        <span class="token keyword">for</span> t <span class="token keyword">in</span> M<span class="token punctuation">:</span>                            <span class="token keyword">if</span> t <span class="token operator">not</span> <span class="token keyword">in</span> N<span class="token punctuation">:</span>                                N<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># 若pi不属于任何簇，C[pi] == -1说明C中第pi个值没有改动</span>                <span class="token keyword">if</span> C<span class="token punctuation">[</span>pi<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>                    C<span class="token punctuation">[</span>pi<span class="token punctuation">]</span> <span class="token operator">=</span> k        <span class="token comment" spellcheck="true"># 如果p的epsilon邻域中的对象数小于指定阈值，说明p是一个噪声点</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            C<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">return</span> C<span class="token comment" spellcheck="true"># 数据集二：788个点</span>dataSet <span class="token operator">=</span> loadDataSet<span class="token punctuation">(</span><span class="token string">'788points.txt'</span><span class="token punctuation">,</span> splitChar<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>C <span class="token operator">=</span> dbscan<span class="token punctuation">(</span>dataSet<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>C<span class="token punctuation">)</span>x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> data <span class="token keyword">in</span> dataSet<span class="token punctuation">:</span>    x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dpi<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span> c<span class="token operator">=</span>C<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print(x)</span><span class="token comment" spellcheck="true"># print(y)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      DBSCAN
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="DBSCAN" scheme="https://dataquaner.github.io/tags/DBSCAN/"/>
    
  </entry>
  
  <entry>
    <title>短文本聚类【DBSCAN】算法原理+Python代码实现+聚类结果展示</title>
    <link href="https://dataquaner.github.io/2020/01/07/duan-wen-ben-ju-lei-dbscan-suan-fa-yuan-li-python-dai-ma-shi-xian-ju-lei-jie-guo-zhan-shi/"/>
    <id>https://dataquaner.github.io/2020/01/07/duan-wen-ben-ju-lei-dbscan-suan-fa-yuan-li-python-dai-ma-shi-xian-ju-lei-jie-guo-zhan-shi/</id>
    <published>2020-01-07T08:05:00.000Z</published>
    <updated>2020-04-11T11:34:53.017Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p>[TOC]</p><h1 id="1-算法原理"><a href="#1-算法原理" class="headerlink" title="1. 算法原理"></a>1. 算法原理</h1><h2 id="1-1-常见的聚类算法"><a href="#1-1-常见的聚类算法" class="headerlink" title="1.1 常见的聚类算法"></a>1.1 常见的聚类算法</h2><p>聚类算法属于常见的无监督分类算法，在很多场景下都有应用，如用户聚类，文本聚类等。常见的聚类算法可以分成两类：</p><ul><li>以 k-means 为代表的基于分区的算法</li><li>以层次聚类为代表的基于层次划分的算法</li></ul><p>对于第一类方法，有以下几个缺点：</p><blockquote><p>1）需要事先确定聚类的个数，当数据集比较大时，很难事先给出一个合适的值；</p><p>2）只适用于具有凸形状的簇，不适用于具有任意形状的簇；</p><p>3）对内存的占用资源比较大，难以推广至大规模数据集；        </p></blockquote><p>对于第二类方法，有以下缺点：</p><blockquote><p>1）需要确定停止分裂的条件</p><p>2）计算速度慢</p></blockquote><h2 id="1-2-DBSCAN聚类"><a href="#1-2-DBSCAN聚类" class="headerlink" title="1.2 DBSCAN聚类"></a>1.2 DBSCAN聚类</h2><blockquote><p><a href="http://www.philippe-fournier-viger.com/spmf/DBScan.pdf" target="_blank" rel="noopener">A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise （Martin Ester, Hans-Peter Kriegel, Jörg Sander, Xiaowei Xu）</a></p></blockquote><p>DBSCAN是一类基于密度的算法，能有效解决上述两类算法的问题。</p><blockquote><p>DBSCAN的基本假设是一个集群的密度要显著高于噪声点的密度。因此，其基本思想是对于集群中的每一个点，在给定的半径范围内，相邻点的数量必须超过预先设定的某一个阈值。</p></blockquote><p>因此，DBSCAN算法中包含两个重要的参数：</p><blockquote><p><strong>eps：</strong>聚类类别中样本的相似度衡量，与类别内样本相似度成反比。可以理解为同一个类别当中，对两个样本之间距离的最大值限定。<br>    <strong>min_samples：</strong>每个聚类类别中的最小样本数，会对未分类样本数量造成影响，与未分类样本数量成正比。当相似样本数量少于该参数时，不会聚到一起。</p></blockquote><p>在实际应用过程中，根据样本的大小，以及样本的大致分布，了解聚类结果会随着这两个参数如何变化之后，可以根据自己的经验对两个参数进行调整。只有两个模型参数需要调整，因此调参过程也不会太麻烦。</p><h1 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2. 代码实现"></a>2. 代码实现</h1><h2 id="2-1-import需要的包"><a href="#2-1-import需要的包" class="headerlink" title="2.1 import需要的包"></a>2.1 import需要的包</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># === import packages === #</span><span class="token keyword">import</span> jieba<span class="token punctuation">.</span>posseg <span class="token keyword">as</span> pseg<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfTransformer<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> DBSCAN<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-2-载入数据"><a href="#2-2-载入数据" class="headerlink" title="2.2 载入数据"></a>2.2 载入数据</h2><p>根据数据文件的不同存在不同的数据载入方法，我当时使用的是两种类型的数据，分别是直接包含目标短文本的txt，以json格式存储的txt。如果有用到这两种类型的文件可以参考这部分的数据载入代码，其他的请根据文件类型和数据样式自行载入。首先是载入以json格式存储的txt文件，可以用正则表达式，也可以根据数据存储的方式提取出对应的字段。先展示一下数据的存储格式：</p><pre class="line-numbers language-json"><code class="language-json"><span class="token punctuation">{</span><span class="token property">"code"</span><span class="token operator">:</span> <span class="token string">"200"</span><span class="token punctuation">,</span><span class="token property">"data"</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token property">"result"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"updateDate"</span><span class="token operator">:</span> <span class="token number">1551923786433</span><span class="token punctuation">,</span><span class="token property">"ensureIntentName"</span><span class="token operator">:</span> <span class="token string">"新意图"</span><span class="token punctuation">,</span><span class="token property">"corpus"</span><span class="token operator">:</span> <span class="token string">"怎么查询之前的小微提醒"</span><span class="token punctuation">,</span><span class="token property">"recommendResult"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token property">"remark"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span><span class="token property">"source"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token property">"result"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token property">"eventName"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span><span class="token property">"id"</span><span class="token operator">:</span> <span class="token string">"b07328fc-8383-44b7-b466-15b063b8544a"</span><span class="token punctuation">,</span><span class="token property">"state"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token property">"tag"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span><span class="token property">"isHandle"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token property">"createDate"</span><span class="token operator">:</span> <span class="token number">1551669751334</span><span class="token punctuation">,</span><span class="token property">"eventId"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span><span class="token property">"corpusTagId"</span><span class="token operator">:</span> <span class="token string">"3335d2d8-a16e-46a2-9ed7-76739108d684"</span><span class="token punctuation">,</span><span class="token property">"intentName"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span><span class="token property">"ensureIntent"</span><span class="token operator">:</span> <span class="token string">"newIntent"</span><span class="token punctuation">,</span><span class="token property">"recommendIntent"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"setmsgnotifications"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"uploadTime"</span><span class="token operator">:</span> <span class="token number">1551669751333</span><span class="token punctuation">,</span><span class="token property">"w3account"</span><span class="token operator">:</span> <span class="token string">"x00286769"</span><span class="token punctuation">,</span><span class="token property">"createBy"</span><span class="token operator">:</span> <span class="token string">"x00286769"</span><span class="token punctuation">,</span><span class="token property">"intentCode"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span><span class="token property">"isBotSupport"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token property">"userRole"</span><span class="token operator">:</span> <span class="token string">"0"</span><span class="token punctuation">,</span><span class="token property">"welinkVersion"</span><span class="token operator">:</span> <span class="token string">"3.9.13"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"pagination"</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token property">"pageCount"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token property">"pageSizes"</span><span class="token operator">:</span> <span class="token number">50</span><span class="token punctuation">,</span><span class="token property">"pageNumber"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token property">"offset"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token property">"pageTotal"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token property">"pageNumbers"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token property">"pageSize"</span><span class="token operator">:</span> <span class="token number">50</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token property">"error"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span><span class="token property">"stack"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span><span class="token property">"message"</span><span class="token operator">:</span> <span class="token string">"ok"</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我的目标是对上述数据当中，字典中key “data” 对应的字典中的 “result” 中每一个item 的 “corpus” 进行提取，于是就有了下列代码。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># === Data loading === #</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>corpus <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> line <span class="token keyword">in</span> open<span class="token punctuation">(</span><span class="token string">"新意图语料.txt"</span><span class="token punctuation">,</span> <span class="token string">'r+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>eval<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    tmp <span class="token operator">=</span> data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'result'</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>tmp<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmp<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'corpus'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后是载入包含目标短文本的txt，也就是说该txt直接存储了上面的 “corpus” 对应的内容，但是每一行的内容都加上了双引号和逗号，就通过strip把这些不需要的部分去掉了，最后得到所有 “corpus” 组成的list。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> line <span class="token keyword">in</span> open<span class="token punctuation">(</span><span class="token string">"未识别语料.txt"</span><span class="token punctuation">,</span> <span class="token string">'r+'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>lstrip<span class="token punctuation">(</span><span class="token string">'"'</span><span class="token punctuation">)</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">'"'</span><span class="token punctuation">)</span>    corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-3-对文本进行分词，并记录词性"><a href="#2-3-对文本进行分词，并记录词性" class="headerlink" title="2.3 对文本进行分词，并记录词性"></a>2.3 对文本进行分词，并记录词性</h2><p>调用结巴词库对语料进行分词，并记录分词结果中每个词的词性。我的数据集在处理之后得到了5316条短文本，分词得到20640个不重复的词汇及其对应的词性，并建立了两者之间的字典联系。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># === Record the text cut and POS === #</span>part_of_speech <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>word_after_cut <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>cut_corpus_iter <span class="token operator">=</span> corpus<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>cut_corpus <span class="token operator">=</span> corpus<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    cut_corpus_iter<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> pseg<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 5316</span>    cut_corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">""</span>    <span class="token keyword">for</span> every <span class="token keyword">in</span> cut_corpus_iter<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>        cut_corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>cut_corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>every<span class="token punctuation">.</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        part_of_speech<span class="token punctuation">.</span>append<span class="token punctuation">(</span>every<span class="token punctuation">.</span>flag<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 20640</span>        word_after_cut<span class="token punctuation">.</span>append<span class="token punctuation">(</span>every<span class="token punctuation">.</span>word<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 20640</span>word_pos_dict <span class="token operator">=</span> <span class="token punctuation">{</span>word_after_cut<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span> part_of_speech<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>word_after_cut<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-4-文本向量化–TF-IDF权重"><a href="#2-4-文本向量化–TF-IDF权重" class="headerlink" title="2.4 文本向量化–TF-IDF权重"></a>2.4 文本向量化–TF-IDF权重</h2><p>使用TF-IDF对文本进行向量化，得到文本的TF-IDF权重。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># === Get the TF-IDF weights === #</span>Count_vectorizer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>transformer <span class="token operator">=</span> TfidfTransformer<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 用于统计每个词语的tf-idf权值</span>tf_idf <span class="token operator">=</span> transformer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>Count_vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>cut_corpus<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># （5316，2039）第一个fit_transform是计算tf-idf 第二个fit_transform是将文本转为词频矩阵</span>word <span class="token operator">=</span> Count_vectorizer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 2039，获取词袋模型中的所有词语</span>weight <span class="token operator">=</span> tf_idf<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># （5316，2039）将tf-idf矩阵抽取出来，元素w[i][j]表示j词在i类文本中的tf-idf权重</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-5-基于词性的新权重"><a href="#2-5-基于词性的新权重" class="headerlink" title="2.5 基于词性的新权重"></a>2.5 基于词性的新权重</h2><p>前面得到了分词的结果，并对词性进行了记录，接下来可以针对不同词汇的词性码，给与其TF-IDF权重以不同的乘数，这样可以突出某些类型的词汇的重要性，在一定程度上有助于聚类的效果。</p><p>具体的乘数构造规则可以根据需求自行调整。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># === Get new weight with POS considered === #</span>word_weight <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> word<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">not</span> <span class="token keyword">in</span> word_pos_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">continue</span>    <span class="token keyword">if</span> word_pos_dict<span class="token punctuation">[</span>word<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'n'</span><span class="token punctuation">:</span>        word_weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.2</span>    <span class="token keyword">elif</span> word_pos_dict<span class="token punctuation">[</span>word<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"vn"</span><span class="token punctuation">:</span>        word_weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.1</span>    <span class="token keyword">elif</span> word_pos_dict<span class="token punctuation">[</span>word<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"m"</span><span class="token punctuation">:</span>        word_weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 权重调整可以根据实际情况进行更改</span>        <span class="token keyword">continue</span>word_weight <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>word_weight<span class="token punctuation">)</span>new_weight <span class="token operator">=</span> weight<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        new_weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">*</span> word_weight<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-6-DBSCAN模型"><a href="#2-6-DBSCAN模型" class="headerlink" title="2.6 DBSCAN模型"></a>2.6 DBSCAN模型</h2><p>得到了文本的向量化表示之后就可以将其投喂到模型当中了，eps和min_samples都是可以调整的参数。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># === Fit the DBSCAN model and get the classify labels === #</span>DBS_clf <span class="token operator">=</span> DBSCAN<span class="token punctuation">(</span>eps<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> min_samples<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>DBS_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>new_weight<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>DBS_clf<span class="token punctuation">.</span>labels_<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-聚类结果"><a href="#3-聚类结果" class="headerlink" title="3. 聚类结果"></a>3. 聚类结果</h1><p>DBSCAN模型实现聚类之后，聚类的结果会存储在 <code>labels_</code> 中，将 <code>labels_</code> 与原来的文本一一对应，可以得到最终的聚类结果：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># === Define the function of classify the original corpus according to the labels === #</span><span class="token keyword">def</span> <span class="token function">labels_to_original</span><span class="token punctuation">(</span>labels<span class="token punctuation">,</span> original_corpus<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">assert</span> len<span class="token punctuation">(</span>labels<span class="token punctuation">)</span> <span class="token operator">==</span> len<span class="token punctuation">(</span>original_corpus<span class="token punctuation">)</span>    max_label <span class="token operator">=</span> max<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>    number_label <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> max_label <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    number_label<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>number_label<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        index <span class="token operator">=</span> number_label<span class="token punctuation">.</span>index<span class="token punctuation">(</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        result<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>original_corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">labels_original <span class="token operator">=</span> labels_to_original<span class="token punctuation">(</span>DBS_clf<span class="token punctuation">.</span>labels_<span class="token punctuation">,</span> corpus<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>labels_original<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 聚类结果展示（部分）    </span><span class="token punctuation">[</span><span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'社保卡。'</span><span class="token punctuation">,</span> <span class="token string">'社保卡办理'</span><span class="token punctuation">,</span> <span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'社保卡挂失'</span><span class="token punctuation">,</span> <span class="token string">'社保卡。'</span><span class="token punctuation">,</span> <span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'领取社保卡。'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'五险一金'</span><span class="token punctuation">,</span> <span class="token string">'五险一金。'</span><span class="token punctuation">,</span> <span class="token string">'五险一金。'</span><span class="token punctuation">,</span> <span class="token string">'五险一金介绍'</span><span class="token punctuation">,</span> <span class="token string">'看看二月份五险一金情况'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'打开汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'打开汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'我要办车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'等等邮件附件权限。'</span><span class="token punctuation">,</span> <span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'您好，请问怎样申请图片查看权限和邮件附件查看权限？'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="4-附件：完整代码"><a href="#4-附件：完整代码" class="headerlink" title="4 附件：完整代码"></a>4 附件：完整代码</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># === import packages === #</span><span class="token keyword">import</span> jieba<span class="token punctuation">.</span>posseg <span class="token keyword">as</span> pseg<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfTransformer<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> DBSCAN<span class="token comment" spellcheck="true"># === Data loading === #</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>corpus <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> line <span class="token keyword">in</span> open<span class="token punctuation">(</span><span class="token string">"新意图语料.txt"</span><span class="token punctuation">,</span> <span class="token string">'r+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>eval<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    tmp <span class="token operator">=</span> data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'result'</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>tmp<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmp<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'corpus'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">for</span> line <span class="token keyword">in</span> open<span class="token punctuation">(</span><span class="token string">"未识别语料.txt"</span><span class="token punctuation">,</span> <span class="token string">'r+'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>lstrip<span class="token punctuation">(</span><span class="token string">'"'</span><span class="token punctuation">)</span>    line <span class="token operator">=</span> line<span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">'"'</span><span class="token punctuation">)</span>    corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># === Record the text cut and POS === #</span>part_of_speech <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>word_after_cut <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>cut_corpus_iter <span class="token operator">=</span> corpus<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>cut_corpus <span class="token operator">=</span> corpus<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    cut_corpus_iter<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> pseg<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 5316</span>    cut_corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">""</span>    <span class="token keyword">for</span> every <span class="token keyword">in</span> cut_corpus_iter<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>        cut_corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>cut_corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>every<span class="token punctuation">.</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        part_of_speech<span class="token punctuation">.</span>append<span class="token punctuation">(</span>every<span class="token punctuation">.</span>flag<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 20640</span>        word_after_cut<span class="token punctuation">.</span>append<span class="token punctuation">(</span>every<span class="token punctuation">.</span>word<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 20640</span>word_pos_dict <span class="token operator">=</span> <span class="token punctuation">{</span>word_after_cut<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span> part_of_speech<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>word_after_cut<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span>  <span class="token comment" spellcheck="true"># === Get new weight with POS considered === #</span>word_weight <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> word<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">not</span> <span class="token keyword">in</span> word_pos_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">continue</span>    <span class="token keyword">if</span> word_pos_dict<span class="token punctuation">[</span>word<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'n'</span><span class="token punctuation">:</span>        word_weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.2</span>    <span class="token keyword">elif</span> word_pos_dict<span class="token punctuation">[</span>word<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"vn"</span><span class="token punctuation">:</span>        word_weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.1</span>    <span class="token keyword">elif</span> word_pos_dict<span class="token punctuation">[</span>word<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"m"</span><span class="token punctuation">:</span>        word_weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 权重调整可以根据实际情况进行更改</span>        <span class="token keyword">continue</span>word_weight <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>word_weight<span class="token punctuation">)</span>new_weight <span class="token operator">=</span> weight<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        new_weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> weight<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">*</span> word_weight<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># === Fit the DBSCAN model and get the classify labels === #</span>DBS_clf <span class="token operator">=</span> DBSCAN<span class="token punctuation">(</span>eps<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> min_samples<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>DBS_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>new_weight<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>DBS_clf<span class="token punctuation">.</span>labels_<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># === Define the function of classify the original corpus according to the labels === #</span><span class="token keyword">def</span> <span class="token function">labels_to_original</span><span class="token punctuation">(</span>labels<span class="token punctuation">,</span> original_corpus<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">assert</span> len<span class="token punctuation">(</span>labels<span class="token punctuation">)</span> <span class="token operator">==</span> len<span class="token punctuation">(</span>original_corpus<span class="token punctuation">)</span>    max_label <span class="token operator">=</span> max<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>    number_label <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> max_label <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    number_label<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>number_label<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        index <span class="token operator">=</span> number_label<span class="token punctuation">.</span>index<span class="token punctuation">(</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        result<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>original_corpus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> resultlabels_original <span class="token operator">=</span> labels_to_original<span class="token punctuation">(</span>DBS_clf<span class="token punctuation">.</span>labels_<span class="token punctuation">,</span> corpus<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>labels_original<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 聚类结果展示（部分）    </span><span class="token punctuation">[</span><span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'社保卡。'</span><span class="token punctuation">,</span> <span class="token string">'社保卡办理'</span><span class="token punctuation">,</span> <span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'社保卡挂失'</span><span class="token punctuation">,</span> <span class="token string">'社保卡。'</span><span class="token punctuation">,</span> <span class="token string">'社保卡'</span><span class="token punctuation">,</span> <span class="token string">'领取社保卡。'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'五险一金'</span><span class="token punctuation">,</span> <span class="token string">'五险一金。'</span><span class="token punctuation">,</span> <span class="token string">'五险一金。'</span><span class="token punctuation">,</span> <span class="token string">'五险一金介绍'</span><span class="token punctuation">,</span> <span class="token string">'看看二月份五险一金情况'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'打开汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'打开汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">,</span> <span class="token string">'我要汇钱。'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'我要办车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证。'</span><span class="token punctuation">,</span> <span class="token string">'车辆通行证'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'等等邮件附件权限。'</span><span class="token punctuation">,</span> <span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'邮件附件权限'</span><span class="token punctuation">,</span> <span class="token string">'您好，请问怎样申请图片查看权限和邮件附件查看权限？'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      DBSCAN
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="DBSCAN" scheme="https://dataquaner.github.io/tags/DBSCAN/"/>
    
  </entry>
  
  <entry>
    <title>机器学习系列之决策树算法(08):梯度提升树算法LightGBM</title>
    <link href="https://dataquaner.github.io/2020/01/07/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-08-ti-du-ti-sheng-shu-suan-fa-lightgbm/"/>
    <id>https://dataquaner.github.io/2020/01/07/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-08-ti-du-ti-sheng-shu-suan-fa-lightgbm/</id>
    <published>2020-01-07T02:30:00.000Z</published>
    <updated>2020-04-11T11:33:39.995Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-LightGBM简介"><a href="#1-LightGBM简介" class="headerlink" title="1. LightGBM简介"></a>1. LightGBM简介</h1><p>GBDT (Gradient Boosting Decision Tree) 是机器学习中一个长盛不衰的模型，其主要思想是利用弱分类器（决策树）迭代训练以得到最优模型，该模型具有训练效果好、不易过拟合等优点。GBDT不仅在工业界应用广泛，通常被用于多分类、点击率预测、搜索排序等任务；在各种数据挖掘竞赛中也是致命武器，据统计Kaggle上的比赛有一半以上的冠军方案都是基于GBDT。而LightGBM（Light Gradient Boosting Machine）是一个实现GBDT算法的框架，支持高效率的并行训练，并且具有更快的训练速度、更低的内存消耗、更好的准确率、支持分布式可以快速处理海量数据等优点。</p><h2 id="1-1-LightGBM提出的动机"><a href="#1-1-LightGBM提出的动机" class="headerlink" title="1.1 LightGBM提出的动机"></a>1.1 LightGBM提出的动机</h2><p>常用的机器学习算法，例如神经网络等算法，都可以以mini-batch的方式训练，训练数据的大小不会受到内存限制。而GBDT在每一次迭代的时候，都需要遍历整个训练数据多次。如果把整个训练数据装进内存则会限制训练数据的大小；如果不装进内存，反复地读写训练数据又会消耗非常大的时间。尤其面对工业级海量的数据，普通的GBDT算法是不能满足其需求的。</p><p>LightGBM提出的主要原因就是为了解决GBDT在海量数据遇到的问题，让GBDT可以更好更快地用于工业实践。</p><h2 id="1-2-XGBoost的缺点及LightGBM的优化"><a href="#1-2-XGBoost的缺点及LightGBM的优化" class="headerlink" title="1.2 XGBoost的缺点及LightGBM的优化"></a>1.2 XGBoost的缺点及LightGBM的优化</h2><h3 id="（1）XGBoost的缺点"><a href="#（1）XGBoost的缺点" class="headerlink" title="（1）XGBoost的缺点"></a>（1）XGBoost的缺点</h3><p>在LightGBM提出之前，最有名的GBDT工具就是XGBoost了，它是基于预排序方法的决策树算法。这种构建决策树的算法基本思想是：</p><blockquote><p>首先，对所有特征都按照特征的数值进行<strong>预排序</strong>。</p><p>其次，在遍历分割点的时候用的代价找到一个特征上的<strong>最好分割点</strong>。</p><p>最后，在找到一个特征的最好分割点后，将数据分裂成<strong>左右子节点</strong>。</p></blockquote><p>这样的预排序算法的优点是能精确地找到分割点。但是缺点也很明显：</p><blockquote><p>首先，空间消耗大。这样的算法需要保存数据的特征值，还保存了特征排序的结果（例如，为了后续快速的计算分割点，保存了排序后的索引），这就需要消耗训练数据两倍的内存。</p><p>其次，时间上也有较大的开销，在遍历每一个分割点的时候，都需要进行分裂增益的计算，消耗的代价大。</p><p>最后，对cache优化不友好。在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss。</p></blockquote><h3 id="（2）LightGBM的优化"><a href="#（2）LightGBM的优化" class="headerlink" title="（2）LightGBM的优化"></a>（2）LightGBM的优化</h3><p>为了避免上述XGBoost的缺陷，并且能够在不损害准确率的条件下加快GBDT模型的训练速度，lightGBM在传统的GBDT算法上进行了如下优化：</p><ul><li>基于Histogram的决策树算法。</li><li>单边梯度采样 Gradient-based One-Side Sampling(GOSS)：使用GOSS可以减少大量只具有小梯度的数据实例，这样在计算信息增益的时候只利用剩下的具有高梯度的数据就可以了，相比XGBoost遍历所有特征值节省了不少时间和空间上的开销。</li><li>互斥特征捆绑 Exclusive Feature Bundling(EFB)：使用EFB可以将许多互斥的特征绑定为一个特征，这样达到了降维的目的。</li><li>带深度限制的Leaf-wise的叶子生长策略：大多数GBDT工具使用低效的按层生长 (level-wise) 的决策树生长策略，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销。实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。LightGBM使用了带有深度限制的按叶子生长 (leaf-wise) 算法。</li><li>直接支持类别特征(Categorical Feature)</li><li>支持高效并行</li><li>Cache命中率优化</li></ul><p>下面我们就详细介绍以上提到的lightGBM优化算法。</p><h1 id="2-LightGBM的基本原理"><a href="#2-LightGBM的基本原理" class="headerlink" title="2. LightGBM的基本原理"></a>2. LightGBM的基本原理</h1><h2 id="2-1-基于Histogram的决策树算法"><a href="#2-1-基于Histogram的决策树算法" class="headerlink" title="2.1 基于Histogram的决策树算法"></a>2.1 基于Histogram的决策树算法</h2><h3 id="（1）直方图算法"><a href="#（1）直方图算法" class="headerlink" title="（1）直方图算法"></a>（1）直方图算法</h3><p>Histogram algorithm应该翻译为直方图算法，直方图算法的基本思想是：</p><blockquote><p>先把连续的浮点特征值离散化成 k个整数，同时构造一个宽度为 k 的 直方图。在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点。</p></blockquote><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnwCicKXgHhvyufUDOaWKtOMvGHTnOp7qty1WdDzoCibZ6613YRCngqLjg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="直方图算法"></p><p>图：直方图算法</p><p>直方图算法简单理解为：</p><blockquote><p>首先确定对于每一个特征需要多少个箱子（bin）并为每一个箱子分配一个整数；</p><p>然后将浮点数的范围均分成若干区间，区间个数与箱子个数相等，将属于该箱子的样本数据更新为箱子的值；</p><p>最后用直方图（#bins）表示。看起来很高大上，其实就是直方图统计，将大规模的数据放在了直方图中。</p></blockquote><p>我们知道特征离散化具有很多优点，如存储方便、运算更快、鲁棒性强、模型更加稳定等。对于直方图算法来说最直接的有以下两个优点：</p><ul><li><strong>内存占用更小：</strong> 直方图算法不仅不需要额外存储预排序的结果，而且可以只保存特征离散化后的值，而这个值一般用8位整型存储就足够了，内存消耗可以降低为原来的1/8 。也就是说XGBoost需要用32位的浮点数去存储特征值，并用32位的整形去存储索引，而 LightGBM只需要用8位去存储直方图，内存相当于减少为 ；</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnXTiclyL79CUh8dTMCllo4QEbHTHSqDRxaia9ke6UZicdticGPMpBfOJoIQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>图：内存占用优化为预排序算法的1/8</p><ul><li><strong>计算代价更小：</strong> 预排序算法XGBoost每遍历一个特征值就需要计算一次分裂的增益，而直方图算法LightGBM只需要计算 k次（ 可以认为是常数），直接将时间复杂度从O(#data * #feature )降低到 O(k * #feature )，而我们知道#data &gt;&gt;k。</li></ul><p>当然，Histogram算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。但在不同的数据集上的结果表明，离散化的分割点对最终的精度影响并不是很大，甚至有时候会更好一点。原因是决策树本来就是弱模型，分割点是不是精确并不是太重要；较粗的分割点也有正则化的效果，可以有效地防止过拟合；即使单棵树的训练误差比精确分割的算法稍大，但在梯度提升（Gradient Boosting）的框架下没有太大的影响。</p><h3 id="（2）直方图做差加速"><a href="#（2）直方图做差加速" class="headerlink" title="（2）直方图做差加速"></a>（2）直方图做差加速</h3><p>LightGBM另一个优化是Histogram（直方图）做差加速。一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到，在速度上可以提升一倍。通常构造直方图时，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的k个桶。在实际构建树的过程中，LightGBM还可以先计算直方图小的叶子节点，然后利用直方图做差来获得直方图大的叶子节点，这样就可以用非常微小的代价得到它兄弟叶子的直方图。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnJftGtGmKibGV4OycNSiaE6YcAjONvEh9aglgOzCNAl75kia3QzF6Nc4Og/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图：直方图做差"></p><p><strong>注意：</strong> XGBoost 在进行预排序时只考虑非零值进行加速，而 LightGBM 也采用类似策略：只用非零特征构建直方图。</p><h2 id="2-2-带深度限制的-Leaf-wise-算法"><a href="#2-2-带深度限制的-Leaf-wise-算法" class="headerlink" title="2.2 带深度限制的 Leaf-wise 算法"></a>2.2 带深度限制的 Leaf-wise 算法</h2><p>在Histogram算法之上，LightGBM进行进一步的优化。首先它抛弃了大多数GBDT工具使用的按层生长 (level-wise) 的决策树生长策略，而使用了带有深度限制的按叶子生长 (leaf-wise) 算法。</p><p>XGBoost 采用 Level-wise 的增长策略，该策略遍历一次数据可以同时分裂同一层的叶子，容易进行多线程优化，也好控制模型复杂度，不容易过拟合。但实际上Level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，实际上很多叶子的分裂增益较低，没必要进行搜索和分裂，因此带来了很多没必要的计算开销。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnZKttaTX2iajSgicfL5jMIsgFEiad6yk28rJClIwtH9abX9gmMQj0l5fJg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图：按层生长的决策树"></p><p>LightGBM采用Leaf-wise的增长策略，该策略每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，Leaf-wise的优点是：在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度；Leaf-wise的缺点是：可能会长出比较深的决策树，产生过拟合。因此LightGBM会在Leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnwT3h60X31B6gLFlw9Dhh5z81OicEBrmbFkqrcQuL0soSogOazr882bg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图：按叶子生长的决策树"></p><h2 id="2-3-单边梯度采样算法"><a href="#2-3-单边梯度采样算法" class="headerlink" title="2.3 单边梯度采样算法"></a>2.3 单边梯度采样算法</h2><p>Gradient-based One-Side Sampling 应该被翻译为单边梯度采样（GOSS）。GOSS算法从减少样本的角度出发，排除大部分小梯度的样本，仅用剩下的样本计算信息增益，它是一种在减少数据量和保证精度上平衡的算法。</p><p>AdaBoost中，样本权重是数据重要性的指标。然而在GBDT中没有原始样本权重，不能应用权重采样。幸运的是，我们观察到GBDT中每个数据都有不同的梯度值，对采样十分有用。即梯度小的样本，训练误差也比较小，说明数据已经被模型学习得很好了，直接想法就是丢掉这部分梯度小的数据。然而这样做会改变数据的分布，将会影响训练模型的精确度，为了避免此问题，提出了GOSS算法。</p><p>GOSS是一个样本的采样算法，目的是丢弃一些对计算信息增益没有帮助的样本留下有帮助的。根据计算信息增益的定义，梯度大的样本对信息增益有更大的影响。因此，GOSS在进行数据采样的时候只保留了梯度较大的数据，但是如果直接将所有梯度较小的数据都丢弃掉势必会影响数据的总体分布。所以，GOSS首先将要进行分裂的特征的所有取值按照绝对值大小降序排序（XGBoost一样也进行了排序，但是LightGBM不用保存排序后的结果），选取绝对值最大的 个数据。然后在剩下的较小梯度数据中随机选择 个数据。接着将这 个数据乘以一个常数 ，这样算法就会更关注训练不足的样本，而不会过多改变原数据集的分布。最后使用这 个数据来计算信息增益。下图是GOSS的具体算法。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnxhBz107Qv6GDvoWZVdFk3VJCy9Iq5nzwsZPkCANyvC9cNdySWpDhWQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图：单边梯度采样算法"></p><h2 id="2-4-互斥特征捆绑算法"><a href="#2-4-互斥特征捆绑算法" class="headerlink" title="2.4 互斥特征捆绑算法"></a>2.4 互斥特征捆绑算法</h2><p>高维度的数据往往是稀疏的，这种稀疏性启发我们设计一种无损的方法来减少特征的维度。通常被捆绑的特征都是互斥的（即特征不会同时为非零值，像one-hot），这样两个特征捆绑起来才不会丢失信息。如果两个特征并不是完全互斥（部分情况下两个特征都是非零值），可以用一个指标对特征不互斥程度进行衡量，称之为冲突比率，当这个值较小时，我们可以选择把不完全互斥的两个特征捆绑，而不影响最后的精度。互斥特征捆绑算法（Exclusive Feature Bundling, EFB）指出如果将一些特征进行融合绑定，则可以降低特征数量。这样在构建直方图时的时间复杂度从 变为 ，这里 指特征融合绑定后特征包的个数，且 远小于 。</p><p>针对这种想法，我们会遇到两个问题：</p><ul><li>怎么判定哪些特征应该绑在一起（build bundled）？</li><li>怎么把特征绑为一个（merge feature）？</li></ul><h3 id="（1）解决哪些特征应该绑在一起"><a href="#（1）解决哪些特征应该绑在一起" class="headerlink" title="（1）解决哪些特征应该绑在一起"></a>（1）解决哪些特征应该绑在一起</h3><p>将相互独立的特征进行绑定是一个 NP-Hard 问题，LightGBM的EFB算法将这个问题转化为图着色的问题来求解，将所有的特征视为图的各个顶点，将不是相互独立的特征用一条边连接起来，边的权重就是两个相连接的特征的总冲突值，这样需要绑定的特征就是在图着色问题中要涂上同一种颜色的那些点（特征）。此外，我们注意到通常有很多特征，尽管不是％相互排斥，但也很少同时取非零值。如果我们的算法可以允许一小部分的冲突，我们可以得到更少的特征包，进一步提高计算效率。经过简单的计算，随机污染小部分特征值将影响精度最多 ， 是每个绑定中的最大冲突比率，当其相对较小时，能够完成精度和效率之间的平衡。具体步骤可以总结如下：</p><ol><li>构造一个加权无向图，顶点是特征，边有权重，其权重与两个特征间冲突相关；</li><li>根据节点的度进行降序排序，度越大，与其它特征的冲突越大；</li><li>遍历每个特征，将它分配给现有特征包，或者新建一个特征包，使得总体冲突最小。</li></ol><p>算法允许两两特征并不完全互斥来增加特征捆绑的数量，通过设置最大冲突比率 来平衡算法的精度和效率。EFB 算法的伪代码如下所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnibV09sDI2NasyH6cbofAZ26FmibiaXxnDo78qHfeoFc9X1waibNYLhAo7A/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图：贪心绑定算法"></p><p>算法3的时间复杂度是 ，训练之前只处理一次，其时间复杂度在特征不是特别多的情况下是可以接受的，但难以应对百万维度的特征。为了继续提高效率，LightGBM提出了一种更加高效的无图的排序策略：将特征按照非零值个数排序，这和使用图节点的度排序相似，因为更多的非零值通常会导致冲突，新算法在算法3基础上改变了排序策略。</p><h3 id="（2）解决怎么把特征绑为一捆"><a href="#（2）解决怎么把特征绑为一捆" class="headerlink" title="（2）解决怎么把特征绑为一捆"></a>（2）解决怎么把特征绑为一捆</h3><p>特征合并算法，其关键在于原始特征能从合并的特征中分离出来。绑定几个特征在同一个bundle里需要保证绑定前的原始特征的值可以在bundle中识别，考虑到histogram-based算法将连续的值保存为离散的bins，我们可以使得不同特征的值分到bundle中的不同bin（箱子）中，这可以通过在特征值中加一个偏置常量来解决。比如，我们在bundle中绑定了两个特征A和B，A特征的原始取值为区间 ，B特征的原始取值为区间，我们可以在B特征的取值上加一个偏置常量，将其取值范围变为，绑定后的特征取值范围为 ，这样就可以放心的融合特征A和B了。具体的特征合并算法如下所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnutkSNWGiaNTSXibPu6tY7Os5LeTnycfzXyd1BXX9oib6sVia4nHZxj4uSw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图：特征合并算法"></p><h1 id="3-LightGBM的工程优化"><a href="#3-LightGBM的工程优化" class="headerlink" title="3. LightGBM的工程优化"></a>3. LightGBM的工程优化</h1><p>我们将论文《Lightgbm: A highly efficient gradient boosting decision tree》中没有提到的优化方案，而在其相关论文《A communication-efficient parallel algorithm for decision tree》中提到的优化方案，放到本节作为LightGBM的工程优化来向大家介绍。</p><h2 id="3-1-直接支持类别特征"><a href="#3-1-直接支持类别特征" class="headerlink" title="3.1 直接支持类别特征"></a>3.1 直接支持类别特征</h2><p>实际上大多数机器学习工具都无法直接支持类别特征，一般需要把类别特征，通过 one-hot 编码，转化到多维的特征，降低了空间和时间的效率。但我们知道对于决策树来说并不推荐使用 one-hot 编码，尤其当类别特征中类别个数很多的情况下，会存在以下问题：</p><ul><li>会产生样本切分不平衡问题，导致切分增益非常小（即浪费了这个特征）。使用 one-hot编码，意味着在每一个决策节点上只能使用one vs rest（例如是不是狗，是不是猫等）的切分方式。例如，动物类别切分后，会产生是否狗，是否猫等一系列特征，这一系列特征上只有少量样本为1 ，大量样本为 0，这时候切分样本会产生不平衡，这意味着切分增益也会很小。较小的那个切分样本集，它占总样本的比例太小，无论增益多大，乘以该比例之后几乎可以忽略；较大的那个拆分样本集，它几乎就是原始的样本集，增益几乎为零。比较直观的理解就是不平衡的切分和不切分没有区别。</li><li>会影响决策树的学习。因为就算可以对这个类别特征进行切分，独热编码也会把数据切分到很多零散的小空间上，如下图左边所示。而决策树学习时利用的是统计信息，在这些数据量小的空间上，统计信息不准确，学习效果会变差。但如果使用下图右边的切分方法，数据会被切分到两个比较大的空间，进一步的学习也会更好。下图右边叶子节点的含义是或者放到左孩子，其余放到右孩子。</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnIjV8dicRWyoeRWTiayd7Y7ZDUibN47IuzOOaFV8hfjpmDjpSeLSxCyLLw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>图：左图为基于 one-hot 编码进行分裂，右图为 LightGBM 基于 many-vs-many 进行分裂</p><p>而类别特征的使用在实践中是很常见的。且为了解决one-hot编码处理类别特征的不足，LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外的展开。LightGBM采用 many-vs-many 的切分方式将类别特征分为两个子集，实现类别特征的最优切分。假设某维特征有 个类别，则有 种可能，时间复杂度为 ，LightGBM 基于 Fisher的《On Grouping For Maximum Homogeneity》论文实现了 的时间复杂度。</p><p>算法流程如下图所示，在枚举分割点之前，先把直方图按照每个类别对应的label均值进行排序；然后按照排序的结果依次枚举最优分割点。从下图可以看到， 为类别的均值。当然，这个方法很容易过拟合，所以LightGBM里面还增加了很多对于这个方法的约束和正则化。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnyEyRiaYAe6iaMpstC2KzEMyP5G3akoJNTAZ7t69fBokqOeZwznhPGq7Q/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>图：LightGBM求解类别特征的最优切分算法</p><p>在Expo数据集上的实验结果表明，相比展开的方法，使用LightGBM支持的类别特征可以使训练速度加速倍，并且精度一致。更重要的是，LightGBM是第一个直接支持类别特征的GBDT工具。</p><h2 id="3-2-支持高效并行"><a href="#3-2-支持高效并行" class="headerlink" title="3.2 支持高效并行"></a>3.2 支持高效并行</h2><h3 id="（1）特征并行"><a href="#（1）特征并行" class="headerlink" title="（1）特征并行"></a>（1）特征并行</h3><p>特征并行的主要思想是不同机器在不同的特征集合上分别寻找最优的分割点，然后在机器间同步最优的分割点。XGBoost使用的就是这种特征并行方法。这种特征并行方法有个很大的缺点：就是对数据进行垂直划分，每台机器所含数据不同，然后使用不同机器找到不同特征的最优分裂点，划分结果需要通过通信告知每台机器，增加了额外的复杂度。</p><p>LightGBM 则不进行数据垂直划分，而是在每台机器上保存全部训练数据，在得到最佳划分方案后可在本地执行划分而减少了不必要的通信。具体过程如下图所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnOoy04GLlKxTI9EqajtYApyiaUwnSaSrQIGBSQtGH2sUEjCMibz7msiapw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图：特征并行"></p><h3 id="（2）数据并行"><a href="#（2）数据并行" class="headerlink" title="（2）数据并行"></a>（2）数据并行</h3><p>传统的数据并行策略主要为水平划分数据，让不同的机器先在本地构造直方图，然后进行全局的合并，最后在合并的直方图上面寻找最优分割点。这种数据划分有一个很大的缺点：通讯开销过大。如果使用点对点通信，一台机器的通讯开销大约为 ；如果使用集成的通信，则通讯开销为 。</p><p>LightGBM在数据并行中使用分散规约 (Reduce scatter) 把直方图合并的任务分摊到不同的机器，降低通信和计算，并利用直方图做差，进一步减少了一半的通信量。具体过程如下图所示。</p><p><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="img"></p><p>图：数据并行</p><h3 id="（3）投票并行"><a href="#（3）投票并行" class="headerlink" title="（3）投票并行"></a>（3）投票并行</h3><p>基于投票的数据并行则进一步优化数据并行中的通信代价，使通信代价变成常数级别。在数据量很大的时候，使用投票并行的方式只合并部分特征的直方图从而达到降低通信量的目的，可以得到非常好的加速效果。具体过程如下图所示。</p><p>大致步骤为两步：</p><ol><li>本地找出 Top K 特征，并基于投票筛选出可能是最优分割点的特征；</li><li>合并时只合并每个机器选出来的特征。</li></ol><p><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="img"></p><p>图：投票并行</p><h2 id="3-3-Cache命中率优化"><a href="#3-3-Cache命中率优化" class="headerlink" title="3.3 Cache命中率优化"></a>3.3 Cache命中率优化</h2><p>XGBoost对cache优化不友好，如下图所示。在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss。为了解决缓存命中率低的问题，XGBoost 提出了缓存访问算法进行改进。</p><p><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="img"></p><p>图：随机访问会造成cache miss</p><p>而 LightGBM 所使用直方图算法对 Cache 天生友好：</p><ul><li>首先，所有的特征都采用相同的方式获得梯度（区别于XGBoost的不同特征通过不同的索引获得梯度），只需要对梯度进行排序并可实现连续访问，大大提高了缓存命中率；</li><li>其次，因为不需要存储行索引到叶子索引的数组，降低了存储消耗，而且也不存在 Cache Miss的问题。</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnrdNfRmcoo5BTWT9mrzpepqrD3znib63F2aBy8icHcMsx5DCLQUdia7jdg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>图：LightGBM增加缓存命中率</p><h1 id="4-LightGBM的优缺点"><a href="#4-LightGBM的优缺点" class="headerlink" title="4. LightGBM的优缺点"></a>4. LightGBM的优缺点</h1><h2 id="4-1-优点"><a href="#4-1-优点" class="headerlink" title="4.1 优点"></a>4.1 优点</h2><p>这部分主要总结下 LightGBM 相对于 XGBoost 的优点，从内存和速度两方面进行介绍。</p><h3 id="（1）速度更快"><a href="#（1）速度更快" class="headerlink" title="（1）速度更快"></a>（1）速度更快</h3><ul><li>LightGBM 采用了直方图算法将遍历样本转变为遍历直方图，极大的降低了时间复杂度；</li><li>LightGBM 在训练过程中采用单边梯度算法过滤掉梯度小的样本，减少了大量的计算；</li><li>LightGBM 采用了基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；</li><li>LightGBM 采用优化后的特征并行、数据并行方法加速计算，当数据量非常大的时候还可以采用投票并行的策略；</li><li>LightGBM 对缓存也进行了优化，增加了缓存命中率；</li></ul><h3 id="（2）内存更小"><a href="#（2）内存更小" class="headerlink" title="（2）内存更小"></a>（2）内存更小</h3><ul><li>XGBoost使用预排序后需要记录特征值及其对应样本的统计值的索引，而 LightGBM 使用了直方图算法将特征值转变为 bin 值，且不需要记录特征到样本的索引，将空间复杂度从 降低为 ，极大的减少了内存消耗；</li><li>LightGBM 采用了直方图算法将存储特征值转变为存储 bin 值，降低了内存消耗；</li><li>LightGBM 在训练过程中采用互斥特征捆绑算法减少了特征数量，降低了内存消耗。</li></ul><h2 id="4-2-缺点"><a href="#4-2-缺点" class="headerlink" title="4.2 缺点"></a>4.2 缺点</h2><ul><li>可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度限制，在保证高效率的同时防止过拟合；</li><li>Boosting族是迭代算法，每一次迭代都根据上一次迭代的预测结果对样本进行权重调整，所以随着迭代不断进行，误差会越来越小，模型的偏差（bias）会不断降低。由于LightGBM是基于偏差的算法，所以会对噪点较为敏感；</li><li>在寻找最优解时，依据的是最优切分变量，没有将最优解是全部特征的综合这一理念考虑进去；</li></ul><h1 id="5-LightGBM实例"><a href="#5-LightGBM实例" class="headerlink" title="5. LightGBM实例"></a>5. LightGBM实例</h1><p>本篇文章所有数据集和代码均在我的GitHub中，地址：<a href="https://github.com/Microstrong0305/WeChat-zhihu-csdnblog-code/tree/master/Ensemble%20Learning/LightGBM" target="_blank" rel="noopener">https://github.com/Microstrong0305/WeChat-zhihu-csdnblog-code/tree/master/Ensemble%20Learning/LightGBM</a></p><h2 id="5-1-安装LightGBM依赖包"><a href="#5-1-安装LightGBM依赖包" class="headerlink" title="5.1 安装LightGBM依赖包"></a>5.1 安装LightGBM依赖包</h2><pre class="line-numbers language-shell"><code class="language-shell">pip install lightgbm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-2-LightGBM分类和回归"><a href="#5-2-LightGBM分类和回归" class="headerlink" title="5.2 LightGBM分类和回归"></a>5.2 LightGBM分类和回归</h2><p>LightGBM有两大类接口：LightGBM原生接口 和 scikit-learn接口 ，并且LightGBM能够实现分类和回归两种任务。</p><h3 id="（1）基于LightGBM原生接口的分类"><a href="#（1）基于LightGBM原生接口的分类" class="headerlink" title="（1）基于LightGBM原生接口的分类"></a>（1）基于LightGBM原生接口的分类</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> lightgbm <span class="token keyword">as</span> lgb<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_auc_score<span class="token punctuation">,</span> accuracy_score<span class="token comment" spellcheck="true"># 加载数据</span>iris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 划分训练集和测试集</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 转换为Dataset数据格式</span>train_data <span class="token operator">=</span> lgb<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> label<span class="token operator">=</span>y_train<span class="token punctuation">)</span>validation_data <span class="token operator">=</span> lgb<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> label<span class="token operator">=</span>y_test<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 参数</span>params <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>    <span class="token string">'lambda_l1'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>    <span class="token string">'lambda_l2'</span><span class="token punctuation">:</span> <span class="token number">0.2</span><span class="token punctuation">,</span>    <span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span>    <span class="token string">'objective'</span><span class="token punctuation">:</span> <span class="token string">'multiclass'</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 目标函数</span>    <span class="token string">'num_class'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true"># 模型训练</span>gbm <span class="token operator">=</span> lgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>params<span class="token punctuation">,</span> train_data<span class="token punctuation">,</span> valid_sets<span class="token operator">=</span><span class="token punctuation">[</span>validation_data<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 模型预测</span>y_pred <span class="token operator">=</span> gbm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>y_pred <span class="token operator">=</span> <span class="token punctuation">[</span>list<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>index<span class="token punctuation">(</span>max<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> y_pred<span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 模型评估</span><span class="token keyword">print</span><span class="token punctuation">(</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="（2）基于Scikit-learn接口的分类"><a href="#（2）基于Scikit-learn接口的分类" class="headerlink" title="（2）基于Scikit-learn接口的分类"></a>（2）基于Scikit-learn接口的分类</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> lightgbm <span class="token keyword">import</span> LGBMClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>externals <span class="token keyword">import</span> joblib<span class="token comment" spellcheck="true"># 加载数据</span>iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>data <span class="token operator">=</span> iris<span class="token punctuation">.</span>datatarget <span class="token operator">=</span> iris<span class="token punctuation">.</span>target<span class="token comment" spellcheck="true"># 划分训练数据和测试数据</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 模型训练</span>gbm <span class="token operator">=</span> LGBMClassifier<span class="token punctuation">(</span>num_leaves<span class="token operator">=</span><span class="token number">31</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> n_estimators<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>gbm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> eval_set<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> early_stopping_rounds<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 模型存储</span>joblib<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>gbm<span class="token punctuation">,</span> <span class="token string">'loan_model.pkl'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 模型加载</span>gbm <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'loan_model.pkl'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 模型预测</span>y_pred <span class="token operator">=</span> gbm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> num_iteration<span class="token operator">=</span>gbm<span class="token punctuation">.</span>best_iteration_<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 模型评估</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The accuracy of prediction is:'</span><span class="token punctuation">,</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 特征重要度</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Feature importances:'</span><span class="token punctuation">,</span> list<span class="token punctuation">(</span>gbm<span class="token punctuation">.</span>feature_importances_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 网格搜索，参数优化</span>estimator <span class="token operator">=</span> LGBMClassifier<span class="token punctuation">(</span>num_leaves<span class="token operator">=</span><span class="token number">31</span><span class="token punctuation">)</span>param_grid <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">}</span>gbm <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span> param_grid<span class="token punctuation">)</span>gbm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Best parameters found by grid search are:'</span><span class="token punctuation">,</span> gbm<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="（3）基于LightGBM原生接口的回归"><a href="#（3）基于LightGBM原生接口的回归" class="headerlink" title="（3）基于LightGBM原生接口的回归"></a>（3）基于LightGBM原生接口的回归</h3><p>对于LightGBM解决回归问题，我们用Kaggle比赛中回归问题：House Prices: Advanced Regression Techniques，地址：<a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" target="_blank" rel="noopener">https://www.kaggle.com/c/house-prices-advanced-regression-techniques</a> 来进行实例讲解。</p><p>该房价预测的训练数据集中一共有81列，第一列是Id，最后一列是label，中间79列是特征。这79列特征中，有43列是分类型变量，33列是整数变量，3列是浮点型变量。训练数据集中存在缺失值。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">import</span> lightgbm <span class="token keyword">as</span> lgb<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_error<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> Imputer<span class="token comment" spellcheck="true"># 1.读文件</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./dataset/train.csv'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 2.切分数据输入：特征 输出：预测目标变量</span>y <span class="token operator">=</span> data<span class="token punctuation">.</span>SalePriceX <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select_dtypes<span class="token punctuation">(</span>exclude<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'object'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 3.切分训练集、测试集,切分比例7.5 : 2.5</span>train_X<span class="token punctuation">,</span> test_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">.</span>values<span class="token punctuation">,</span> y<span class="token punctuation">.</span>values<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 4.空值处理，默认方法：使用特征列的平均值进行填充</span>my_imputer <span class="token operator">=</span> Imputer<span class="token punctuation">(</span><span class="token punctuation">)</span>train_X <span class="token operator">=</span> my_imputer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>train_X<span class="token punctuation">)</span>test_X <span class="token operator">=</span> my_imputer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 5.转换为Dataset数据格式</span>lgb_train <span class="token operator">=</span> lgb<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>lgb_eval <span class="token operator">=</span> lgb<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_y<span class="token punctuation">,</span> reference<span class="token operator">=</span>lgb_train<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 6.参数</span>params <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'task'</span><span class="token punctuation">:</span> <span class="token string">'train'</span><span class="token punctuation">,</span>    <span class="token string">'boosting_type'</span><span class="token punctuation">:</span> <span class="token string">'gbdt'</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 设置提升类型</span>    <span class="token string">'objective'</span><span class="token punctuation">:</span> <span class="token string">'regression'</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 目标函数</span>    <span class="token string">'metric'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'l2'</span><span class="token punctuation">,</span> <span class="token string">'auc'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 评估函数</span>    <span class="token string">'num_leaves'</span><span class="token punctuation">:</span> <span class="token number">31</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 叶子节点数</span>    <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token number">0.05</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 学习速率</span>    <span class="token string">'feature_fraction'</span><span class="token punctuation">:</span> <span class="token number">0.9</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 建树的特征选择比例</span>    <span class="token string">'bagging_fraction'</span><span class="token punctuation">:</span> <span class="token number">0.8</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 建树的样本采样比例</span>    <span class="token string">'bagging_freq'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># k 意味着每 k 次迭代执行bagging</span>    <span class="token string">'verbose'</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token comment" spellcheck="true"># &lt;0 显示致命的, =0 显示错误 (警告), >0 显示信息</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true"># 7.调用LightGBM模型，使用训练集数据进行训练（拟合）</span><span class="token comment" spellcheck="true"># Add verbosity=2 to print messages while running boosting</span>my_model <span class="token operator">=</span> lgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>params<span class="token punctuation">,</span> lgb_train<span class="token punctuation">,</span> num_boost_round<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> valid_sets<span class="token operator">=</span>lgb_eval<span class="token punctuation">,</span> early_stopping_rounds<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 8.使用模型对测试集数据进行预测</span>predictions <span class="token operator">=</span> my_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> num_iteration<span class="token operator">=</span>my_model<span class="token punctuation">.</span>best_iteration<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 9.对模型的预测结果进行评判（平均绝对误差）</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="（4）基于Scikit-learn接口的回归"><a href="#（4）基于Scikit-learn接口的回归" class="headerlink" title="（4）基于Scikit-learn接口的回归"></a>（4）基于Scikit-learn接口的回归</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">import</span> lightgbm <span class="token keyword">as</span> lgb<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_error<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> Imputer<span class="token comment" spellcheck="true"># 1.读文件</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./dataset/train.csv'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 2.切分数据输入：特征 输出：预测目标变量</span>y <span class="token operator">=</span> data<span class="token punctuation">.</span>SalePriceX <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select_dtypes<span class="token punctuation">(</span>exclude<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'object'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 3.切分训练集、测试集,切分比例7.5 : 2.5</span>train_X<span class="token punctuation">,</span> test_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">.</span>values<span class="token punctuation">,</span> y<span class="token punctuation">.</span>values<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 4.空值处理，默认方法：使用特征列的平均值进行填充</span>my_imputer <span class="token operator">=</span> Imputer<span class="token punctuation">(</span><span class="token punctuation">)</span>train_X <span class="token operator">=</span> my_imputer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>train_X<span class="token punctuation">)</span>test_X <span class="token operator">=</span> my_imputer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 5.调用LightGBM模型，使用训练集数据进行训练（拟合）</span><span class="token comment" spellcheck="true"># Add verbosity=2 to print messages while running boosting</span>my_model <span class="token operator">=</span> lgb<span class="token punctuation">.</span>LGBMRegressor<span class="token punctuation">(</span>objective<span class="token operator">=</span><span class="token string">'regression'</span><span class="token punctuation">,</span> num_leaves<span class="token operator">=</span><span class="token number">31</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> n_estimators<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>                             verbosity<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>my_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 6.使用模型对测试集数据进行预测</span>predictions <span class="token operator">=</span> my_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 7.对模型的预测结果进行评判（平均绝对误差）</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="5-3-LightGBM调参"><a href="#5-3-LightGBM调参" class="headerlink" title="5.3 LightGBM调参"></a>5.3 LightGBM调参</h2><p>在上一部分中，LightGBM模型的参数有一部分进行了简单的设置，但大都使用了模型的默认参数，但默认参数并不是最好的。要想让LightGBM表现的更好，需要对LightGBM模型进行参数微调。下图展示的是回归模型需要调节的参数，分类模型需要调节的参数与此类似。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/rB4jswrswuy3ml2bDMRhOk4LzRVUVMnnXqMSrXo3fOt7NhvJnOKYEe0EXg7yOPGLr27tQdJUaPNoKAAF9P6frQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图：LightGBM回归模型调参"></p><h1 id="6-关于LightGBM若干问题的思考"><a href="#6-关于LightGBM若干问题的思考" class="headerlink" title="6. 关于LightGBM若干问题的思考"></a>6. 关于LightGBM若干问题的思考</h1><h2 id="6-1-LightGBM与XGBoost的联系和区别有哪些？"><a href="#6-1-LightGBM与XGBoost的联系和区别有哪些？" class="headerlink" title="6.1 LightGBM与XGBoost的联系和区别有哪些？"></a>6.1 LightGBM与XGBoost的联系和区别有哪些？</h2><p>（1）LightGBM使用了基于histogram的决策树算法，这一点不同于XGBoost中的贪心算法和近似算法，histogram算法在内存和计算代价上都有不小优势。1）内存上优势：很明显，直方图算法的内存消耗为 (因为对特征分桶后只需保存特征离散化之后的值)，而XGBoost的贪心算法内存消耗为： ，因为XGBoost既要保存原始feature的值，也要保存这个值的顺序索引，这些值需要位的浮点数来保存。2）计算上的优势：预排序算法在选择好分裂特征计算分裂收益时需要遍历所有样本的特征值，时间为，而直方图算法只需要遍历桶就行了，时间为。</p><p>（2）XGBoost采用的是level-wise的分裂策略，而LightGBM采用了leaf-wise的策略，区别是XGBoost对每一层所有节点做无差别分裂，可能有些节点的增益非常小，对结果影响不大，但是XGBoost也进行了分裂，带来了不必要的开销。leaft-wise的做法是在当前所有叶子节点中选择分裂收益最大的节点进行分裂，如此递归进行，很明显leaf-wise这种做法容易过拟合，因为容易陷入比较高的深度中，因此需要对最大深度做限制，从而避免过拟合。</p><p>（3）XGBoost在每一层都动态构建直方图，因为XGBoost的直方图算法不是针对某个特定的特征，而是所有特征共享一个直方图(每个样本的权重是二阶导)，所以每一层都要重新构建直方图，而LightGBM中对每个特征都有一个直方图，所以构建一次直方图就够了。</p><p>（4）LightGBM使用直方图做差加速，一个子节点的直方图可以通过父节点的直方图减去兄弟节点的直方图得到，从而加速计算。</p><p>（5）LightGBM支持类别特征，不需要进行独热编码处理。</p><p>（6）LightGBM优化了特征并行和数据并行算法，除此之外还添加了投票并行方案。</p><p>（7）LightGBM采用基于梯度的单边采样来减少训练样本并保持数据分布不变，减少模型因数据分布发生变化而造成的模型精度下降。</p><p>（8）特征捆绑转化为图着色问题，减少特征数量。</p><h1 id="7-Reference"><a href="#7-Reference" class="headerlink" title="7. Reference"></a>7. Reference</h1><p>由于参考的文献较多，我把每篇参考文献按照自己的学习思路，进行了详细的归类和标注。</p><p><strong>LightGBM论文解读：</strong></p><p>【1】Ke G, Meng Q, Finley T, et al. Lightgbm: A highly efficient gradient boosting decision tree[C]//Advances in Neural Information Processing Systems. 2017: 3146-3154.</p><p>【2】Taifeng Wang分享LightGBM的视频，地址：<a href="https://v.qq.com/x/page/k0362z6lqix.html" target="_blank" rel="noopener">https://v.qq.com/x/page/k0362z6lqix.html</a></p><p>【3】开源|LightGBM：三天内收获GitHub 1000+ 星，地址：<a href="https://mp.weixin.qq.com/s/M25d_43gHkk3FyG_Jhlvog" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/M25d_43gHkk3FyG_Jhlvog</a></p><p>【4】Lightgbm源论文解析：LightGBM: A Highly Efficient Gradient Boosting Decision Tree，地址：<a href="https://blog.csdn.net/anshuai_aw1/article/details/83048709" target="_blank" rel="noopener">https://blog.csdn.net/anshuai_aw1/article/details/83048709</a></p><p>【5】快的不要不要的lightGBM - 王乐的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/31986189" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31986189</a></p><p>【6】『 论文阅读』LightGBM原理-LightGBM: A Highly Efficient Gradient Boosting Decision Tree，地址：<a href="https://blog.csdn.net/shine19930820/article/details/79123216" target="_blank" rel="noopener">https://blog.csdn.net/shine19930820/article/details/79123216</a></p><p><strong>LightGBM算法讲解：</strong></p><p>【7】【机器学习】决策树（下）——XGBoost、LightGBM（非常详细） - 阿泽的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/87885678" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/87885678</a></p><p>【8】入门 | 从结构到性能，一文概述XGBoost、Light GBM和CatBoost的同与不同，地址：<a href="https://mp.weixin.qq.com/s/TD3RbdDidCrcL45oWpxNmw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/TD3RbdDidCrcL45oWpxNmw</a></p><p>【9】CatBoost vs. Light GBM vs. XGBoost，地址：<a href="https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db" target="_blank" rel="noopener">https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db</a></p><p>【10】机器学习算法之LightGBM，地址：<a href="https://www.biaodianfu.com/lightgbm.html" target="_blank" rel="noopener">https://www.biaodianfu.com/lightgbm.html</a></p><p><strong>LightGBM工程优化：</strong></p><p>【11】Meng Q, Ke G, Wang T, et al. A communication-efficient parallel algorithm for decision tree[C]//Advances in Neural Information Processing Systems. 2016: 1279-1287.</p><p>【12】Zhang H, Si S, Hsieh C J. GPU-acceleration for Large-scale Tree Boosting[J]. arXiv preprint arXiv:1706.08359, 2017.</p><p>【13】LightGBM的官方GitHub代码库，地址：<a href="https://github.com/microsoft/LightGBM" target="_blank" rel="noopener">https://github.com/microsoft/LightGBM</a></p><p>【14】关于sklearn中的决策树是否应该用one-hot编码？- 柯国霖的回答 - 知乎 <a href="https://www.zhihu.com/question/266195966/answer/306104444" target="_blank" rel="noopener">https://www.zhihu.com/question/266195966/answer/306104444</a></p><p><strong>LightGBM实例：</strong></p><p>【15】LightGBM使用，地址：<a href="https://bacterous.github.io/2018/09/13/LightGBM%E4%BD%BF%E7%94%A8/" target="_blank" rel="noopener">https://bacterous.github.io/2018/09/13/LightGBM%E4%BD%BF%E7%94%A8/</a></p><p>【16】LightGBM两种使用方式 ，地址：<a href="https://www.cnblogs.com/chenxiangzhen/p/10894306.html" target="_blank" rel="noopener">https://www.cnblogs.com/chenxiangzhen/p/10894306.html</a></p><p><strong>LightGBM若干问题的思考：</strong></p><p>【17】GBDT、XGBoost、LightGBM的区别和联系，地址：<a href="https://www.jianshu.com/p/765efe2b951a" target="_blank" rel="noopener">https://www.jianshu.com/p/765efe2b951a</a></p><p>【18】xgboost和lightgbm的区别和适用场景，地址：<a href="https://www.nowcoder.com/ta/review-ml/review?page=101" target="_blank" rel="noopener">https://www.nowcoder.com/ta/review-ml/review?page=101</a> </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      LightGBM
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="LightGBM" scheme="https://dataquaner.github.io/tags/LightGBM/"/>
    
  </entry>
  
  <entry>
    <title>机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战：原生接口和sklearn接口区别</title>
    <link href="https://dataquaner.github.io/2019/12/27/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-07-ti-du-ti-sheng-shu-suan-fa-xgboost-shi-zhan-yuan-sheng-jie-kou-he-sklearn-jie-kou-de-qu-bie/"/>
    <id>https://dataquaner.github.io/2019/12/27/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-07-ti-du-ti-sheng-shu-suan-fa-xgboost-shi-zhan-yuan-sheng-jie-kou-he-sklearn-jie-kou-de-qu-bie/</id>
    <published>2019-12-26T16:00:00.000Z</published>
    <updated>2020-04-11T11:33:22.949Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><h1 id="2-官方文档"><a href="#2-官方文档" class="headerlink" title="2 官方文档"></a>2 官方文档</h1><p><strong><a href="https://xgboost.readthedocs.io/en/latest/" target="_blank" rel="noopener">英文官方文档</a></strong></p><p><strong><a href="https://xgboost.apachecn.org/#/xgboost.apachecn.org" target="_blank" rel="noopener">中文文档</a></strong></p><h1 id="3-sklearn接口"><a href="#3-sklearn接口" class="headerlink" title="3 sklearn接口"></a>3 sklearn接口</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> xgboost<span class="token punctuation">.</span>sklearn <span class="token keyword">import</span> XGBClassifierxgbc <span class="token operator">=</span> XGBClassifier<span class="token punctuation">(</span>n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 新建xgboost sklearn的分类class</span><span class="token comment" spellcheck="true"># xgboost的sklearn接口默认只使用cpu单线程，设置n_jobs=-1使用所有线程</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"开始xgboost classifier训练"</span><span class="token punctuation">)</span>xgbc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_vector<span class="token punctuation">,</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_label<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 喂给分类器训练numpy形式的训练特征向量和标签向量</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"完成xgboost classifier训练，开始预测"</span><span class="token punctuation">)</span>pre_train_Classifier <span class="token operator">=</span> xgbc<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_vector<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 喂给分类器numpy形式的测试特征向量</span>np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span><span class="token string">"pre_train_Classifier.npy"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>pre_train_Classifier<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 保存结果</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>xgboost的sklearn接口，可以不经过标签标准化(即将标签编码为0~n_class-1)，直接喂给分类器特征向量和标签向量，使用fit训练后调用predict就能得到预测向量的预测标签，它会在内部调用sklearn.preprocessing.LabelEncoder()将标签在分类器使用时transform，在输出结果时inverse_transform。</p><p><strong>优点：使用简单，无需对标签进行标准化处理，直接得到预测标签；</strong></p><p><strong>缺点：在模型保存后重新载入，丢失LabelEncoder，不能增量训练只能用一次.</strong></p><h1 id="4-xgboost的原生接口"><a href="#4-xgboost的原生接口" class="headerlink" title="4 xgboost的原生接口"></a>4 xgboost的原生接口</h1><pre class="line-numbers language-python"><code class="language-python">vector_matrix<span class="token punctuation">,</span>label_single_new <span class="token operator">=</span> get_data<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 获取得到特征矩阵、标签向量</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"标签总数为：%d；数据量总数为：%d"</span><span class="token operator">%</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>list<span class="token punctuation">(</span>set<span class="token punctuation">(</span>label_single_new<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>vector_matrix<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 将标签标准化为0~class number-1,则xgboost概率最大的下标即为该位置数对应的标签</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessinglabel_coder <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>label_single_code <span class="token operator">=</span> label_coder<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>label_single_new<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 切割训练集、测试集</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_splittrain_matrix<span class="token punctuation">,</span>test_matrix<span class="token punctuation">,</span>train_label<span class="token punctuation">,</span>test_label <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>        vector_matrix<span class="token punctuation">,</span>label_single_code<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb<span class="token comment" spellcheck="true"># 参数设置见 http://www.huaxiaozhuan.com/%E5%B7%A5%E5%85%B7/xgboost/chapters/xgboost_usage.html</span>params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'booster'</span><span class="token punctuation">:</span> <span class="token string">'gbtree'</span><span class="token punctuation">,</span><span class="token string">'silent'</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span>                    <span class="token comment" spellcheck="true"># 如果为 0（默认值），则表示打印运行时的信息；如果为 1，则表示不打印这些信息</span><span class="token string">'objective'</span><span class="token punctuation">:</span> <span class="token string">'multi:softprob'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 基于softmax 的多分类模型，但是它的输出是一个矩阵：ndata*nclass，给出了每个样本属于每个类别的概率。</span><span class="token string">'num_class'</span><span class="token punctuation">:</span>len<span class="token punctuation">(</span>set<span class="token punctuation">(</span>label_single_new<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#指定类别数量</span><span class="token punctuation">}</span>dtrain <span class="token operator">=</span> xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>train_matrix<span class="token punctuation">,</span> label<span class="token operator">=</span>train_label<span class="token punctuation">,</span> nthread<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># xgboost原生接口需要使用DMatrix格式的数据，这里与sklearn接口不同</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"开始xgboost训练"</span><span class="token punctuation">)</span>xgbc <span class="token operator">=</span> xgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>params<span class="token punctuation">,</span>dtrain<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 初始化xgboost分类器，原生接口默认启用全部线程</span>xgbc<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span>model_path<span class="token operator">+</span>save_name<span class="token operator">+</span><span class="token string">'xgbc_0.9.model'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 保存模型 </span><span class="token comment" spellcheck="true"># =============================================================================</span><span class="token comment" spellcheck="true">#     xgbc = xgb.Booster()  # 重新载入模型</span><span class="token comment" spellcheck="true">#     xgbc.load_model(fname=model_path+save_name+'xgbc_0.9.model')</span><span class="token comment" spellcheck="true"># =============================================================================</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"xgboost训练完成，得到概率矩阵"</span><span class="token punctuation">)</span>pre_train <span class="token operator">=</span> xgbc<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>train_matrix<span class="token punctuation">,</span> nthread<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 训练数据的预测概率矩阵，启用全部线程</span>pre_test <span class="token operator">=</span> xgbc<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>test_matrix<span class="token punctuation">,</span> nthread<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true"># 测试数据的预测概率矩阵，启用全部线程</span><span class="token comment" spellcheck="true"># 概率矩阵各行的数据为各条数据的预测概率，各行数据之和为1；</span><span class="token comment" spellcheck="true"># 概率矩阵各行的下标即为标准化后的label标签(0~class number-1)</span><span class="token comment" spellcheck="true"># 数据保存</span>np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model_path<span class="token operator">+</span>save_name<span class="token operator">+</span><span class="token string">'pre_train.npy'</span><span class="token punctuation">,</span>pre_train<span class="token punctuation">)</span>np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model_path<span class="token operator">+</span>save_name<span class="token operator">+</span><span class="token string">'train_label.npy'</span><span class="token punctuation">,</span>train_label<span class="token punctuation">)</span>  np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model_path<span class="token operator">+</span>save_name<span class="token operator">+</span><span class="token string">'pre_test.npy'</span><span class="token punctuation">,</span>pre_test<span class="token punctuation">)</span>np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model_path<span class="token operator">+</span>save_name<span class="token operator">+</span><span class="token string">'test_label.npy'</span><span class="token punctuation">,</span>test_label<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 数据载入</span><span class="token comment" spellcheck="true"># =============================================================================</span><span class="token comment" spellcheck="true"># pre_train = np.load(model_path+save_name+'pre_train.npy') </span><span class="token comment" spellcheck="true"># train_label = np.load(model_path+save_name+'train_label.npy') </span><span class="token comment" spellcheck="true"># pre_test = np.load(model_path+save_name+'pre_test.npy') </span><span class="token comment" spellcheck="true"># test_label = np.load(model_path+save_name+'test_label.npy') </span><span class="token comment" spellcheck="true"># =============================================================================</span><span class="token comment" spellcheck="true"># narray_target.argsort(axis=1)，获得按行(排序对象为各行数值)升序后的下标矩阵，axis=0为按列升序;</span><span class="token comment" spellcheck="true"># np.fliplr(narray_target)获取矩阵的左右翻转，narray_target[::-1]获取矩阵的上下翻转</span><span class="token comment" spellcheck="true"># narray_target[:,-5:]获取矩阵的后5列;</span>top_k <span class="token operator">=</span> <span class="token number">5</span>  <span class="token comment" spellcheck="true"># 获取预测概率最大的5个标签</span><span class="token comment" spellcheck="true"># 获取概率矩阵排序信息，得到按行升序的下标矩阵,切割得到各行的后5个下标,</span><span class="token comment" spellcheck="true"># 将其左右翻转后，得到各行降序的前5个下标，即标准化后的标签</span>pre_test_index <span class="token operator">=</span> np<span class="token punctuation">.</span>fliplr<span class="token punctuation">(</span>pre_test<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">*</span>top_k<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>pre_test_label <span class="token operator">=</span> label_coder<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>pre_test_index<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 调用label标准化工具inverse_transform将下标转化为真实标签</span>pre_train_index <span class="token operator">=</span> np<span class="token punctuation">.</span>fliplr<span class="token punctuation">(</span>pre_train<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">*</span>top_k<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>pre_train_label <span class="token operator">=</span> label_coder<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>pre_train_index<span class="token punctuation">)</span>        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>xgboost原生接口，数据需要经过标签标准化(LabelEncoder().fit_transform)、输入数据标准化(xgboost.DMatrix)和输出结果反标签标准化(LabelEncoder().inverse_transform)，训练调用train预测调用predict.</p><p>需要注意的是，<strong>xgboost原生接口输出的预测标签概率矩阵各行的下标即为标准化后的label标签(0~class number-1).</strong></p><h1 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h1><p>优先考虑使用原生接口形式，便于模型保存后的复用。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      XGBoost
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="XGBoost" scheme="https://dataquaner.github.io/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>机器学习系列之决策树算法（07）：梯度提升树算法XGBoost实战</title>
    <link href="https://dataquaner.github.io/2019/12/26/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-07-ti-du-ti-sheng-shu-suan-fa-xgboost-shi-zhan/"/>
    <id>https://dataquaner.github.io/2019/12/26/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-07-ti-du-ti-sheng-shu-suan-fa-xgboost-shi-zhan/</id>
    <published>2019-12-25T16:00:00.000Z</published>
    <updated>2020-04-11T11:33:03.342Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>上一篇从数据原理角度深入介绍了XGBoost的实现原理及优化，参考《<a href="https://dataquaner.github.io/2019/12/25/机器学习系列之决策树算法（07）：梯度提升树算法XGBOOST/">梯度提升树算法XGBoost</a>》。本篇主要介绍XGBoost的工程实战，参数调优等内容。</p><blockquote><p>学习一个算法实战，一般按照以下几步，第一步能够基于某个平台、某种语言构建一个模型，第二步是能够优化一个模型 。我们将学习以下内容</p><ol><li>如果使用xgboost构建分类器</li><li>xgboost 的参数含义，以及如何调参</li><li>xgboost 的如何做cv</li><li>xgboost的可视化</li></ol></blockquote><h1 id="2-XGBoost模型构建"><a href="#2-XGBoost模型构建" class="headerlink" title="2 XGBoost模型构建"></a>2 XGBoost模型构建</h1><h2 id="回归模型"><a href="#回归模型" class="headerlink" title="回归模型"></a>回归模型</h2><h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><p>我们使用<strong><a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data" target="_blank" rel="noopener">房价数据</a></strong> ，做的是一个回归任务，预测房价，分类任务类似。</p><p>导入包</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> xgboost <span class="token keyword">import</span> XGBRegressor<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> Imputer<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_error<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>读入和展示数据</p><pre class="line-numbers language-python"><code class="language-python">data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'../input/train.csv'</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y <span class="token operator">=</span> data<span class="token punctuation">.</span>SalePriceX <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select_dtypes<span class="token punctuation">(</span>exclude<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'object'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>train_X<span class="token punctuation">,</span> test_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">.</span>as_matrix<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>as_matrix<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span>my_imputer <span class="token operator">=</span> Imputer<span class="token punctuation">(</span><span class="token punctuation">)</span>train_X <span class="token operator">=</span> my_imputer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>train_X<span class="token punctuation">)</span>test_X <span class="token operator">=</span> my_imputer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>train_X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>test_X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>train_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token comment" spellcheck="true">##执行结果</span><span class="token punctuation">(</span><span class="token number">1095</span><span class="token punctuation">,</span> <span class="token number">37</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">365</span><span class="token punctuation">,</span> <span class="token number">37</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">1095</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">365</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="创建并训练XGBoost模型"><a href="#创建并训练XGBoost模型" class="headerlink" title="创建并训练XGBoost模型"></a>创建并训练XGBoost模型</h3><p>随机选取默认参数进行初始化建模</p><pre class="line-numbers language-python"><code class="language-python">my_model <span class="token operator">=</span> XGBRegressor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Add silent=True to avoid printing out updates with each cycle</span>my_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="评估并预测模型"><a href="#评估并预测模型" class="headerlink" title="评估并预测模型"></a>评估并预测模型</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># make predictions</span>predictions <span class="token operator">=</span> my_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="模型调优"><a href="#模型调优" class="headerlink" title="模型调优"></a>模型调优</h3><p>XGBoost有一些参数可以显著影响模型的准确性和训练速度。</p><h4 id="n-estimators"><a href="#n-estimators" class="headerlink" title="n_estimators"></a><strong>n_estimators</strong></h4><p><strong>n_estimators</strong> 指定训练循环次数。在 <a href="https://link.zhihu.com/?target=http%3A//i.imgur.com/2q85n9s.png">欠拟合 vs 过拟合 图表</a>, n_estimators让训练沿着图表向右移动。 值太低会导致欠拟合，这对训练数据和新数据的预测都是不准确的。 太大的值会导致过度拟合，这是对训练数据的准确预测，但对新数据的预测不准确（这是我们关心的）。 通过实际实验来找到理想的n_estimators。 典型值范围为100-1000，但这很大程度上取决于下面讨论的</p><h4 id="early-stopping-rounds"><a href="#early-stopping-rounds" class="headerlink" title="early_stopping_rounds"></a><strong>early_stopping_rounds</strong></h4><p><strong>early_stopping_rounds</strong> 提供了一种自动查找理想值的方法。 early_stopping_rounds会导致模型在validation score停止改善时停止迭代，即使迭代次数还没有到n_estimators。为<strong>n_estimators</strong>设置一个高值然后使用<strong>early_stopping_rounds</strong>来找到停止迭代的最佳时间是明智的。</p><p>存在随机的情况有时会导致validation score无法改善，因此需要指定一个数字，以确定在停止前允许多少轮退化。<strong>early_stopping_rounds = 5</strong>是一个合理的值。 因此，在五轮validation score无法改善之后训练将停止。 以下是early_stopping的代码：</p><pre class="line-numbers language-python"><code class="language-python">my_model <span class="token operator">=</span> XGBRegressor<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>my_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> early_stopping_rounds<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>              eval_set<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>predictions <span class="token operator">=</span> my_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当使用<strong>early_stopping_rounds</strong>时，需要留出一些数据来检查要使用的轮数。 如果以后想要使所有数据拟合模型，请将<strong>n_estimators</strong>设置为在早期停止运行时发现的最佳值。</p><h4 id="learning-rate"><a href="#learning-rate" class="headerlink" title="learning_rate"></a>learning_rate</h4><p>对于更好的XGBoost模型，这是一个微妙但重要的技巧：</p><p>XGBoost模型不是通过简单地将每个组件模型中的预测相加来获得预测，而是在将它们添加之前将每个模型的预测乘以一个小数字。这意味着我们添加到集合中的每个树都不会对最后结果有决定性的影响。在实践中，这降低了模型过度拟合的倾向。</p><p>因此，使用一个较大的<strong>n_estimators</strong>值并不会造成过拟合。如果使用early_stopping_rounds，树的数量会被设置成一个合适的值。</p><p>通常，较小的learning rate（以及大量的estimators）将产生更准确的XGBoost模型，但是由于它在整个循环中进行更多迭代，因此也将使模型更长时间进行训练。 包含学习率的代码如下：</p><pre class="line-numbers language-python"><code class="language-python">my_model <span class="token operator">=</span> XGBRegressor<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span>my_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> early_stopping_rounds<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>              eval_set<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>predictions <span class="token operator">=</span> my_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>XGBoost目前是用于在传统数据（也称为表格或结构数据）上构建精确模型的主要算法</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> xgboost <span class="token keyword">import</span> XGBRegressor<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_errormy_model1 <span class="token operator">=</span> XGBRegressor<span class="token punctuation">(</span><span class="token punctuation">)</span>my_model1<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>predictions <span class="token operator">=</span> my_model1<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error 1: "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>my_model2 <span class="token operator">=</span> XGBRegressor<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>my_model2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> early_stopping_rounds<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>              eval_set<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>predictions <span class="token operator">=</span> my_model2<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error 2: "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>my_model3 <span class="token operator">=</span> XGBRegressor<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span>my_model3<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span>               eval_set<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>predictions <span class="token operator">=</span> my_model3<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error 3: "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="分类模型"><a href="#分类模型" class="headerlink" title="分类模型"></a>分类模型</h2><p>以天池竞赛中的<a href="https://tianchi.aliyun.com/competition/entrance/231702/introduction?spm=5176.12281973.1005.1.3dd52448pr3509" target="_blank" rel="noopener">《<strong>快来一起挖掘幸福感！</strong>》</a>中的数据为例，开始一个多分类模型的的实例</p><h4 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> learning_curve<span class="token punctuation">,</span> train_test_split<span class="token punctuation">,</span>GridSearchCV<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_error<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token triple-quoted-string string">'''  ##         准备训练集和测试集'''</span>  data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'happiness_train_abbr.csv'</span><span class="token punctuation">)</span>y<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token string">'happiness'</span><span class="token punctuation">]</span>data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'happiness'</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'survey_time'</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#survey_time格式不能直接识别</span>X<span class="token operator">=</span>data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="数据集划分"><a href="#数据集划分" class="headerlink" title="数据集划分"></a>数据集划分</h4><pre class="line-numbers language-python"><code class="language-python">train_x<span class="token punctuation">,</span> test_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_y <span class="token operator">=</span> train_test_split <span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size <span class="token operator">=</span><span class="token number">0.30</span><span class="token punctuation">,</span> early_stopping_rounds<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state <span class="token operator">=</span> <span class="token number">33</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="XGBoost模型训练"><a href="#XGBoost模型训练" class="headerlink" title="XGBoost模型训练"></a>XGBoost模型训练</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token triple-quoted-string string">'''  ##         xgboost训练'''</span> params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>           <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">,</span>           <span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span>           <span class="token string">'min_child_weight'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>           <span class="token string">'seed'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>           <span class="token string">'subsample'</span><span class="token punctuation">:</span> <span class="token number">0.8</span><span class="token punctuation">,</span>           <span class="token string">'colsample_bytree'</span><span class="token punctuation">:</span> <span class="token number">0.8</span><span class="token punctuation">,</span>          <span class="token string">'gamma'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>           <span class="token string">'reg_alpha'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>           <span class="token string">'reg_lambda'</span><span class="token punctuation">:</span> <span class="token number">1</span>         <span class="token punctuation">}</span><span class="token comment" spellcheck="true">#第一次设置300次的迭代，评测的指标是"merror","mlogloss"，这是一个多分类问题。</span>model <span class="token operator">=</span> xgb<span class="token punctuation">.</span>XGBClassifier<span class="token punctuation">(</span>params<span class="token punctuation">)</span>eval_set <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>test_x<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">]</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> eval_set<span class="token operator">=</span>eval_set<span class="token punctuation">,</span> eval_metric<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"merror"</span><span class="token punctuation">,</span> <span class="token string">"mlogloss"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>predictions <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy: %.2f%%"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>accuracy <span class="token operator">*</span> <span class="token number">100.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="模型可视化"><a href="#模型可视化" class="headerlink" title="模型可视化"></a>模型可视化</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token triple-quoted-string string">'''  ##         可视化训练过程'''</span> results <span class="token operator">=</span> model<span class="token punctuation">.</span>evals_result<span class="token punctuation">(</span><span class="token punctuation">)</span>epochs <span class="token operator">=</span> len<span class="token punctuation">(</span>results<span class="token punctuation">[</span><span class="token string">'validation_0'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'merror'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x_axis <span class="token operator">=</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplotfig<span class="token punctuation">,</span> ax <span class="token operator">=</span> pyplot<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_axis<span class="token punctuation">,</span> results<span class="token punctuation">[</span><span class="token string">'validation_0'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mlogloss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Train'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_axis<span class="token punctuation">,</span> results<span class="token punctuation">[</span><span class="token string">'validation_1'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mlogloss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Test'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'XGBoost Log Loss'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Log Loss'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epochs'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_axis<span class="token punctuation">,</span> results<span class="token punctuation">[</span><span class="token string">'validation_0'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'merror'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Train'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_axis<span class="token punctuation">,</span> results<span class="token punctuation">[</span><span class="token string">'validation_1'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'merror'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Test'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'XGBoost Classification Error'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Classification Error'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epochs'</span><span class="token punctuation">)</span>pyplot<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="C:\Users\liyu25\AppData\Roaming\Typora\typora-user-images\image-20191226184624206.png" alt="模型迭代结果" style="zoom: 80%;"><p>实际训练效果，在第146次迭代就停止了，说明最好的效果实在136次左右。根据许多大牛的实践经验，选择<strong>early_stopping_rounds = 10% * n_estimators</strong>。</p><p>最终输出模型最佳状态下的结果：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"best iteration:"</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>best_iteration<span class="token punctuation">)</span>limit <span class="token operator">=</span> model<span class="token punctuation">.</span>best_iterationpredictions <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_x<span class="token punctuation">,</span>ntree_limit<span class="token operator">=</span>limit<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy: %.2f%%"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>accuracy <span class="token operator">*</span> <span class="token number">100.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-参考资料"><a href="#3-参考资料" class="headerlink" title="3 参考资料"></a>3 参考资料</h2><p><a href="https://link.zhihu.com/?target=https%3A//www.kaggle.com/dansbecker/xgboost">https://www.kaggle.com/dansbecker/xgboost</a></p><p><a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/lujiandong1/article/details/52777168">https://blog.csdn.net/lujiandong1/article/details/52777168</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      XGBoost
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="XGBoost" scheme="https://dataquaner.github.io/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>机器学习系列之决策树算法（07）：梯度提升树算法XGBoost</title>
    <link href="https://dataquaner.github.io/2019/12/25/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-07-ti-du-ti-sheng-shu-suan-fa-xgboost/"/>
    <id>https://dataquaner.github.io/2019/12/25/ji-qi-xue-xi-xi-lie-zhi-jue-ce-shu-suan-fa-07-ti-du-ti-sheng-shu-suan-fa-xgboost/</id>
    <published>2019-12-24T16:00:00.000Z</published>
    <updated>2020-04-11T11:32:44.329Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>XGBoost的全称是eXtreme Gradient Boosting，它是经过优化的分布式梯度提升库，旨在高效、灵活且可移植。XGBoost是大规模并行boosting tree的工具，它是目前最快最好的开源 boosting tree工具包，比常见的工具包快10倍以上。在数据科学方面，有大量的Kaggle选手选用XGBoost进行数据挖掘比赛，是各大数据科学比赛的必杀武器；在工业界大规模数据方面，XGBoost的分布式版本有广泛的可移植性，支持在Kubernetes、Hadoop、SGE、MPI、 Dask等各个分布式环境上运行，使得它可以很好地解决工业界大规模数据的问题。本文将从XGBoost的数学原理和工程实现上进行介绍，然后介绍XGBoost的优缺点。</p><h2 id="数学原理"><a href="#数学原理" class="headerlink" title="数学原理"></a>数学原理</h2><h3 id="生成一棵树"><a href="#生成一棵树" class="headerlink" title="生成一棵树"></a>生成一棵树</h3><h4 id="Boosting-Tree回顾"><a href="#Boosting-Tree回顾" class="headerlink" title="Boosting Tree回顾"></a><strong>Boosting Tree回顾</strong></h4><p>XGBoost模型是大规模并行boosting tree的工具，它是目前较好的开源boosting tree工具包。因此，在了解XGBoost算法基本原理之前，需要首先了解Boosting Tree算法基本原理。Boosting方法是一类应用广泛且非常有效的统计学习方法。它是基于这样一种思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合所得出的判断，要比任何一个专家单独的判断要好。这种思想整体上可以分为两种：</p><ul><li><strong>强可学习</strong>：如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么就称为强可学习，直接单个模型就搞定常规问题。就好比专家给出的意见都很接近且都是正确率很高的结果，那么一个专家的结论就可以用了，这种情况非常少见。</li><li><strong>弱可学习</strong>：如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，那么就称这个概念是弱可学习的。这种情况是比较常见的。</li></ul><p>boosting算法主要是针对弱可学习的分类器来开展优化工作。其关心的问题包括两方面内容：</p><p>（1）在每一轮如何改变训练数据的权值和概率分布；</p><p>（2）如何将弱分类器组合成一个强分类器，这种思路较好的就是AdaBoost算法，以前在遥感图像地物识别中得到过应用。</p><p><img src="https://pic2.zhimg.com/80/v2-35e3fd2bd53b5cbfc2f9596eb2479591_hd.jpg" alt="Boosting模型基本流程"></p><p>Boosting Tree模型采用<strong>加法模型</strong>与<strong>前向分步算法</strong>，而且基模型都是决策树模型。前向分步算法（Forward stage wise additive model）是指在叠加新的基模型的基础上同步进行优化，具体而言，就是每一次叠加的模型都去拟合上一次模型拟合后产生的残差（Residual）。从算法模型解释上来说，Boosting Tree是决策树的加法模型：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+f_%7BM%7D%28x%29+%3D+%5Csum_%7Bm%3D1%7D%5E%7BM%7DT%28x%2C%5Ctheta_%7Bm%7D%29+%5Cend%7Bequation%7D" alt="[公式]"> （1）</p><p>上式中M为决策树的数量； <img src="https://www.zhihu.com/equation?tex=T%28x%2C+%5Ctheta_%7Bm%7D%29" alt="[公式]"> 为某个决策树； <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bm%7D" alt="[公式]"> 为对应决策树的参数。</p><p>Boosting Tree模型采用前向分步算法，其中假设 <img src="https://www.zhihu.com/equation?tex=f_%7B0%7D%28x%29+%3D+0" alt="[公式]"> ，则第m步的模型是：</p><p><img src="https://www.zhihu.com/equation?tex=f_%7Bm%7D%28x%29+%3D+f_%7Bm-1%7D%28x%29%2BT%28x%2C+%5Ctheta_%7Bm%7D%29" alt="[公式]"> （2）</p><p>为求解对应的参数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bm%7D" alt="[公式]"> ，需要最小化相应损失函数来确定，具体公式如下：</p><p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bm%7D%5E%7B%27%7D+%3D+arg+%5Cmin_%7B%5Ctheta_%7Bm%7D%7D%5Csum_%7Bi%3D1%7D%5E%7BM%7DL%28y_%7Bi%7D%2C+f_%7Bm-1%7D%28x_%7Bi%7D%29+%2B+T%28x_%7Bi%7D%3B%5Ctheta_%7Bm%7D%29%29" alt="[公式]"> （3）</p><p>由前向分步算法得到M棵决策树<img src="https://www.zhihu.com/equation?tex=T%28x%2C+%5Ctheta_%7Bm%7D%29" alt="[公式]"> 后，再进行加和，就得到了提升树模型 <img src="https://www.zhihu.com/equation?tex=f_%7BM%7D%28x%29" alt="[公式]"> 。在xgboost论文中提到的一个明显的boosting tree的加和应用案例如图3所示。</p><p><img src="https://pic2.zhimg.com/80/v2-fee9ec17376a633196bebbf56c18c2f5_hd.jpg" alt="img">图2 boosting tree的累加效果示意图</p><blockquote><p>相关树模型的参数值求解主要依据于<strong>损失函数</strong>的定义。</p><p>一般来言对于<strong>分类问题</strong>，选择<strong>指数损失函数</strong>作为损失函数时，将形成<strong>AdaBoost模型</strong>；</p><p>对于<strong>回归问题</strong>，损失函数常利用<strong>平方损失函数</strong>。为了扩展Boosting Tree的应用范围，需要构建一种可以广泛适用的残差描述方式来满足于任意损失函数的形式，为解决分类问题的Gradient Boosting Decision Tree算法应运而生。</p></blockquote><p><strong><a href="https://zhuanlan.zhihu.com/p/90520307" target="_blank" rel="noopener">带正则项的Boosting Tree模型和带梯度的Boosting Tree推导过程</a></strong></p><h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p>我们知道 XGBoost 是由 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 个基模型组成的一个加法运算式：</p><p><img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i%3D%5Csum_%7Bt%3D1%7D%5E%7Bk%7D%5C+f_t%28x_i%29+%5C%5C" alt="[公式]"></p><p>其中 <img src="https://www.zhihu.com/equation?tex=f_k" alt="[公式]"> 为第 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 个基模型， <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i" alt="[公式]"> 为第 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 个样本的预测值。</p><p>损失函数可由预测值 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i" alt="[公式]"> 与真实值 <img src="https://www.zhihu.com/equation?tex=y_i" alt="[公式]"> 进行表示：</p><p><img src="https://www.zhihu.com/equation?tex=L%3D%5Csum_%7Bi%3D1%7D%5En+l%28+y_i%2C+%5Chat%7By%7D_i%29+%5C%5C" alt="[公式]"></p><p>其中 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 为样本数量。</p><p>我们知道模型的预测精度由模型的偏差和方差共同决定，损失函数代表了模型的偏差，想要方差小则需要简单的模型，所以目标函数由模型的<strong>损失函数 <img src="https://www.zhihu.com/equation?tex=L" alt="[公式]"></strong> 与<strong>抑制模型复杂度的正则项 <img src="https://www.zhihu.com/equation?tex=%5COmega" alt="[公式]"></strong> 组成，所以我们有：</p><p><img src="https://www.zhihu.com/equation?tex=Obj+%3D%5Csum_%7Bi%3D1%7D%5En+l%28%5Chat%7By%7D_i%2C+y_i%29+%2B+%5Csum_%7Bt%3D1%7D%5Ek+%5COmega%28f_t%29+%5C%5C+" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=%5COmega" alt="[公式]"> 为模型的正则项，由于 XGBoost 支持决策树也支持线性模型，所以这里再不展开描述。</p><p>我们知道 boosting 模型是前向加法，以第 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 步的模型为例，模型对第 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 个样本 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D" alt="[公式]"> 的预测为：</p><p><img src="https://www.zhihu.com/equation?tex=++%5Chat%7By%7D_i%5Et%3D+%5Chat%7By%7D_i%5E%7Bt-1%7D+%2B+f_t%28x_i%29++%5C%5C" alt="[公式]"></p><p>其中 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i%5E%7Bt-1%7D" alt="[公式]"> 由第 <img src="https://www.zhihu.com/equation?tex=t-1" alt="[公式]"> 步的模型给出的预测值，是已知常数，<img src="https://www.zhihu.com/equation?tex=f_t%28x_i%29" alt="[公式]"> 是我们这次需要加入的新模型的预测值，此时，目标函数就可以写成：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D+Obj%5E%7B%28t%29%7D+%26%3D+%5Csum_%7Bi%3D1%7D%5Enl%28y_i%2C+%5Chat%7By%7D_i%5Et%29+%2B+%5Csum_%7Bi%3D1%7D%5Et%5COmega%28f_i%29+%5C%5C++++%26%3D+%5Csum_%7Bi%3D1%7D%5En+l%5Cleft%28y_i%2C+%5Chat%7By%7D_i%5E%7Bt-1%7D+%2B+f_t%28x_i%29+%5Cright%29+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29++%5Cend%7Balign%7D+%5C%5C" alt="[公式]"></p><p>求此时最优化目标函数，就相当于求解 <img src="https://www.zhihu.com/equation?tex=f_t%28x_i%29" alt="[公式]"> 。</p><blockquote><p>泰勒公式是将一个在 <img src="https://www.zhihu.com/equation?tex=x%3Dx_0" alt="[公式]"> 处具有 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 阶导数的函数 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> 利用关于 <img src="https://www.zhihu.com/equation?tex=x-x_0" alt="[公式]"> 的 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 次多项式来逼近函数的方法，若函数 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> 在包含 <img src="https://www.zhihu.com/equation?tex=x_0" alt="[公式]"> 的某个闭区间 <img src="https://www.zhihu.com/equation?tex=%5Ba%2Cb%5D" alt="[公式]"> 上具有 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 阶导数，且在开区间 <img src="https://www.zhihu.com/equation?tex=%28a%2Cb%29" alt="[公式]"> 上具有 <img src="https://www.zhihu.com/equation?tex=n%2B1" alt="[公式]"> 阶导数，则对闭区间 <img src="https://www.zhihu.com/equation?tex=%5Ba%2Cb%5D" alt="[公式]"> 上任意一点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 有 <img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+f%28x%29%3D%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%5Cfrac%7Bf%5E%7B%28i%29%7D%28x_0%29%7D%7Bi%21%7D%28x-x_0%29%5E+i%2BR_n%28x%29+" alt="[公式]"> ，其中的多项式称为函数在 <img src="https://www.zhihu.com/equation?tex=x_0" alt="[公式]"> 处的泰勒展开式， <img src="https://www.zhihu.com/equation?tex=R_n%28x%29" alt="[公式]"> 是泰勒公式的余项且是 <img src="https://www.zhihu.com/equation?tex=%28x%E2%88%92x_0%29%5En" alt="[公式]"> 的高阶无穷小。</p></blockquote><p>根据泰勒公式我们把函数 <img src="https://www.zhihu.com/equation?tex=f%28x%2B%5CDelta+x%29" alt="[公式]"> 在点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 处进行泰勒的二阶展开，可得到如下等式：</p><p><img src="https://www.zhihu.com/equation?tex=f%28x%2B%5CDelta+x%29+%5Capprox+f%28x%29+%2B+f%27%28x%29%5CDelta+x+%2B+%5Cfrac12+f%27%27%28x%29%5CDelta+x%5E2++%5C%5C" alt="[公式]"></p><p>我们把 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i%5E%7Bt-1%7D" alt="[公式]"> 视为 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=f_t%28x_i%29" alt="[公式]"> 视为 <img src="https://www.zhihu.com/equation?tex=%5CDelta+x" alt="[公式]"> ，故可以将目标函数写为：</p><p><img src="https://www.zhihu.com/equation?tex=Obj%5E%7B%28t%29%7D+%3D+%5Csum_%7Bi%3D1%7D%5En+%5Cleft%5B+l%28y_i%2C+%5Chat%7By%7D_i%5E%7Bt-1%7D%29+%2B+g_if_t%28x_i%29+%2B+%5Cfrac12h_if_t%5E2%28x_i%29+%5Cright%5D+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29+%5C%5C" alt="[公式]"></p><p>其中 <img src="https://www.zhihu.com/equation?tex=g_%7Bi%7D" alt="[公式]"> 为损失函数的一阶导， <img src="https://www.zhihu.com/equation?tex=h_%7Bi%7D" alt="[公式]"> 为损失函数的二阶导，<strong>注意这里的导是对 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i%5E%7Bt-1%7D" alt="[公式]"> 求导</strong>。</p><p>我们以平方损失函数为例：</p><p><img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5En+%5Cleft%28y_i+-+%28%5Chat%7By%7D_i%5E%7Bt-1%7D+%2B+f_t%28x_i%29%29+%5Cright%29%5E2++%5C%5C" alt="[公式]"></p><p>则：</p><p><img src="https://www.zhihu.com/equation?tex=++%5Cbegin%7Balign%7D++++++g_i+%26%3D+%5Cfrac%7B%5Cpartial+%28%5Chat%7By%7D%5E%7Bt-1%7D+-+y_i%29%5E2%7D%7B%5Cpartial+%7B%5Chat%7By%7D%5E%7Bt-1%7D%7D%7D+%3D+2%28%5Chat%7By%7D%5E%7Bt-1%7D+-+y_i%29+%5C%5C++++++h_i+%26%3D%5Cfrac%7B%5Cpartial%5E2%28%5Chat%7By%7D%5E%7Bt-1%7D+-+y_i%29%5E2%7D%7B%7B%5Chat%7By%7D%5E%7Bt-1%7D%7D%7D+%3D+2++++%5Cend%7Balign%7D++%5C%5C" alt="[公式]"></p><p>由于在第 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 步时 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i%5E%7Bt-1%7D" alt="[公式]"> 其实是一个已知的值，所以 <img src="https://www.zhihu.com/equation?tex=l%28y_i%2C+%5Chat%7By%7D_i%5E%7Bt-1%7D%29" alt="[公式]"> 是一个常数，其对函数的优化不会产生影响，因此目标函数可以写成：</p><p><img src="https://www.zhihu.com/equation?tex=+Obj%5E%7B%28t%29%7D+%5Capprox+%5Csum_%7Bi%3D1%7D%5En+%5Cleft%5B+g_if_t%28x_i%29+%2B+%5Cfrac12h_if_t%5E2%28x_i%29+%5Cright%5D+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29+%5C%5C" alt="[公式]"></p><p>所以<strong>我们只需要求出每一步损失函数的一阶导和二阶导的值（由于前一步的 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D%5E%7Bt-1%7D" alt="[公式]"> 是已知的，所以这两个值就是常数），然后最优化目标函数，就可以得到每一步的 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> ，最后根据加法模型得到一个整体模型。</strong></p><h4 id="基于决策树的目标函数"><a href="#基于决策树的目标函数" class="headerlink" title="基于决策树的目标函数"></a>基于决策树的目标函数</h4><p>损失函数可由预测值 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_%7Bi%7D" alt="[公式]"> 与真实值 <img src="https://www.zhihu.com/equation?tex=y_%7Bi%7D" alt="[公式]"> 进行表示：</p><p><img src="https://www.zhihu.com/equation?tex=L+%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bl%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%29%7D+%5C%5C" alt="[公式]"></p><p>其中， <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 为样本的数量。</p><p>我们知道模型的预测精度由模型的偏差和方差共同决定，损失函数代表了模型的偏差，想要方差小则需要在目标函数中添加正则项，用于防止过拟合。所以目标函数由模型的损失函数 <img src="https://www.zhihu.com/equation?tex=L" alt="[公式]"> 与抑制模型复杂度的正则项 <img src="https://www.zhihu.com/equation?tex=%5COmega" alt="[公式]"> 组成，目标函数的定义如下：</p><p><img src="https://www.zhihu.com/equation?tex=Obj+%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bl%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%29%7D+%2B+%5Csum_%7Bi%3D1%7D%5E%7Bt%7D%7B%5COmega%28f_%7Bi%7D%29%7D+%5C%5C" alt="[公式]"></p><p>其中，<img src="https://www.zhihu.com/equation?tex=+%5Csum_%7Bi%3D1%7D%5E%7Bt%7D%7B%5COmega%28f_%7Bi%7D%29%7D" alt="[公式]"> 是将全部 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 棵树的复杂度进行求和，添加到目标函数中作为正则化项，用于防止模型过度拟合。</p><p>由于XGBoost是boosting族中的算法，所以遵从前向分步加法，以第 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 步的模型为例，模型对第 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 个样本 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D" alt="[公式]"> 的预测值为：</p><p><img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_%7Bi%7D%5E%7B%28t%29%7D+%3D+%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D+%2B+f_%7Bt%7D%28x_%7Bi%7D%29+%5C%5C" alt="[公式]"></p><p>其中， <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D" alt="[公式]"> 是由第 <img src="https://www.zhihu.com/equation?tex=+t-1+" alt="[公式]"> 步的模型给出的预测值，是已知常数， <img src="https://www.zhihu.com/equation?tex=+f_%7Bt%7D%28x_%7Bi%7D%29+" alt="[公式]"> 是这次需要加入的新模型的预测值。此时，目标函数就可以写成：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D+Obj%5E%7B%28t%29%7D+%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bl%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t%29%7D%29%7D+%2B+%5Csum_%7Bi%3D1%7D%5E%7Bt%7D%7B%5COmega%28f_%7Bi%7D%29%7D+%5C%5C+%26+%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bl%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%2Bf_%7Bt%7D%28x_%7Bi%7D%29%29%7D+%2B+%5Csum_%7Bi%3D1%7D%5E%7Bt%7D%7B%5COmega%28f_%7Bi%7D%29%7D+%5C%5C+%26%3D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bl%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%2Bf_%7Bt%7D%28x_%7Bi%7D%29%29%7D+%2B+%5COmega%28f_%7Bt%7D%29+%2Bconstant++%5Cend%7Baligned%7D+%5Cend%7Bequation%7D+%5C%5C" alt="[公式]"></p><p>注意上式中，只有一个变量，那就是第 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 棵树<img src="https://www.zhihu.com/equation?tex=f_%7Bt%7D%28x_%7Bi%7D%29" alt="[公式]"> ，其余都是已知量或可通过已知量可以计算出来的。细心的同学可能会问，上式中的第二行到第三行是如何得到的呢？这里我们将正则化项进行拆分，由于前<img src="https://www.zhihu.com/equation?tex=t-1" alt="[公式]"> 棵树的结构已经确定，因此前<img src="https://www.zhihu.com/equation?tex=+t-1+" alt="[公式]"> 棵树的复杂度之和可以用一个常量表示，如下所示：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D+%5Csum_%7Bi%3D1%7D%5E%7Bt%7D%7B%5COmega%28f_%7Bi%7D%29%7D+%26%3D%5COmega%28f_%7Bt%7D%29+%2B+%5Csum_%7Bi%3D1%7D%5E%7Bt-1%7D%7B%5COmega%28f_%7Bi%7D%29%7D+%5C%5C+%26%3D+%5COmega%28f_%7Bt%7D%29+%2B+constant+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D+%5C%5C" alt="[公式]"></p><h4 id="泰勒公式展开"><a href="#泰勒公式展开" class="headerlink" title="泰勒公式展开"></a><strong>泰勒公式展开</strong></h4><p>泰勒公式是将一个在 <img src="https://www.zhihu.com/equation?tex=x%3Dx_%7B0%7D" alt="[公式]"> 处具有<img src="https://www.zhihu.com/equation?tex=+n" alt="[公式]"> 阶导数的函数<img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> 利用关于<img src="https://www.zhihu.com/equation?tex=%28x-x_%7B0%7D%29" alt="[公式]"> 的 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 次多项式来逼近函数的方法。若函数<img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> 在包含 <img src="https://www.zhihu.com/equation?tex=x_%7B0%7D" alt="[公式]"> 的某个闭区间 <img src="https://www.zhihu.com/equation?tex=%5Ba%2Cb%5D" alt="[公式]"> 上具有 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 阶导数，且在开区间 <img src="https://www.zhihu.com/equation?tex=%28a%2Cb%29" alt="[公式]"> 上具有 <img src="https://www.zhihu.com/equation?tex=n%2B1+" alt="[公式]"> 阶导数，则对闭区间 <img src="https://www.zhihu.com/equation?tex=%5Ba%2Cb%5D" alt="[公式]"> 上任意一点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 有：</p><p><img src="https://www.zhihu.com/equation?tex=f%28x%29+%3D+%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%7B%5Cfrac%7Bf%5E%7B%28i%29%7D%28x_%7B0%7D%29%7D%7Bi%21%7D%7D%28x-x_%7B0%7D%29%5E%7Bi%7D%2BR_%7Bn%7D%28x%29+%5C%5C" alt="[公式]"></p><p>其中的多项式称为函数在 <img src="https://www.zhihu.com/equation?tex=x_%7B0%7D" alt="[公式]"> 处的泰勒展开式，<img src="https://www.zhihu.com/equation?tex=R_%7Bn%7D%28x%29" alt="[公式]"> 是泰勒公式的余项且是 <img src="https://www.zhihu.com/equation?tex=%28x-x_%7B0%7D%29%5E%7Bn%7D" alt="[公式]"> 的高阶无穷小。</p><p>根据泰勒公式，把函数 <img src="https://www.zhihu.com/equation?tex=f%28x%2B%5CDelta+x%29" alt="[公式]"> 在点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 处进行泰勒的二阶展开，可得如下等式：</p><p><img src="https://www.zhihu.com/equation?tex=f%28x%2B%5CDelta+x%29+%5Capprox+f%28x%29%2Bf%27%28x%29%5CDelta+x+%2B+%5Cfrac%7B1%7D%7B2%7D+f%27%27%28x%29%5CDelta+x%5E%7B2%7D+%5C%5C" alt="[公式]"></p><p>回到XGBoost的目标函数上来， <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> 对应损失函数 <img src="https://www.zhihu.com/equation?tex=l%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%2Bf_%7Bt%7D%28x_%7Bi%7D%29%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 对应前 <img src="https://www.zhihu.com/equation?tex=t-1+" alt="[公式]"> 棵树的预测值 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D" alt="[公式]"> ，<img src="https://www.zhihu.com/equation?tex=%5CDelta+x" alt="[公式]"> 对应于我们正在训练的第 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 棵树 <img src="https://www.zhihu.com/equation?tex=f_%7Bt%7D%28x_%7Bi%7D%29" alt="[公式]"> ，则可以将损失函数写为：</p><p><img src="https://www.zhihu.com/equation?tex=l%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%2Bf_%7Bt%7D%28x_%7Bi%7D%29%29+%3D+l%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%29+%2B+g_%7Bi%7Df_%7Bt%7D%28x_%7Bi%7D%29+%2B+%5Cfrac%7B1%7D%7B2%7Dh_%7Bi%7Df_%7Bt%7D%5E%7B2%7D%28x_%7Bi%7D%29+%5C%5C" alt="[公式]"></p><p>其中， <img src="https://www.zhihu.com/equation?tex=g_%7Bi%7D" alt="[公式]"> 为损失函数的一阶导， <img src="https://www.zhihu.com/equation?tex=h_%7Bi%7D" alt="[公式]"> 为损失函数的二阶导，注意这里的求导是对 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D" alt="[公式]"> 求导。</p><p>我们以平方损失函数为例：</p><p><img src="https://www.zhihu.com/equation?tex=l%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%29+%3D+%28y_%7Bi%7D-%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%29%5E%7B2%7D+%5C%5C" alt="[公式]"></p><p>则：</p><p><img src="https://www.zhihu.com/equation?tex=g_%7Bi%7D+%3D+%5Cfrac%7B%5Cpartial+l%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%29%7D%7B%5Cpartial+%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D+%7D+%3D++-2%28y_%7Bi%7D-%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%29+%5C%5C" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=h_%7Bi%7D+%3D+%5Cfrac%7B%5Cpartial+%5E%7B2%7D+l%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%29%7D%7B%5Cpartial+%28%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%29%5E%7B2%7D+%7D+%3D++2+%5C%5C" alt="[公式]"></p><p>将上述的二阶展开式，带入到XGBoost的目标函数中，可以得到目标函数的近似值：</p><p><img src="https://www.zhihu.com/equation?tex=Obj%5E%7B%28t%29%7D+%5Csimeq+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%5Bl%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7Bt-1%7D%29%2Bg_%7Bi%7Df_%7Bt%7D%28x_%7Bi%7D%29%2B%5Cfrac%7B1%7D%7B2%7Dh_%7Bi%7Df_%7Bt%7D%5E%7B2%7D%28x_%7Bi%7D%29%5D%7D+%2B+%5COmega%28f_%7Bt%7D%29%2Bconstant+%5C%5C" alt="[公式]"></p><p>由于在第 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 步时 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D" alt="[公式]"> 其实是一个已知的值，所以 <img src="https://www.zhihu.com/equation?tex=l%28y_%7Bi%7D%2C%5Chat%7By%7D_%7Bi%7D%5E%7B%28t-1%29%7D%29+" alt="[公式]"> 是一个常数，其对函数的优化不会产生影响。因此，去掉全部的常数项，得到目标函数为：</p><p><img src="https://www.zhihu.com/equation?tex=Obj%5E%7B%28t%29%7D+%5Csimeq+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%5Bg_%7Bi%7Df_%7Bt%7D%28x_%7Bi%7D%29%2B%5Cfrac%7B1%7D%7B2%7Dh_%7Bi%7Df_%7Bt%7D%5E%7B2%7D%28x_%7Bi%7D%29%5D%7D%2B%5COmega%28f_%7Bt%7D%29+%5C%5C" alt="[公式]"></p><p>所以我们只需要求出每一步损失函数的一阶导和二阶导的值（由于前一步的 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D%5E%7B%28t-1%29%7D" alt="[公式]"> 是已知的，所以这两个值就是常数），然后最优化目标函数，就可以得到每一步的 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> ，最后根据加法模型得到一个整体模型。</p><h3 id="一棵树的生长细节"><a href="#一棵树的生长细节" class="headerlink" title="一棵树的生长细节"></a>一棵树的生长细节</h3><h4 id="分裂结点"><a href="#分裂结点" class="headerlink" title="分裂结点"></a>分裂结点</h4><p>在实际训练过程中，当建立第 t 棵树时，XGBoost采用贪心法进行树结点的分裂：</p><p>从树深为0时开始：</p><ul><li>对树中的每个叶子结点尝试进行分裂；</li><li>每次分裂后，原来的一个叶子结点继续分裂为左右两个子叶子结点，原叶子结点中的样本集将根据该结点的判断规则分散到左右两个叶子结点中；</li><li>新分裂一个结点后，我们需要检测这次分裂是否会给损失函数带来增益，增益的定义如下：</li></ul><p><img src="https://pic4.zhimg.com/80/v2-61e13bb229a8574a8ff9a1f9d8fcc87b_hd.jpg" alt="img"></p><p>如果增益Gain&gt;0，即分裂为两个叶子节点后，目标函数下降了，那么我们会考虑此次分裂的结果。</p><p>但是，在一个结点分裂时，可能有很多个分裂点，每个分裂点都会产生一个增益，如何才能寻找到最优的分裂点呢？接下来会讲到。</p><h4 id="寻找最佳分裂点"><a href="#寻找最佳分裂点" class="headerlink" title="寻找最佳分裂点"></a>寻找最佳分裂点</h4><blockquote><p>在实际训练过程中，当建立第 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 棵树时，一个非常关键的问题是如何找到叶子节点的最优切分点，XGBoost支持两种分裂节点的方法——<strong>贪心算法</strong>和<strong>近似算法</strong>。</p></blockquote><h6 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h6><p>  从树的深度为0开始：</p><blockquote><ol><li>对每个叶节点枚举所有的可用特征；</li><li>针对每个特征，把属于该节点的训练样本根据该特征值进行升序排列，通过<strong>线性扫描</strong>的方式来决定该特征的最佳分裂点，并记录该特征的<strong>分裂收益</strong>；</li><li>选择收益最大的特征作为分裂特征，用该特征的最佳分裂点作为分裂位置，在该节点上分裂出左右两个新的叶节点，并为每个新节点关联对应的样本集；</li><li>回到第1步，递归执行直到满足特定条件为止；</li></ol></blockquote><p> <strong>那么如何计算每个特征的分裂收益呢？</strong></p><p>  假设我们在某一节点完成特征分裂，则分裂前的目标函数可以写为：</p><p>  <img src="https://www.zhihu.com/equation?tex=Obj_%7B1%7D+%3D-%5Cfrac12+%5B%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5D+%2B+%5Cgamma++%5C%5C" alt="[公式]"></p><p>  分裂后的目标函数为：</p><p>  <img src="https://www.zhihu.com/equation?tex=Obj_2+%3D++-%5Cfrac12+%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D%5D+%2B2%5Cgamma+%5C%5C" alt="[公式]"></p><p>  则对于目标函数来说，分裂后的收益为：</p><p>  <img src="https://www.zhihu.com/equation?tex=Gain%3D%5Cfrac12+%5Cleft%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D+-+%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5Cright%5D+-+%5Cgamma+%5C%5C" alt="[公式]"></p><p>  <strong>注意：</strong>该特征收益也可作为特征重要性输出的重要依据。</p><p>  <strong>对于每次分裂，我们都需要枚举所有特征可能的分割方案，如何高效地枚举所有的分割呢？</strong></p><p>  假设我们要枚举某个特征所有 <img src="https://www.zhihu.com/equation?tex=x+%3C+a" alt="[公式]"> 这样条件的样本，对于某个特定的分割点 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> 我们要计算 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> 左边和右边的导数和。</p><p>  <img src="https://pic2.zhimg.com/80/v2-973173d22eeb508eb1b6f26acbf9f2d1_hd.jpg" alt="img"></p><p>  我们可以发现对于所有的分裂点 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> ，只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <img src="https://www.zhihu.com/equation?tex=G_L" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=G_R" alt="[公式]"> 。然后用上面的公式计算每个分割方案的收益就可以了。</p><p>  观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入新叶子的惩罚项，也就是说引入的分割带来的增益如果小于一个阀值的时候，我们可以剪掉这个分割。</p><p>上面是一种贪心的方法，每次进行分裂尝试都要遍历一遍全部候选分割点，也叫做全局扫描法。</p><p>但当数据量过大导致内存无法一次载入或者在分布式情况下，贪心算法的效率就会变得很低，全局扫描法不再适用。</p><blockquote><p>基于此，XGBoost提出了一系列加快寻找最佳分裂点的方案：</p><ul><li><p><strong>特征预排序+缓存：</strong>XGBoost在训练之前，预先对每个特征按照特征值大小进行排序，然后保存为block结构，后面的迭代中会重复地使用这个结构，使计算量大大减小。</p></li><li><p><strong>分位点近似法：</strong>对每个特征按照特征值排序后，采用类似分位点选取的方式，仅仅选出常数个特征值作为该特征的候选分割点，在寻找该特征的最佳分割点时，从候选分割点中选出最优的一个。</p></li><li><p><strong>并行查找：</strong>由于各个特性已预先存储为block结构，XGBoost支持利用多个线程并行地计算每个特征的最佳分割点，这不仅大大提升了结点的分裂速度，也极利于大规模训练集的适应性扩展。</p></li></ul></blockquote><h6 id="近似算法"><a href="#近似算法" class="headerlink" title="近似算法"></a>近似算法</h6><p>  贪心算法可以得到最优解，但当数据量太大时则无法读入内存进行计算，近似算法主要针对贪心算法这一缺点给出了近似最优解。</p><p>  对于每个特征，只考察分位点可以减少计算复杂度。</p><p>  该算法首先根据特征分布的分位数提出候选划分点，然后将连续型特征映射到由这些候选点划分的桶中，然后聚合统计信息找到所有区间的最佳分裂点。</p><p>  在提出候选切分点时有两种策略：</p><ul><li><p><strong>Global：</strong>学习每棵树前就提出候选切分点，并在每次分裂时都采用这种分割；</p></li><li><p><strong>Local：</strong>每次分裂前将重新提出候选切分点。</p><p>直观上来看，Local策略需要更多的计算步骤，而Global策略因为节点已有划分所以需要更多的候选点。</p><p>下图给出不同种分裂策略的AUC变化曲线，横坐标为迭代次数，纵坐标为测试集AUC，eps为近似算法的精度，其倒数为桶的数量。</p><p><img src="https://pic4.zhimg.com/80/v2-3081183127c025ee9f3a1436bb873b07_hd.jpg" alt="img"></p><p>从上图我们可以看到， Global 策略在候选点数多时（eps 小）可以和 Local 策略在候选点少时（eps 大）具有相似的精度。此外我们还发现，在eps取值合理的情况下，<strong>分位数策略</strong>可以获得与贪心算法相同的精度。</p><p>近似算法简单来说，就是根据特征 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 的分布来确定 <img src="https://www.zhihu.com/equation?tex=l" alt="[公式]"> 个候选切分点 <img src="https://www.zhihu.com/equation?tex=S_%7Bk%7D+%3D+%5Cleft%5C%7B+s_%7Bk1%7D%2C+s_%7Bk2%7D%2C...%2C+s_%7Bkl%7D+%5Cright%5C%7D" alt="[公式]"> ，然后根据这些候选切分点把相应的样本放入对应的桶中，对每个桶的 <img src="https://www.zhihu.com/equation?tex=G%2CH" alt="[公式]"> 进行累加。最后在候选切分点集合上贪心查找。该算法描述如下：</p><p><img src="https://pic1.zhimg.com/80/v2-1fe2882f8ef3b0a80068c57905ceaba0_hd.jpg" alt="img"></p></li></ul><p>  <strong>算法讲解：</strong></p><ul><li><p><strong>第一个for循环：</strong>对特征k根据该特征分布的分位数找到切割点的候选集合 <img src="https://www.zhihu.com/equation?tex=S_k%3D%5C%7Bs_%7Bk1%7D%2Cs_%7Bk2%7D%2C...%2Cs_%7Bkl%7D+%5C%7D" alt="[公式]"> 。这样做的目的是提取出部分的切分点不用遍历所有的切分点。其中获取某个特征k的候选切割点的方式叫<code>proposal</code>(策略)。XGBoost 支持 Global 策略和 Local 策略。</p></li><li><p><strong>第二个for循环：</strong>将每个特征的取值映射到由该特征对应的候选点集划分的分桶区间，即 <img src="https://www.zhihu.com/equation?tex=%7Bs_%7Bk%2Cv%7D%E2%89%A5x_%7Bjk%7D%3Es_%7Bk%2Cv%E2%88%921%7D%7D" alt="[公式]"> 。对每个桶区间内的样本统计值 G,H并进行累加，最后在这些累计的统计量上寻找最佳分裂点。这样做的目的是获取每个特征的候选分割点的 G,H值。</p><p>下图给出近似算法的具体例子，以三分位为例：</p><p><img src="https://pic2.zhimg.com/80/v2-cfecb2f6ad675e6e3bf536562e5c06dd_hd.jpg" alt="img"></p><p>根据样本特征进行排序，然后基于分位数进行划分，并统计三个桶内的 G,H 值，最终求解节点划分的增益。</p></li></ul><h4 id="停止生长"><a href="#停止生长" class="headerlink" title="停止生长"></a>停止生长</h4><p>一棵树不会一直生长下去，下面是一些常见的限制条件。</p><p><strong>(1) 当新引入的一次分裂所带来的增益Gain&lt;0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。</strong></p><p><img src="https://pic1.zhimg.com/80/v2-46c88b4258c2b9740d89c87d203ed0c0_hd.jpg" alt="img"></p><p><strong>(2) 当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。</strong></p><p><strong>(3) 当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。</strong>这涉及到一个超参数:最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细，这也是过拟合的一种措施。</p><p>每个叶子结点的样本权值和计算方式如下：</p><img src="https://pic3.zhimg.com/80/v2-4ecca09165ffb7a76123401d2009191a_hd.jpg" alt="img" style="zoom:33%;"><p>总结推导过程：</p><p><img src="https://pic2.zhimg.com/80/v2-def00357a06b469b6144d6acb8ab75a9_hd.jpg" alt="总结推导过程"></p><h2 id="算法工程优化"><a href="#算法工程优化" class="headerlink" title="算法工程优化"></a>算法工程优化</h2><h3 id="对内存的优化：列块并行学习"><a href="#对内存的优化：列块并行学习" class="headerlink" title="对内存的优化：列块并行学习"></a>对内存的优化：<strong>列块并行学习</strong></h3><p>在树生成过程中，最耗时的一个步骤就是在每次寻找最佳分裂点时都需要对特征的值进行排序。而 XGBoost 在训练之前会根据特征对数据进行排序，然后保存到<strong>块结构</strong>中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed Sparse Columns Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</p><p>作者提出通过按特征进行分块并排序，在块里面保存排序后的特征值及对应样本的引用，以便于获取样本的一阶、二阶导数值。具体流程为：</p><ul><li><p>整体训练数据可以看做一个 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+m" alt="[公式]"> 的超大规模稀疏矩阵</p></li><li><p>按照mini-batch的方式横向分割，可以切成很多个“Block”</p></li><li><p>每一个“Block”内部采用一种Compress Sparse Column的稀疏短阵格式，每一列特征分别做好升序排列，便于搜索切分点，整体的时间复杂度有效降低。</p></li><li><p>通过Block的设置，可以采用并行计算，从而提升模型训练速度。</p></li></ul><p>具体方式如图：</p><p><img src="https://pic2.zhimg.com/80/v2-3a93e4d9940cf6e2e9fd89dfa38dc62d_hd.jpg" alt=" 列分块的升序排列优化示意图"></p><p>通过顺序访问排序后的块遍历样本特征的特征值，方便进行切分点的查找。此外分块存储后多个特征之间互不干涉，可以使用多线程同时对不同的特征进行切分点查找，即特征的并行化处理。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个特征的增益计算可以同时进行，这也是 XGBoost 能够实现分布式或者多线程计算的原因。</p><h3 id="对CPU-Cache的优化：缓存优化"><a href="#对CPU-Cache的优化：缓存优化" class="headerlink" title="对CPU Cache的优化：缓存优化"></a>对<strong>CPU Cache</strong>的优化：缓存优化</h3><p>针对一个具体的块(block)，其中存储了排序好的特征值，以及指向特征值所属样本的索引指针，算法需要间接地利用索引指针来获得样本的梯度值。列块并行学习的设计可以减少节点分裂时的计算量，在顺序访问特征值时，访问的是一块连续的内存空间，但通过特征值持有的索引（样本索引）访问样本获取一阶、二阶导数时，这个访问操作访问的内存空间并不连续，这样可能造成cpu缓存命中率低，影响算法效率。由于块中数据是按特征值来排序的，当索引指针指向内存中不连续的样本时，无法充分利用CPU缓存来提速。</p><p>为了解决缓存命中率低的问题，XGBoost 提出了两种优化思路。</p><p><strong>（1）提前取数（Prefetching）</strong></p><p>对于精确搜索，利用多线程的方式，给每个线程划分一个连续的缓存空间，当training线程在按特征值的顺序计算梯度的累加时，prefetching线程可以提前将接下来的一批特征值对应的梯度加载到CPU缓存中。为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就实现了非连续空间到连续空间的转换，提高了算法效率。</p><p><strong>（2）合理设置分块大小</strong></p><p>对于近似分桶搜索，按行分块时需要准确地选择块的大小。块太小会导致每个线程的工作量太少，切换线程的成本过高，不利于并行计算；块太大导致缓存命中率低，需要花费更多时间在读取数据上。经过反复实验，作者找到一个合理的<code>block_size</code>为 <img src="https://www.zhihu.com/equation?tex=2%5E%7B16%7D" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=2%5E%7B16%7D" alt="[公式]">。</p><h3 id="对IO的优化：核外块计算"><a href="#对IO的优化：核外块计算" class="headerlink" title="对IO的优化：核外块计算"></a>对IO的优化：核外块计算</h3><p>当数据量非常大时，我们不能把所有的数据都加载到内存中。那么就必须将一部分需要加载进内存的数据先存放在硬盘中，当需要时再加载进内存。这样操作具有很明显的瓶颈，即硬盘的IO操作速度远远低于内存的处理速度，肯定会存在大量等待硬盘IO操作的情况。针对这个问题作者提出了“核外”计算的优化方法。具体操作为，将数据集分成多个块存放在硬盘中，使用一个独立的线程专门从硬盘读取数据，加载到内存中，这样算法在内存中处理数据就可以和从硬盘读取数据同时进行。此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p><ul><li><strong>块压缩</strong>（<strong>Block Compression</strong>）。论文使用的是按列进行压缩，读取的时候用另外的线程解压。对于行索引，只保存第一个索引值，然后用16位的整数保存与该block第一个索引的差值。作者通过测试在block设置为 <img src="https://www.zhihu.com/equation?tex=2%5E%7B16%7D" alt="[公式]"> 个样本大小时，压缩比率几乎达到26% <img src="https://www.zhihu.com/equation?tex=%5Csim" alt="[公式]"> 29%。</li><li><strong>块分区</strong>（<strong>Block Sharding</strong> ）。块分区是将特征block分区存放在不同的硬盘上，以此来增加硬盘IO的吞吐量。</li></ul><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li><strong>精度更高：</strong>GBDT 只用到一阶泰勒展开，而 XGBoost 对损失函数进行了二阶泰勒展开。XGBoost 引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数；</li><li><strong>灵活性更强：</strong>GBDT 以 CART 作为基分类器，XGBoost 不仅支持 CART 还支持线性分类器，使用线性分类器的 XGBoost 相当于带 L1 和 L2 正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。此外，XGBoost 工具支持自定义损失函数，只需函数支持一阶和二阶求导；</li><li><strong>正则化：</strong>XGBoost 在目标函数中加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、叶子节点权重的 L2 范式。正则项降低了模型的方差，使学习出来的模型更加简单，有助于防止过拟合，这也是XGBoost优于传统GBDT的一个特性。</li><li><strong>Shrinkage（缩减）：</strong>相当于学习速率。XGBoost 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。传统GBDT的实现也有学习速率；</li><li><strong>列抽样：</strong>XGBoost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算。这也是XGBoost异于传统GBDT的一个特性；</li><li><strong>缺失值处理：</strong>对于特征的值有缺失的样本，XGBoost 采用的稀疏感知算法可以自动学习出它的分裂方向；</li><li><strong>XGBoost工具支持并行：</strong>boosting不是一种串行的结构吗?怎么并行的？注意XGBoost的并行不是tree粒度的并行，XGBoost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。XGBoost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），XGBoost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</li><li><strong>可并行的近似算法：</strong>树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以XGBoost还提出了一种可并行的近似算法，用于高效地生成候选的分割点。</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li><p>虽然利用预排序和近似算法可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要遍历数据集；</p></li><li><p>预排序过程的空间复杂度过高，不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。</p></li></ul><h3 id="XGBoost与GBDT的差异"><a href="#XGBoost与GBDT的差异" class="headerlink" title="XGBoost与GBDT的差异"></a>XGBoost与GBDT的差异</h3><p>在分析XGBooting优缺点的时候，通过比较该算法与GBDT的差异，即可有较清楚的描述，具体表现在如下方面。</p><p><strong>（1）基分类器的差异</strong></p><ul><li>GBDT算法只能利用CART树作为基学习器，满足分类应用；</li><li>XGBoost算法除了回归树之外还支持线性的基学习器，因此其一方面可以解决带L1与L2正则化项的逻辑回归分类问题，也可以解决线性回问题。</li></ul><p><strong>（2）节点分类方法的差异</strong></p><ul><li>GBDT算法主要是利用Gini impurity针对特征进行节点划分；</li><li>XGBoost经过公式推导，提出的weighted quantile sketch（<strong>加权分位数缩略图</strong>）划分方法，依据影响Loss的程度来确定连续特征的切分值。</li></ul><p><strong>（3）模型损失函数的差异</strong></p><ul><li>传统GBDT在优化时只用到一阶导数信息；</li><li>xgboost则对代价函数进行了二阶泰勒展开，二阶导数有利于梯度下降的更快更准。</li></ul><p><strong>（4）模型防止过拟合的差异</strong></p><ul><li>GBDT算法无正则项，可能出现过拟合；</li><li>Xgboost在代价函数里加入了正则项，用于控制模型的复杂度，降低了过拟合的可能性。</li></ul><p><strong>（5）模型实现上的差异</strong></p><p>决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点）。xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。其能够实现在特征粒度的并行。</p><h2 id="XGBoost代码实现"><a href="#XGBoost代码实现" class="headerlink" title="XGBoost代码实现"></a>XGBoost代码实现</h2><h3 id="安装XGBoost依赖包"><a href="#安装XGBoost依赖包" class="headerlink" title="安装XGBoost依赖包"></a><strong>安装XGBoost依赖包</strong></h3><pre class="line-numbers language-python"><code class="language-python">pip install xgboost<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="XGBoost分类和回归"><a href="#XGBoost分类和回归" class="headerlink" title="XGBoost分类和回归"></a><strong>XGBoost分类和回归</strong></h3><p>XGBoost有两大类接口：XGBoost原生接口 和 scikit-learn接口 ，并且XGBoost能够实现分类和回归两种任务。</p><p><strong>（1）基于XGBoost原生接口的分类</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris<span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb<span class="token keyword">from</span> xgboost <span class="token keyword">import</span> plot_importance<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token comment" spellcheck="true"># read in the iris data</span>iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>X <span class="token operator">=</span> iris<span class="token punctuation">.</span>datay <span class="token operator">=</span> iris<span class="token punctuation">.</span>target<span class="token comment" spellcheck="true"># split train data and test data</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1234565</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># set XGBoost's parameters</span>params <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'booster'</span><span class="token punctuation">:</span> <span class="token string">'gbtree'</span><span class="token punctuation">,</span>    <span class="token string">'objective'</span><span class="token punctuation">:</span> <span class="token string">'multi:softmax'</span><span class="token punctuation">,</span>   <span class="token comment" spellcheck="true"># 回归任务设置为：'objective': 'reg:gamma',</span>    <span class="token string">'num_class'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># 回归任务没有这个参数</span>    <span class="token string">'gamma'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>    <span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">6</span><span class="token punctuation">,</span>    <span class="token string">'lambda'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>    <span class="token string">'subsample'</span><span class="token punctuation">:</span> <span class="token number">0.7</span><span class="token punctuation">,</span>    <span class="token string">'colsample_bytree'</span><span class="token punctuation">:</span> <span class="token number">0.7</span><span class="token punctuation">,</span>    <span class="token string">'min_child_weight'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span>    <span class="token string">'silent'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>    <span class="token string">'eta'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>    <span class="token string">'seed'</span><span class="token punctuation">:</span> <span class="token number">1000</span><span class="token punctuation">,</span>    <span class="token string">'nthread'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">}</span>plst <span class="token operator">=</span> params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span>dtrain <span class="token operator">=</span> xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>num_rounds <span class="token operator">=</span> <span class="token number">500</span>model <span class="token operator">=</span> xgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>plst<span class="token punctuation">,</span> dtrain<span class="token punctuation">,</span> num_rounds<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 对测试集进行预测</span>dtest <span class="token operator">=</span> xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>ans <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>dtest<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 计算准确率</span>cnt1 <span class="token operator">=</span> <span class="token number">0</span>cnt2 <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> ans<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> y_test<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>        cnt1 <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        cnt2 <span class="token operator">+=</span> <span class="token number">1</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy: %.2f %% "</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> cnt1 <span class="token operator">/</span> <span class="token punctuation">(</span>cnt1 <span class="token operator">+</span> cnt2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 显示重要特征</span>plot_importance<span class="token punctuation">(</span>model<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>（2）基于Scikit-learn接口的回归</strong></p><p>这里，我们用Kaggle比赛中回归问题：House Prices: Advanced Regression Techniques，地址：<a href="https://link.zhihu.com/?target=https%3A//www.kaggle.com/c/house-prices-advanced-regression-techniques">https://www.kaggle.com/c/house-prices-advanced-regression-techniques</a> 来进行实例讲解。</p><p>该房价预测的训练数据集中一共有81列，第一列是Id，最后一列是label，中间79列是特征。这79列特征中，有43列是分类型变量，33列是整数变量，3列是浮点型变量。训练数据集中存在缺失值。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>impute <span class="token keyword">import</span> SimpleImputer<span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_error<span class="token comment" spellcheck="true"># 1.读文件</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./dataset/train.csv'</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 2.切分数据输入：特征 输出：预测目标变量</span>y <span class="token operator">=</span> data<span class="token punctuation">.</span>SalePriceX <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select_dtypes<span class="token punctuation">(</span>exclude<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'object'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 3.切分训练集、测试集,切分比例7.5 : 2.5</span>train_X<span class="token punctuation">,</span> test_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">.</span>values<span class="token punctuation">,</span> y<span class="token punctuation">.</span>values<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 4.空值处理，默认方法：使用特征列的平均值进行填充</span>my_imputer <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span><span class="token punctuation">)</span>train_X <span class="token operator">=</span> my_imputer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>train_X<span class="token punctuation">)</span>test_X <span class="token operator">=</span> my_imputer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 5.调用XGBoost模型，使用训练集数据进行训练（拟合）</span><span class="token comment" spellcheck="true"># Add verbosity=2 to print messages while running boosting</span>my_model <span class="token operator">=</span> xgb<span class="token punctuation">.</span>XGBRegressor<span class="token punctuation">(</span>objective<span class="token operator">=</span><span class="token string">'reg:squarederror'</span><span class="token punctuation">,</span> verbosity<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># xgb.XGBClassifier() XGBoost分类模型</span>my_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 6.使用模型对测试集数据进行预测</span>predictions <span class="token operator">=</span> my_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 7.对模型的预测结果进行评判（平均绝对误差）</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean Absolute Error : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="XGBoost调参"><a href="#XGBoost调参" class="headerlink" title="XGBoost调参"></a><strong>XGBoost调参</strong></h3><p>在上一部分中，XGBoot模型的参数都使用了模型的默认参数，但默认参数并不是最好的。要想让XGBoost表现的更好，需要对XGBoost模型进行参数微调。XGBoost需要调的参数不算多，他们可以分成三个部分：</p><blockquote><p><strong>1、General Parameters，即与整个模型属基调相关的参数；</strong></p><p><strong>2、Booster Parameters，即与单颗树生成有关的参数；</strong></p><p><strong>3、Learning Task Parameters，与模型调优相关的参数；</strong></p></blockquote><h4 id="General-Parameters"><a href="#General-Parameters" class="headerlink" title="General Parameters"></a><strong>General Parameters</strong></h4><p><strong>1、booster [default=gbtree]</strong></p><p>即xgboost中基学习器类型，有两种选择，分别是树模型（gbtree）和线性模型（linear models）</p><p><strong>2、silent [default=0]</strong></p><p>即控制迭代日志的是否输出，默认输出；</p><p><strong>3、nthread [default to maximum number of threads available if not set]</strong></p><p>即控制模型训练调用机器的核心数，与sklearn中<em>n_jobs的含义相似；</em></p><h4 id="Booster-parameters"><a href="#Booster-parameters" class="headerlink" title="Booster parameters"></a><strong>Booster parameters</strong></h4><p>因为booster有两种类型，常用的一般是树模型，这里只列树模型相关的参数：</p><p><strong>1、eta [default=0.3]</strong> <strong>：学习率</strong></p><p>学习率，这个相当于sklearn中的learning_rate，常见的设置范围在0.01-0.2之间</p><p><strong>2、min_child_weight [default=1]：叶节点的最小权重值</strong></p><p>这个参数与GBM（sklearn）中的“min_samples_leaf”很相似，只不过这里不是样本数，而是权重值，如果样本的权重都是1，这两个参数是等同的；这个值设置较大时，通常树不会太深，可以控制过拟合，但太大时，容易造成欠拟合的现象，具体调参需要cv；</p><p><strong>3、max_depth：树的最大深度</strong></p><p>树的最大深度，含义很直白，控制树的复杂性；通常取值范围在3-10；</p><p><strong>4、max_leaf_nodes：最大叶节点数</strong></p><p>一般这个参数与max_depth二选一控制即可；</p><p><strong>5、gamma [default=0]：分裂收益阈值</strong></p><p>即用来比较每次节点分裂带来的收益，有效控制节点的过度分裂；</p><p>这个参数的变化范围受损失函数的选取影响；</p><p><strong>6、max_delta_step [default=0]</strong></p><p>这个参数暂时不是很理解它的作用范围，一般可以忽略它；</p><p><strong>7、subsample [default=1]：采样比例</strong></p><p>与sklearn中的参数一样，即每颗树的生成可以不去全部样本，这样可以控制模型的过拟合；通常取值范围0.5-1；</p><p><strong>8、colsample_bytree [default=1]：特征采样的比例（每棵树）</strong></p><p>即每棵树不使用全部的特征，控制模型的过拟合；</p><p>通常取值范围0.5-1；</p><p><strong>9、colsample_bylevel [default=1]</strong></p><p>特征采样的比例（每次分裂）；</p><p>这个与随机森林的思想很相似，即每次分裂都不取全部变量；</p><p>当7、8的参数设置较好时，该参数可以不用在意；</p><p><strong>10、lambda [default=1]</strong></p><p>L2范数的惩罚系数，叶子结点的分数？；</p><p><strong>11、alpha [default=0]</strong></p><p>L1范数的惩罚系数，叶子结点数？；</p><p><strong>12、scale_pos_weight [default=1]</strong></p><p>这个参数也不是很理解，貌似与类别不平衡的问题相关；</p><h4 id="Learning-Task-Parameters"><a href="#Learning-Task-Parameters" class="headerlink" title="Learning Task Parameters"></a><strong>Learning Task Parameters</strong></h4><p><strong>1、objective [default=reg:linear]：目标函数</strong></p><p>通常的选项分别是：binary:logistic，用于二分类，产生每类的概率值；multi:softmax，用于多分类，但不产生概率值，直接产生类别结果；multi:softprob，类似softmax，但产生多分类的概率值；</p><p><strong>2、eval_metric [ default according to objective ]：评价指标</strong></p><p>当你给模型一个验证集时，会输出对应的评价指标值；</p><p>一般有：rmse ，均方误差；mae ，绝对平均误差；logloss ，对数似然值；error ，二分类错误率；merror ，多分类错误率；mlogloss ；auc</p><p><strong>3、seed：即随机种子</strong></p><h2 id="关于XGBoost若干问题的思考"><a href="#关于XGBoost若干问题的思考" class="headerlink" title="关于XGBoost若干问题的思考"></a><strong>关于XGBoost若干问题的思考</strong></h2><h3 id="XGBoost与GBDT的联系和区别有哪些？"><a href="#XGBoost与GBDT的联系和区别有哪些？" class="headerlink" title="XGBoost与GBDT的联系和区别有哪些？"></a><strong>XGBoost与GBDT的联系和区别有哪些？</strong></h3><p>（1）GBDT是机器学习算法，XGBoost是该算法的工程实现。</p><p>（2）<strong>正则项：</strong>在使用CART作为基分类器时，XGBoost显式地加入了正则项来控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力。</p><p>（3）<strong>导数信息：</strong>GBDT在模型训练时只使用了代价函数的一阶导数信息，XGBoost对代价函数进行二阶泰勒展开，可以同时使用一阶和二阶导数。</p><p>（4）<strong>基分类器：</strong>传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类器，比如线性分类器。</p><p>（5）<strong>子采样：</strong>传统的GBDT在每轮迭代时使用全部的数据，XGBoost则采用了与随机森林相似的策略，支持对数据进行采样。</p><p>（6）<strong>缺失值处理：</strong>传统GBDT没有设计对缺失值进行处理，XGBoost能够自动学习出缺失值的处理策略。</p><p>（7）<strong>并行化</strong>：传统GBDT没有进行并行化设计，注意不是tree维度的并行，而是特征维度的并行。XGBoost预先将每个特征按特征值排好序，存储为块结构，分裂结点时可以采用多线程并行查找每个特征的最佳分割点，极大提升训练速度。</p><h3 id="为什么XGBoost泰勒二阶展开后效果就比较好呢？"><a href="#为什么XGBoost泰勒二阶展开后效果就比较好呢？" class="headerlink" title="为什么XGBoost泰勒二阶展开后效果就比较好呢？"></a><strong>为什么XGBoost泰勒二阶展开后效果就比较好呢？</strong></h3><p>（1）<strong>从为什么会想到引入泰勒二阶的角度来说（可扩展性）：</strong>XGBoost官网上有说，当目标函数是MSE时，展开是一阶项（残差）+二阶项的形式，而其它目标函数，如logistic loss的展开式就没有这样的形式。为了能有个统一的形式，所以采用泰勒展开来得到二阶项，这样就能把MSE推导的那套直接复用到其它自定义损失函数上。简短来说，就是为了统一损失函数求导的形式以支持自定义损失函数。至于为什么要在形式上与MSE统一？是因为MSE是最普遍且常用的损失函数，而且求导最容易，求导后的形式也十分简单。所以理论上只要损失函数形式与MSE统一了，那就只用推导MSE就好了。</p><p>（2）<strong>从二阶导本身的性质，也就是从为什么要用泰勒二阶展开的角度来说（精准性）：</strong>二阶信息本身就能让梯度收敛更快更准确。这一点在优化算法里的牛顿法中已经证实。可以简单认为一阶导指引梯度方向，二阶导指引梯度方向如何变化。简单来说，相对于GBDT的一阶泰勒展开，XGBoost采用二阶泰勒展开，可以更为精准的逼近真实的损失函数。</p><h3 id="XGBoost对缺失值是怎么处理的？"><a href="#XGBoost对缺失值是怎么处理的？" class="headerlink" title="XGBoost对缺失值是怎么处理的？"></a><strong>XGBoost对缺失值是怎么处理的？</strong></h3><p>在普通的GBDT策略中，对于缺失值的方法是先手动对缺失值进行填充，然后当做有值的特征进行处理，但是这样人工填充不一定准确，而且没有什么理论依据。而XGBoost采取的策略是先不处理那些值缺失的样本，采用那些有值的样本搞出分裂点，在遍历每个有值特征的时候，尝试将缺失样本划入左子树和右子树，选择使损失最优的值作为分裂点。</p><h3 id="XGBoost为什么可以并行训练？"><a href="#XGBoost为什么可以并行训练？" class="headerlink" title="XGBoost为什么可以并行训练？"></a><strong>XGBoost为什么可以并行训练？</strong></h3><p>（1）XGBoost的并行，并不是说每棵树可以并行训练，XGBoost本质上仍然采用boosting思想，每棵树训练前需要等前面的树训练完成才能开始训练。</p><p>（2）XGBoost的并行，指的是特征维度的并行：在训练之前，每个特征按特征值对样本进行预排序，并存储为Block结构，在后面查找特征分割点时可以重复使用，而且特征已经被存储为一个个block结构，那么在寻找每个特征的最佳分割点时，可以利用多线程对每个block并行计算。</p><h2 id="20道XGBoost面试题"><a href="#20道XGBoost面试题" class="headerlink" title="20道XGBoost面试题"></a>20道XGBoost面试题</h2><h3 id="简单介绍一下XGBoost"><a href="#简单介绍一下XGBoost" class="headerlink" title="简单介绍一下XGBoost"></a>简单介绍一下XGBoost</h3><p>首先需要说一说GBDT，它是一种基于boosting增强策略的加法模型，训练的时候采用前向分布算法进行贪婪的学习，每次迭代都学习一棵CART树来拟合之前 t-1 棵树的预测结果与训练样本真实值的残差。</p><p>XGBoost对GBDT进行了一系列优化，比如损失函数进行了二阶泰勒展开、目标函数加入正则项、支持并行和默认缺失值处理等，在可扩展性和训练速度上有了巨大的提升，但其核心思想没有大的变化。</p><h3 id="XGBoost与GBDT有什么不同"><a href="#XGBoost与GBDT有什么不同" class="headerlink" title="XGBoost与GBDT有什么不同"></a>XGBoost与GBDT有什么不同</h3><ul><li><strong>基分类器</strong>：XGBoost的基分类器不仅支持CART决策树，还支持线性分类器，此时XGBoost相当于带L1和L2正则化项的Logistic回归（分类问题）或者线性回归（回归问题）。</li><li><strong>导数信息</strong>：XGBoost对损失函数做了二阶泰勒展开，GBDT只用了一阶导数信息，并且XGBoost还支持自定义损失函数，只要损失函数一阶、二阶可导。</li><li><strong>正则项</strong>：XGBoost的目标函数加了正则项， 相当于预剪枝，使得学习出来的模型更加不容易过拟合。</li><li><strong>列抽样</strong>：XGBoost支持列采样，与随机森林类似，用于防止过拟合。</li><li><strong>缺失值处理</strong>：对树中的每个非叶子结点，XGBoost可以自动学习出它的默认分裂方向。如果某个样本该特征值缺失，会将其划入默认分支。</li><li><strong>并行化</strong>：注意不是tree维度的并行，而是特征维度的并行。XGBoost预先将每个特征按特征值排好序，存储为块结构，分裂结点时可以采用多线程并行查找每个特征的最佳分割点，极大提升训练速度。</li></ul><h3 id="XGBoost为什么使用泰勒二阶展开"><a href="#XGBoost为什么使用泰勒二阶展开" class="headerlink" title="XGBoost为什么使用泰勒二阶展开"></a>XGBoost为什么使用泰勒二阶展开</h3><ul><li><strong>精准性</strong>：相对于GBDT的一阶泰勒展开，XGBoost采用二阶泰勒展开，可以更为精准的逼近真实的损失函数</li><li><strong>可扩展性</strong>：损失函数支持自定义，只需要新的损失函数二阶可导。</li></ul><h3 id="XGBoost为什么可以并行训练"><a href="#XGBoost为什么可以并行训练" class="headerlink" title="XGBoost为什么可以并行训练"></a>XGBoost为什么可以并行训练</h3><ul><li>XGBoost的并行，并不是说每棵树可以并行训练，XGB本质上仍然采用boosting思想，每棵树训练前需要等前面的树训练完成才能开始训练。</li><li>XGBoost的并行，指的是特征维度的并行：在训练之前，每个特征按特征值对样本进行预排序，并存储为Block结构，在后面查找特征分割点时可以重复使用，而且特征已经被存储为一个个block结构，那么在寻找每个特征的最佳分割点时，可以利用多线程对每个block并行计算。</li></ul><h3 id="XGBoost为什么快"><a href="#XGBoost为什么快" class="headerlink" title="XGBoost为什么快"></a>XGBoost为什么快</h3><ul><li><strong>分块并行</strong>：训练前每个特征按特征值进行排序并存储为Block结构，后面查找特征分割点时重复使用，并且支持并行查找每个特征的分割点</li><li><strong>候选分位点</strong>：每个特征采用常数个分位点作为候选分割点</li><li><strong>CPU cache 命中优化</strong>： 使用缓存预取的方法，对每个线程分配一个连续的buffer，读取每个block中样本的梯度信息并存入连续的Buffer中。</li><li><strong>Block 处理优化</strong>：Block预先放入内存；Block按列进行解压缩；将Block划分到不同硬盘来提高吞吐</li></ul><h3 id="XGBoost防止过拟合的方法"><a href="#XGBoost防止过拟合的方法" class="headerlink" title="XGBoost防止过拟合的方法"></a>XGBoost防止过拟合的方法</h3><p>XGBoost在设计时，为了防止过拟合做了很多优化，具体如下：</p><ul><li><strong>目标函数添加正则项</strong>：叶子节点个数+叶子节点权重的L2正则化</li><li><strong>列抽样</strong>：训练的时候只用一部分特征（不考虑剩余的block块即可）</li><li><strong>子采样</strong>：每轮计算可以不使用全部样本，使算法更加保守</li><li><strong>shrinkage</strong>: 可以叫学习率或步长，为了给后面的训练留出更多的学习空间</li></ul><h3 id="XGBoost如何处理缺失值"><a href="#XGBoost如何处理缺失值" class="headerlink" title="XGBoost如何处理缺失值"></a>XGBoost如何处理缺失值</h3><p>XGBoost模型的一个优点就是允许特征存在缺失值。对缺失值的处理方式如下：</p><ul><li>在特征k上寻找最佳 split point 时，不会对该列特征 missing 的样本进行遍历，而只对该列特征值为 non-missing 的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找 split point 的时间开销。</li></ul><ul><li>在逻辑实现上，为了保证完备性，会将该特征值missing的样本分别分配到左叶子结点和右叶子结点，两种情形都计算一遍后，选择分裂后增益最大的那个方向（左分支或是右分支），作为预测时特征值缺失样本的默认分支方向。</li></ul><ul><li>如果在训练中没有缺失值而在预测中出现缺失，那么会自动将缺失值的划分方向放到右子结点。</li></ul><img src="https://mmbiz.qpic.cn/mmbiz_png/90dLE6ibsg0fkqnx5yOhtlvx8dFgk1DvVfp2pmTsZ0yX0A2usH3afam4cJb7lQNIJGb3N2VZicclrfoRqM6MHhtQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" style="zoom:33%;"><p>find_split时，缺失值处理的伪代码</p><h3 id="XGBoost中叶子结点的权重如何计算出来"><a href="#XGBoost中叶子结点的权重如何计算出来" class="headerlink" title="XGBoost中叶子结点的权重如何计算出来"></a>XGBoost中叶子结点的权重如何计算出来</h3><p>XGBoost目标函数最终推导形式如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/90dLE6ibsg0fDfLgXV02BLFJ9eaFEJB0ERQaHDopzOeSvCyaPGicmHqArjzlJYDejcTs9YJoAFdAqwyVrdpUPZQA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>利用一元二次函数求最值的知识，当目标函数达到最小值Obj<em>时，每个叶子结点的权重为wj</em>。</p><p>具体公式如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/90dLE6ibsg0fDfLgXV02BLFJ9eaFEJB0EURBYpwF4xF4x2lLh7BroeKUjRqk17VXpkZqPEjaskia4kiazjs9nyg0A/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><h3 id="XGBoost中的一棵树的停止生长条件"><a href="#XGBoost中的一棵树的停止生长条件" class="headerlink" title="XGBoost中的一棵树的停止生长条件"></a>XGBoost中的一棵树的停止生长条件</h3><ul><li>当新引入的一次分裂所带来的增益Gain&lt;0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。</li><li>当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。</li><li>当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。这涉及到一个超参数:最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细。</li></ul><h3 id="RF和GBDT的区别"><a href="#RF和GBDT的区别" class="headerlink" title="RF和GBDT的区别"></a>RF和GBDT的区别</h3><p><strong>相同点：</strong></p><ul><li>都是由多棵树组成，最终的结果都是由多棵树一起决定。</li></ul><p><strong>不同点：</strong></p><ul><li><strong>集成学习</strong>：RF属于bagging思想，而GBDT是boosting思想</li><li><strong>偏差-方差权衡</strong>：RF不断的降低模型的方差，而GBDT不断的降低模型的偏差</li><li><strong>训练样本</strong>：RF每次迭代的样本是从全部训练集中有放回抽样形成的，而GBDT每次使用全部样本</li><li><strong>并行性</strong>：RF的树可以并行生成，而GBDT只能顺序生成(需要等上一棵树完全生成)</li><li><strong>最终结果</strong>：RF最终是多棵树进行多数表决（回归问题是取平均），而GBDT是加权融合</li><li><strong>数据敏感性</strong>：RF对异常值不敏感，而GBDT对异常值比较敏感</li><li><strong>泛化能力</strong>：RF不易过拟合，而GBDT容易过拟合</li></ul><h3 id="XGBoost如何处理不平衡数据"><a href="#XGBoost如何处理不平衡数据" class="headerlink" title="XGBoost如何处理不平衡数据"></a>XGBoost如何处理不平衡数据</h3><p>对于不平衡的数据集，例如用户的购买行为，肯定是极其不平衡的，这对XGBoost的训练有很大的影响，XGBoost有两种自带的方法来解决：</p><p>第一种，如果你在意AUC，采用AUC来评估模型的性能，那你可以通过设置scale_pos_weight来平衡正样本和负样本的权重。例如，当正负样本比例为1:10时，scale_pos_weight可以取10；</p><p>第二种，如果你在意概率(预测得分的合理性)，你不能重新平衡数据集(会破坏数据的真实分布)，应该设置max_delta_step为一个有限数字来帮助收敛（基模型为LR时有效）。</p><p>原话是这么说的：</p><pre class="line-numbers language-python"><code class="language-python">For common cases such <span class="token keyword">as</span> ads clickthrough log<span class="token punctuation">,</span> the dataset <span class="token keyword">is</span> extremely imbalanced<span class="token punctuation">.</span> This can affect the training of xgboost model<span class="token punctuation">,</span> <span class="token operator">and</span> there are two ways to improve it<span class="token punctuation">.</span>  If you care only about the ranking order <span class="token punctuation">(</span>AUC<span class="token punctuation">)</span> of your prediction      Balance the positive <span class="token operator">and</span> negative weights<span class="token punctuation">,</span> via scale_pos_weight      Use AUC <span class="token keyword">for</span> evaluation  If you care about predicting the right probability      In such a case<span class="token punctuation">,</span> you cannot re<span class="token operator">-</span>balance the dataset      In such a case<span class="token punctuation">,</span> set parameter max_delta_step to a finite number <span class="token punctuation">(</span>say <span class="token number">1</span><span class="token punctuation">)</span> will help convergence<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>那么，源码到底是怎么利用<strong>scale_pos_weight</strong>来平衡样本的呢，是调节权重还是过采样呢？请看源码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">if</span> <span class="token punctuation">(</span>info<span class="token punctuation">.</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1.</span><span class="token number">0f</span><span class="token punctuation">)</span>  w <span class="token operator">*=</span> param_<span class="token punctuation">.</span>scale_pos_weight<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看出，应该是增大了少数样本的权重。</p><p>除此之外，还可以通过上采样、下采样、SMOTE算法或者自定义代价函数的方式解决正负样本不平衡的问题。</p><h3 id="比较LR和GBDT，说说什么情景下GBDT不如LR"><a href="#比较LR和GBDT，说说什么情景下GBDT不如LR" class="headerlink" title="比较LR和GBDT，说说什么情景下GBDT不如LR"></a>比较LR和GBDT，说说什么情景下GBDT不如LR</h3><p>先说说LR和GBDT的区别：</p><ul><li>LR是线性模型，可解释性强，很容易并行化，但学习能力有限，需要大量的人工特征工程</li><li>GBDT是非线性模型，具有天然的特征组合优势，特征表达能力强，但是树与树之间无法并行训练，而且树模型很容易过拟合；</li></ul><p>当在高维稀疏特征的场景下，LR的效果一般会比GBDT好。原因如下：</p><p>先看一个例子：</p><blockquote><p>假设一个二分类问题，label为0和1，特征有100维，如果有1w个样本，但其中只要10个正样本1，而这些样本的特征 f1的值为全为1，而其余9990条样本的f1特征都为0(在高维稀疏的情况下这种情况很常见)。</p><p>我们都知道在这种情况下，树模型很容易优化出一个使用f1特征作为重要分裂节点的树，因为这个结点直接能够将训练数据划分的很好，但是当测试的时候，却会发现效果很差，因为这个特征f1只是刚好偶然间跟y拟合到了这个规律，这也是我们常说的过拟合。</p></blockquote><p>那么这种情况下，如果采用LR的话，应该也会出现类似过拟合的情况呀：y = W1<em>f1 + Wi</em>fi+….，其中 W1特别大以拟合这10个样本。为什么此时树模型就过拟合的更严重呢？</p><p>仔细想想发现，因为现在的模型普遍都会带着正则项，而 LR 等线性模型的正则项是对权重的惩罚，也就是 W1一旦过大，惩罚就会很大，进一步压缩 W1的值，使他不至于过大。但是，树模型则不一样，树模型的惩罚项通常为叶子节点数和深度等，而我们都知道，对于上面这种 case，树只需要一个节点就可以完美分割9990和10个样本，一个结点，最终产生的惩罚项极其之小。</p><p>这也就是为什么在高维稀疏特征的时候，线性模型会比非线性模型好的原因了：<strong>带正则化的线性模型比较不容易对稀疏特征过拟合。</strong></p><h3 id="XGBoost中如何对树进行剪枝"><a href="#XGBoost中如何对树进行剪枝" class="headerlink" title="XGBoost中如何对树进行剪枝"></a>XGBoost中如何对树进行剪枝</h3><ul><li>在目标函数中增加了正则项：使用叶子结点的数目和叶子结点权重的L2模的平方，控制树的复杂度。</li><li>在结点分裂时，定义了一个阈值，如果分裂后目标函数的增益小于该阈值，则不分裂。</li><li>当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值（最小样本权重和），也会放弃此次分裂。</li><li>XGBoost 先从顶到底建立树直到最大深度，再从底到顶反向检查是否有不满足分裂条件的结点，进行剪枝。</li></ul><h3 id="XGBoost如何选择最佳分裂点？"><a href="#XGBoost如何选择最佳分裂点？" class="headerlink" title="XGBoost如何选择最佳分裂点？"></a>XGBoost如何选择最佳分裂点？</h3><p>XGBoost在训练前预先将特征按照特征值进行了排序，并存储为block结构，以后在结点分裂时可以重复使用该结构。</p><p>因此，可以采用特征并行的方法利用多个线程分别计算每个特征的最佳分割点，根据每次分裂后产生的增益，最终选择增益最大的那个特征的特征值作为最佳分裂点。</p><p>如果在计算每个特征的最佳分割点时，对每个样本都进行遍历，计算复杂度会很大，这种全局扫描的方法并不适用大数据的场景。XGBoost还提供了一种直方图近似算法，对特征排序后仅选择常数个候选分裂位置作为候选分裂点，极大提升了结点分裂时的计算效率。</p><h3 id="XGBoost的Scalable性如何体现"><a href="#XGBoost的Scalable性如何体现" class="headerlink" title="XGBoost的Scalable性如何体现"></a>XGBoost的Scalable性如何体现</h3><ul><li><strong>基分类器的scalability</strong>：弱分类器可以支持CART决策树，也可以支持LR和Linear。</li><li><strong>目标函数的scalability</strong>：支持自定义loss function，只需要其一阶、二阶可导。有这个特性是因为泰勒二阶展开，得到通用的目标函数形式。</li><li><strong>学习方法的scalability</strong>：Block结构支持并行化，支持 Out-of-core计算。</li></ul><h3 id="XGBoost如何评价特征的重要性"><a href="#XGBoost如何评价特征的重要性" class="headerlink" title="XGBoost如何评价特征的重要性"></a>XGBoost如何评价特征的重要性</h3><p>我们采用三种方法来评判XGBoost模型中特征的重要程度：</p><pre><code> 官方文档：（1）weight - the number of times a feature is used to split the data across all trees. （2）gain - the average gain of the feature when it is used in trees. （3）cover - the average coverage of the feature when it is used in trees.</code></pre><ul><li><strong>weight</strong> ：该特征在所有树中被用作分割样本的特征的总次数。</li><li><strong>gain</strong> ：该特征在其出现过的所有树中产生的平均增益。</li><li><strong>cover</strong> ：该特征在其出现过的所有树中的平均覆盖范围。</li></ul><blockquote><p>注意：覆盖范围这里指的是一个特征用作分割点后，其影响的样本数量，即有多少样本经过该特征分割到两个子节点。</p></blockquote><h3 id="XGBooost参数调优的一般步骤"><a href="#XGBooost参数调优的一般步骤" class="headerlink" title="XGBooost参数调优的一般步骤"></a>XGBooost参数调优的一般步骤</h3><p>首先需要初始化一些基本变量，例如：</p><ul><li>max_depth = 5</li><li>min_child_weight = 1</li><li>gamma = 0</li><li>subsample, colsample_bytree = 0.8</li><li>scale_pos_weight = 1</li></ul><p><strong>(1) 确定learning rate和estimator的数量</strong></p><p>learning rate可以先用0.1，用cv来寻找最优的estimators</p><p><strong>(2) max_depth和 min_child_weight</strong></p><p>我们调整这两个参数是因为，这两个参数对输出结果的影响很大。我们首先将这两个参数设置为较大的数，然后通过迭代的方式不断修正，缩小范围。</p><p>max_depth，每棵子树的最大深度，check from range(3,10,2)。</p><p>min_child_weight，子节点的权重阈值，check from range(1,6,2)。</p><p>如果一个结点分裂后，它的所有子节点的权重之和都大于该阈值，该叶子节点才可以划分。</p><p><strong>(3) gamma</strong></p><p>也称作最小划分损失<code>min_split_loss</code>，check from 0.1 to 0.5，指的是，对于一个叶子节点，当对它采取划分之后，损失函数的降低值的阈值。</p><ul><li>如果大于该阈值，则该叶子节点值得继续划分</li><li>如果小于该阈值，则该叶子节点不值得继续划分</li></ul><p><strong>(4) subsample, colsample_bytree</strong></p><p>subsample是对训练的采样比例</p><p>colsample_bytree是对特征的采样比例</p><p>both check from 0.6 to 0.9</p><p><strong>(5) 正则化参数</strong></p><p>alpha 是L1正则化系数，try 1e-5, 1e-2, 0.1, 1, 100</p><p>lambda 是L2正则化系数</p><p><strong>(6) 降低学习率</strong></p><p>降低学习率的同时增加树的数量，通常最后设置学习率为0.01~0.1</p><h3 id="XGBoost模型如果过拟合了怎么解决"><a href="#XGBoost模型如果过拟合了怎么解决" class="headerlink" title="XGBoost模型如果过拟合了怎么解决"></a>XGBoost模型如果过拟合了怎么解决</h3><p>当出现过拟合时，有两类参数可以缓解：</p><p>第一类参数：用于直接控制模型的复杂度。包括<code>max_depth,min_child_weight,gamma</code> 等参数</p><p>第二类参数：用于增加随机性，从而使得模型在训练时对于噪音不敏感。包括<code>subsample,colsample_bytree</code></p><p>还有就是直接减小<code>learning rate</code>，但需要同时增加<code>estimator</code> 参数。</p><h3 id="为什么XGBoost相比某些模型对缺失值不敏感"><a href="#为什么XGBoost相比某些模型对缺失值不敏感" class="headerlink" title="为什么XGBoost相比某些模型对缺失值不敏感"></a>为什么XGBoost相比某些模型对缺失值不敏感</h3><p>对存在缺失值的特征，一般的解决方法是：</p><ul><li>离散型变量：用出现次数最多的特征值填充；</li><li>连续型变量：用中位数或均值填充；</li></ul><p>一些模型如SVM和KNN，其模型原理中涉及到了对样本距离的度量，如果缺失值处理不当，最终会导致模型预测效果很差。</p><p>而树模型对缺失值的敏感度低，大部分时候可以在数据缺失时时使用。原因就是，一棵树中每个结点在分裂时，寻找的是某个特征的最佳分裂点（特征值），完全可以不考虑存在特征值缺失的样本，也就是说，如果某些样本缺失的特征值缺失，对寻找最佳分割点的影响不是很大。</p><p>XGBoost对缺失数据有特定的处理方法，<a href="http://mp.weixin.qq.com/s?__biz=Mzg2MjI5Mzk0MA==&amp;mid=2247484181&amp;idx=1&amp;sn=8d0e51fb0cb974f042e66659e1daf447&amp;chksm=ce0b59cef97cd0d8cf7f9ae1e91e41017ff6d4c4b43a4c19b476c0b6d37f15769f954c2965ef&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">详情参考上篇文章第7题</a>。</p><p>因此，对于有缺失值的数据在经过缺失处理后：</p><ul><li>当数据量很小时，优先用朴素贝叶斯</li><li>数据量适中或者较大，用树模型，优先XGBoost</li><li>数据量较大，也可以用神经网络</li><li>避免使用距离度量相关的模型，如KNN和SVM</li></ul><h3 id="XGBoost和LightGBM的区别"><a href="#XGBoost和LightGBM的区别" class="headerlink" title="XGBoost和LightGBM的区别"></a>XGBoost和LightGBM的区别</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_png/90dLE6ibsg0cassUTLvbQlGic1CW6ialKxxJ2S8XI3VokUBf5TBOSDG8zb6gZXe0q63b4TyDlDPCX9G6cPXlmR4cw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>（1）树生长策略：XGB采用<code>level-wise</code>的分裂策略，LGB采用<code>leaf-wise</code>的分裂策略。XGB对每一层所有节点做无差别分裂，但是可能有些节点增益非常小，对结果影响不大，带来不必要的开销。Leaf-wise是在所有叶子节点中选取分裂收益最大的节点进行的，但是很容易出现过拟合问题，所以需要对最大深度做限制 。</p><p>（2）分割点查找算法：XGB使用特征预排序算法，LGB使用基于直方图的切分点算法，其优势如下：</p><ul><li>减少内存占用，比如离散为256个bin时，只需要用8位整形就可以保存一个样本被映射为哪个bin(这个bin可以说就是转换后的特征)，对比预排序的exact greedy算法来说（用int_32来存储索引+ 用float_32保存特征值），可以节省7/8的空间。</li><li>计算效率提高，预排序的Exact greedy对每个特征都需要遍历一遍数据，并计算增益，复杂度为𝑂(#𝑓𝑒𝑎𝑡𝑢𝑟𝑒×#𝑑𝑎𝑡𝑎)。而直方图算法在建立完直方图后，只需要对每个特征遍历直方图即可，复杂度为𝑂(#𝑓𝑒𝑎𝑡𝑢𝑟𝑒×#𝑏𝑖𝑛𝑠)。</li><li>LGB还可以使用直方图做差加速，一个节点的直方图可以通过父节点的直方图减去兄弟节点的直方图得到，从而加速计算</li></ul><blockquote><p>但实际上xgboost的近似直方图算法也类似于lightgbm这里的直方图算法，为什么xgboost的近似算法比lightgbm还是慢很多呢？</p><p>xgboost在每一层都动态构建直方图， 因为xgboost的直方图算法不是针对某个特定的feature，而是所有feature共享一个直方图(每个样本的权重是二阶导)，所以每一层都要重新构建直方图，而lightgbm中对每个特征都有一个直方图，所以构建一次直方图就够了。</p></blockquote><p>（3）支持离散变量：无法直接输入类别型变量，因此需要事先对类别型变量进行编码（例如独热编码），而LightGBM可以直接处理类别型变量。</p><p>（4）缓存命中率：XGB使用Block结构的一个缺点是取梯度的时候，是通过索引来获取的，而这些梯度的获取顺序是按照特征的大小顺序的，这将导致非连续的内存访问，可能使得CPU cache缓存命中率低，从而影响算法效率。而LGB是基于直方图分裂特征的，梯度信息都存储在一个个bin中，所以访问梯度是连续的，缓存命中率高。</p><p>（5）LightGBM 与 XGboost 的并行策略不同：</p><ul><li><strong>特征并行</strong> ：LGB特征并行的前提是每个worker留有一份完整的数据集，但是每个worker仅在特征子集上进行最佳切分点的寻找；worker之间需要相互通信，通过比对损失来确定最佳切分点；然后将这个最佳切分点的位置进行全局广播，每个worker进行切分即可。XGB的特征并行与LGB的最大不同在于XGB每个worker节点中仅有部分的列数据，也就是垂直切分，每个worker寻找局部最佳切分点，worker之间相互通信，然后在具有最佳切分点的worker上进行节点分裂，再由这个节点广播一下被切分到左右节点的样本索引号，其他worker才能开始分裂。二者的区别就导致了LGB中worker间通信成本明显降低，只需通信一个特征分裂点即可，而XGB中要广播样本索引。</li><li><strong>数据并行</strong> ：当数据量很大，特征相对较少时，可采用数据并行策略。LGB中先对数据水平切分，每个worker上的数据先建立起局部的直方图，然后合并成全局的直方图，采用直方图相减的方式，先计算样本量少的节点的样本索引，然后直接相减得到另一子节点的样本索引，这个直方图算法使得worker间的通信成本降低一倍，因为只用通信以此样本量少的节点。XGB中的数据并行也是水平切分，然后单个worker建立局部直方图，再合并为全局，不同在于根据全局直方图进行各个worker上的节点分裂时会单独计算子节点的样本索引，因此效率贼慢，每个worker间的通信量也就变得很大。</li><li><strong>投票并行（LGB）</strong>：当数据量和维度都很大时，选用投票并行，该方法是数据并行的一个改进。数据并行中的合并直方图的代价相对较大，尤其是当特征维度很大时。大致思想是：每个worker首先会找到本地的一些优秀的特征，然后进行全局投票，根据投票结果，选择top的特征进行直方图的合并，再寻求全局的最优分割点。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><strong>XGBoost论文解读：</strong></p><p>【1】Chen T , Guestrin C . XGBoost: A Scalable Tree Boosting System[J]. 2016.</p><p>【2】<a href="https://homes.cs.washington.edu/~tqchen/data/pdf/BoostedTree.pdf" target="_blank" rel="noopener">Tianqi Chen的XGBoost的Slides</a></p><p>【3】<a href="https://zhuanlan.zhihu.com/p/75217528" target="_blank" rel="noopener">对xgboost的理解 - 金贵涛的文章 - 知乎</a></p><p>【4】<a href="https://blog.csdn.net/Dby_freedom/article/details/84301725" target="_blank" rel="noopener">CTR预估 论文精读(一)–XGBoost</a></p><p>【5】<a href="https://zhuanlan.zhihu.com/p/36794802" target="_blank" rel="noopener">XGBoost论文阅读及其原理 - Salon sai的文章 - 知乎</a></p><p>【6】<a href="https://blog.csdn.net/qdbszsj/article/details/79615712" target="_blank" rel="noopener">XGBoost 论文翻译+个人注释</a></p><p><strong>XGBoost算法讲解：</strong></p><p>【7】<a href="https://mp.weixin.qq.com/s/wLE9yb7MtE208IVLFlZNkw" target="_blank" rel="noopener">XGBoost超详细推导，终于有人讲明白了！</a></p><p>【8】<a href="https://mp.weixin.qq.com/s/LoX987dypDg8jbeTJMpEPQ" target="_blank" rel="noopener">终于有人把XGBoost 和 LightGBM 讲明白了，项目中最主流的集成算法！</a></p><p>【9】<a href="https://www.zhihu.com/question/41354392/answer/98658997" target="_blank" rel="noopener">机器学习算法中 GBDT 和 XGBOOST 的区别有哪些？ - wepon的回答 - 知乎</a> </p><p>【10】<a href="http://wepon.me/files/gbdt.pdf" target="_blank" rel="noopener">GBDT算法原理与系统设计简介，wepon</a></p><p><strong>XGBoost实例：</strong></p><p>【11】<a href="https://www.jianshu.com/p/7e0e2d66b3d4" target="_blank" rel="noopener">Kaggle 神器 xgboost</a></p><p>【12】<a href="https://mp.weixin.qq.com/s/X4K6UFZPxL05v2uolId7Lw" target="_blank" rel="noopener">干货 | XGBoost在携程搜索排序中的应用</a></p><p>【13】<a href="https://zhuanlan.zhihu.com/p/31182879" target="_blank" rel="noopener">史上最详细的XGBoost实战 - 章华燕的文章 - 知乎</a></p><p>【14】<a href="https://zhuanlan.zhihu.com/p/61150141" target="_blank" rel="noopener">XGBoost模型构建流程及模型参数微调（房价预测附代码讲解） - 人工智能学术前沿的文章 - 知乎</a></p><p><strong>XGBoost面试题：</strong></p><p>【15】<a href="https://mp.weixin.qq.com/s/_QgnYoW827GDgVH9lexkNA" target="_blank" rel="noopener">珍藏版 | 20道XGBoost面试题，你会几个？(上篇)</a></p><p>【16】<a href="https://mp.weixin.qq.com/s/BbelOsYgsiOvwfwYs5QfpQ" target="_blank" rel="noopener">珍藏版 | 20道XGBoost面试题，你会几个？(下篇</a>)</p><p>【17】<a href="https://mp.weixin.qq.com/s/RSQWx4fH3uI_sjZzAKVyKQ" target="_blank" rel="noopener">推荐收藏 | 10道XGBoost面试题送给你</a></p><p>【18】<a href="https://mp.weixin.qq.com/s/vjLPVhg_UavZIJrOzu_u1w" target="_blank" rel="noopener">面试题：xgboost怎么给特征评分？</a></p><p>【19】<a href="https://zhuanlan.zhihu.com/p/81368182" target="_blank" rel="noopener">[校招-基础算法]GBDT/XGBoost常见问题 - Jack Stark的文章 - 知乎</a></p><p>【20】《百面机器学习》诸葛越主编、葫芦娃著，P295-P297。</p><p>【21】<a href="https://zhuanlan.zhihu.com/p/86816771" target="_blank" rel="noopener">灵魂拷问，你看过Xgboost原文吗？ - 小雨姑娘的文章 - 知乎</a></p><p>【22】<a href="https://www.zhihu.com/question/277638585/answer/522272201" target="_blank" rel="noopener">为什么xgboost泰勒二阶展开后效果就比较好了呢？ - Zsank的回答 - 知乎</a> </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      XGBoost
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://dataquaner.github.io/categories/Machine-Learning/"/>
    
    
      <category term="XGBoost" scheme="https://dataquaner.github.io/tags/XGBoost/"/>
    
  </entry>
  
</feed>
